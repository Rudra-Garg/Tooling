
Filename: .gitignore
Content:
### Python template
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

### Flask template
instance/*
!instance/.gitignore

config/firebase_config.json
output.json
/config/firebase_service_account.json
repo_contents.txt
results*
*.prof
*.patch


================================================================================

Filename: .idea/.gitignore
Content:
# Default ignored files
/shelf/
/workspace.xml
# Editor-based HTTP Client requests
/httpRequests/
# Datasource local storage ignored files
/dataSources/
/dataSources.local.xml


================================================================================

Filename: .idea/Portal-Gambit-Backend.iml
Content:
<?xml version="1.0" encoding="UTF-8"?>
<module type="PYTHON_MODULE" version="4">
  <component name="NewModuleRootManager">
    <content url="file://$MODULE_DIR$">
      <excludeFolder url="file://$MODULE_DIR$/.venv" />
    </content>
    <orderEntry type="jdk" jdkName="Python 3.12 (portal-gambit-backend)" jdkType="Python SDK" />
    <orderEntry type="sourceFolder" forTests="false" />
  </component>
</module>

================================================================================

Filename: .idea/dataSources.xml
Content:
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="DataSourceManagerImpl" format="xml" multifile-model="true">
    <data-source source="LOCAL" name=".coverage.Rudra-Pavilion.420.XYqAlFcx" uuid="8ad2990c-dfbe-414d-8a21-55c36aabdfba">
      <driver-ref>sqlite.xerial</driver-ref>
      <synchronize>true</synchronize>
      <jdbc-driver>org.sqlite.JDBC</jdbc-driver>
      <jdbc-url>jdbc:sqlite:C:\PyCharmProjects\test\portal-gambit-backend\.coverage.Rudra-Pavilion.420.XYqAlFcx.wgw9</jdbc-url>
      <jdbc-additional-properties>
        <property name="com.intellij.clouds.kubernetes.db.enabled" value="false" />
      </jdbc-additional-properties>
      <working-dir>$ProjectFileDir$</working-dir>
    </data-source>
    <data-source source="LOCAL" name=".coverage" uuid="e7da94d1-9801-455a-baab-659df56a47f6">
      <driver-ref>sqlite.xerial</driver-ref>
      <synchronize>true</synchronize>
      <jdbc-driver>org.sqlite.JDBC</jdbc-driver>
      <jdbc-url>jdbc:sqlite:C:\PyCharmProjects\test\portal-gambit-backend\.coverage</jdbc-url>
      <jdbc-additional-properties>
        <property name="com.intellij.clouds.kubernetes.db.enabled" value="false" />
      </jdbc-additional-properties>
      <working-dir>$ProjectFileDir$</working-dir>
    </data-source>
  </component>
</project>

================================================================================

Filename: .idea/inspectionProfiles/Project_Default.xml
Content:
<component name="InspectionProjectProfileManager">
  <profile version="1.0">
    <option name="myName" value="Project Default" />
    <inspection_tool class="DuplicatedCode" enabled="true" level="WEAK WARNING" enabled_by_default="true">
      <Languages>
        <language minSize="51" name="Python" />
      </Languages>
    </inspection_tool>
    <inspection_tool class="Eslint" enabled="true" level="WARNING" enabled_by_default="true" />
    <inspection_tool class="JsonSchemaCompliance" enabled="false" level="WARNING" enabled_by_default="false" />
    <inspection_tool class="PyPackageRequirementsInspection" enabled="true" level="WARNING" enabled_by_default="true">
      <option name="ignoredPackages">
        <value>
          <list size="10">
            <item index="0" class="java.lang.String" itemvalue="typing_extensions" />
            <item index="1" class="java.lang.String" itemvalue="grpcio" />
            <item index="2" class="java.lang.String" itemvalue="Werkzeug" />
            <item index="3" class="java.lang.String" itemvalue="cryptography" />
            <item index="4" class="java.lang.String" itemvalue="Jinja2" />
            <item index="5" class="java.lang.String" itemvalue="idna" />
            <item index="6" class="java.lang.String" itemvalue="packaging" />
            <item index="7" class="java.lang.String" itemvalue="gunicorn" />
            <item index="8" class="java.lang.String" itemvalue="dotenv" />
            <item index="9" class="java.lang.String" itemvalue="flask" />
          </list>
        </value>
      </option>
    </inspection_tool>
    <inspection_tool class="PyPep8Inspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
      <option name="ignoredErrors">
        <list>
          <option value="W605" />
        </list>
      </option>
    </inspection_tool>
    <inspection_tool class="PyPep8NamingInspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
      <option name="ignoredErrors">
        <list>
          <option value="N802" />
          <option value="N803" />
          <option value="N806" />
          <option value="N801" />
        </list>
      </option>
    </inspection_tool>
    <inspection_tool class="PyShadowingBuiltinsInspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
      <option name="ignoredNames">
        <list>
          <option value="str" />
        </list>
      </option>
    </inspection_tool>
    <inspection_tool class="PyUnresolvedReferencesInspection" enabled="true" level="WARNING" enabled_by_default="true">
      <option name="ignoredIdentifiers">
        <list>
          <option value="dict.*" />
        </list>
      </option>
    </inspection_tool>
    <inspection_tool class="SqlResolveInspection" enabled="true" level="ERROR" enabled_by_default="true">
      <option name="suppressForPossibleStringLiterals" value="true" />
    </inspection_tool>
  </profile>
</component>

================================================================================

Filename: .idea/inspectionProfiles/profiles_settings.xml
Content:
<component name="InspectionProjectProfileManager">
  <settings>
    <option name="USE_PROJECT_PROFILE" value="false" />
    <version value="1.0" />
  </settings>
</component>

================================================================================

Filename: .idea/misc.xml
Content:
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="Black">
    <option name="sdkName" value="Python 3.12 (L7)" />
  </component>
  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.12 (portal-gambit-backend)" project-jdk-type="Python SDK" />
</project>

================================================================================

Filename: .idea/modules.xml
Content:
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ProjectModuleManager">
    <modules>
      <module fileurl="file://$PROJECT_DIR$/.idea/Portal-Gambit-Backend.iml" filepath="$PROJECT_DIR$/.idea/Portal-Gambit-Backend.iml" />
    </modules>
  </component>
</project>

================================================================================

Filename: .idea/vcs.xml
Content:
<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="VcsDirectoryMappings">
    <mapping directory="" vcs="Git" />
    <mapping directory="$PROJECT_DIR$" vcs="Git" />
  </component>
</project>

================================================================================

Filename: Dockerfile
Content:
FROM python:3.11-slim

WORKDIR /app

# Install necessary tools
RUN apt-get update && apt-get install -y bash && rm -rf /var/lib/apt/lists/*

# Copy requirements file first for better caching
COPY requirements.txt .

# Install dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the application
COPY . .

# Ensure script is executable
RUN chmod +x config/convert.sh run.sh

# Expose the port the app runs on
EXPOSE 8080

# Command to run the application
CMD bash run.sh


================================================================================

Filename: README.md
Content:
# Portal Gambit Backend

Backend API service for the Portal Gambit chess variant game, built with FastAPI and Firebase Authentication.

## Description

Portal Gambit Backend is a RESTful API service that powers the Portal Gambit chess variant game. It provides endpoints for user profiles, friend management, game history, and analytics, with secure authentication using Firebase.

## Features

- User profile management
- Friend system
- Game history tracking
- Analytics
- Firebase Authentication
- CORS support
- OpenAPI documentation (Swagger UI)

## Tech Stack

- Python 3.x
- FastAPI
- Firebase Admin SDK
- Uvicorn (ASGI server)
- Pydantic for data validation
- Python-dotenv for environment management

## Prerequisites

- Python 3.x
- Firebase project credentials
- Virtual environment (recommended)

## Installation

1. Clone the repository:
```bash
git clone [your-repository-url]
cd portal-gambit-backend
```

2. Create and activate a virtual environment:
```bash
python -m venv .venv
# On Windows
.venv\Scripts\activate
# On Unix or MacOS
source .venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
Create a `.env` file in the root directory with the following variables:
```
FIREBASE_CREDENTIALS=path/to/your/firebase-credentials.json
# Add other environment variables as needed
```

## Running the Application

To run the development server:

```bash
python main.py
```

Or using uvicorn directly:

```bash
uvicorn main:app --reload
```

The API will be available at `http://localhost:8000`

## API Documentation

Once the server is running, you can access:
- Swagger UI documentation at `http://localhost:8000/docs`
- ReDoc documentation at `http://localhost:8000/redoc`

## Project Structure

```
portal-gambit-backend/
├── config/         # Configuration files
├── middleware/     # Custom middleware (including Firebase Auth)
├── models/        # Data models
├── routes/        # API route handlers
├── schemas/       # Pydantic schemas
├── services/      # Business logic
├── utils/         # Utility functions
├── .env           # Environment variables
├── main.py        # Application entry point
└── requirements.txt
```

## API Endpoints

- `/` - Root endpoint with API information
- `/profile/*` - User profile management
- `/friends/*` - Friend system endpoints
- `/history/*` - Game history endpoints
- `/analytics/*` - Analytics endpoints
- `/auth/*` - Authentication endpoints


================================================================================

Filename: cloudbuild.yaml
Content:
steps:
  # Step 1: Print Secret Info (Without Exposing Values)
  - name: gcr.io/cloud-builders/gcloud
    entrypoint: bash
    args:
      - "-c"
      - |
        echo "✅ Checking secrets..."
        echo "JWT_SECRET_KEY is set: ${JWT_SECRET_KEY:+YES}"
        echo "FIREBASE_CONFIG_STRING length: ${#FIREBASE_CONFIG_STRING}"

    secretEnv:
      - JWT_SECRET_KEY
      - FIREBASE_CONFIG_STRING

  # Step 2: Build Docker Image
  - name: gcr.io/cloud-builders/docker
    args: [ "build", "-t", "asia-south1-docker.pkg.dev/portal-gambit/cloud-run-source-deploy/portal-gambit-backend/portal-gambit-backend:$SHORT_SHA", "." ]

  # Step 3: Push Image to Artifact Registry
  - name: gcr.io/cloud-builders/docker
    args: [ "push", "asia-south1-docker.pkg.dev/portal-gambit/cloud-run-source-deploy/portal-gambit-backend/portal-gambit-backend:$SHORT_SHA" ]

  # Step 4: Deploy to Cloud Run
  - name: gcr.io/cloud-builders/gcloud
    args:
      - run
      - deploy
      - portal-gambit-backend
      - --image=asia-south1-docker.pkg.dev/portal-gambit/cloud-run-source-deploy/portal-gambit-backend/portal-gambit-backend:$SHORT_SHA
      - --region=asia-south1
      - --platform=managed
      - --allow-unauthenticated
      - --set-secrets=JWT_SECRET_KEY=JWT_SECRET_KEY:latest,FIREBASE_CONFIG_STRING=FIREBASE_CONFIG_STRING:latest

availableSecrets:
  secretManager:
    - versionName: projects/$PROJECT_ID/secrets/JWT_SECRET_KEY/versions/latest
      env: "JWT_SECRET_KEY"
    - versionName: projects/$PROJECT_ID/secrets/FIREBASE_CONFIG_STRING/versions/latest
      env: "FIREBASE_CONFIG_STRING"

images:
  - "asia-south1-docker.pkg.dev/portal-gambit/cloud-run-source-deploy/portal-gambit-backend/portal-gambit-backend:$SHORT_SHA"


================================================================================

Filename: config/convert.sh
Content:
#!/bin/bash

# Check if variable name argument is provided
if [ $# -eq 0 ]; then
    echo "Usage: $0 VARIABLE_NAME [OUTPUT_FILE]"
    echo "Example: $0 MY_ENCODED_VAR output.json"
    exit 1
fi

# Get variable name and output file from arguments
VAR_NAME=$1
OUTPUT_FILE=${2:-output.json}  # Default to output.json if not specified

# Check if the environment variable exists
if [ -z "${!VAR_NAME}" ]; then
    echo "Error: Variable $VAR_NAME not found"
    exit 1
fi

# Decode base64 and write to file
echo "${!VAR_NAME}" | base64 --decode > "$OUTPUT_FILE"
cat "$OUTPUT_FILE"
# Check if decode was successful
if [ $? -eq 0 ]; then
    echo "Successfully decoded $VAR_NAME to $OUTPUT_FILE"
else
    echo "Error: Failed to decode base64 content"
    rm -f "$OUTPUT_FILE"  # Clean up failed output
    exit 1
fi

================================================================================

Filename: config/firebase_config.py
Content:
import os

import firebase_admin
from dotenv import load_dotenv
from google.cloud.firestore_v1.async_client import AsyncClient

# Load environment variables
load_dotenv()

_db_client: AsyncClient = None  # Cache the client instance


def initialize_firebase():
    """Initialize Firebase Admin SDK and return an Async Firestore client."""
    global _db_client
    if _db_client:
        print("Using cached Firestore AsyncClient.")
        return _db_client

    try:
        # Get the path to service account file from environment variable
        service_account_path = os.getenv('FIREBASE_SERVICE_ACCOUNT_PATH',
                                         'config/firebase_service_account.json')  # Default path

        if os.path.exists(service_account_path):
            cred = firebase_admin.credentials.Certificate(service_account_path)
            print(f"Initializing Firebase from path: {service_account_path}...")
        else:
            raise ValueError(
                "Firebase credentials not found. Set FIREBASE_SERVICE_ACCOUNT_PATH or FIREBASE_CONFIG_STRING.")

        # Initialize Firebase Admin SDK only if not already initialized
        if not firebase_admin._apps:
            firebase_admin.initialize_app(cred, {
                # databaseURL and storageBucket are often optional for Firestore only
                # 'databaseURL': os.getenv('FIREBASE_DATABASE_URL'),
                # 'storageBucket': os.getenv('FIREBASE_STORAGE_BUCKET')
            })
            print("Firebase Admin App Initialized.")
        else:
            print("Firebase Admin App already initialized.")

        # Initialize Firestore Async client
        # Pass the project ID explicitly if needed, often inferred from creds
        from google.auth import default
        credentials, project_id = default()
        _db_client = AsyncClient(project=project_id, credentials=credentials)  # Use AsyncClient
        print(f"Firestore AsyncClient Initialized for project: {_db_client.project}")

        return _db_client
    except Exception as e:
        print(f"Error initializing Firebase/Firestore: {e}")
        raise


================================================================================

Filename: main.py
Content:
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from middleware.auth_middleware import FirebaseAuthMiddleware
from routes import profile_routes, friend_routes, history_routes, analytics_routes, auth_routes

app = FastAPI(
    title="Portal Gambit Backend",
    description="Backend API for Portal Gambit chess variant game",
    version="1.0.0"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Update this with your frontend URL in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure Firebase Authentication Middleware
# Add paths that should be excluded from authentication
excluded_paths = [
    r"^/$",  # Root path
    r"^/docs$",  # Swagger UI
    r"^/openapi.json$",  # OpenAPI schema
    r"^/redoc$",  # ReDoc UI
]
app.add_middleware(FirebaseAuthMiddleware, exclude_paths=excluded_paths)

# Include routers
app.include_router(profile_routes.router)
app.include_router(friend_routes.router)
app.include_router(history_routes.router)
app.include_router(analytics_routes.router)
app.include_router(auth_routes.router)

@app.get("/")
async def root():
    """Root endpoint returning API information."""
    return {
        "name": "Portal Gambit Backend API",
        "version": "1.0.0",
        "status": "running"
    }

if __name__ == '__main__':
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)


================================================================================

Filename: middleware/auth_middleware.py
Content:
# middleware/auth_middleware.py

import logging
import re
from typing import Optional, List

from fastapi import Request, HTTPException
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from starlette import status
# Import Response and JSONResponse
from starlette.responses import JSONResponse

from utils.jwt_utils import verify_token

security = HTTPBearer()
logger = logging.getLogger(__name__)


class FirebaseAuthMiddleware:
    def __init__(self, app, exclude_paths: Optional[List[str]] = None):
        """Initialize middleware with optional paths to exclude from authentication."""
        self.app = app
        default_exclude_paths = [
            r"^/auth/token$",
            r"^/$",
            r"^/docs$",
            r"^/openapi.json$",
            r"^/redoc$",
            r"^/favicon\.ico$",
        ]
        self.exclude_paths = (exclude_paths or []) + default_exclude_paths
        self.exclude_patterns = [re.compile(pattern) for pattern in self.exclude_paths]

    async def __call__(self, scope, receive, send):
        """Process each request through the middleware."""
        if scope["type"] != "http":
            await self.app(scope, receive, send)
            return

        request = Request(scope, receive=receive)
        path = request.url.path

        if any(pattern.match(path) for pattern in self.exclude_patterns) or request.method == "OPTIONS":
            await self.app(scope, receive, send)
            return

        # --- Explicitly handle potential exceptions from security() and verify_token() ---
        try:
            credentials: HTTPAuthorizationCredentials = await security(request)
            token = credentials.credentials
            decoded_token = verify_token(token)
            request.state.user = decoded_token
            # Proceed only if token is valid
            await self.app(scope, receive, send)

        except HTTPException as http_exc:
            # If security() or verify_token() raised an HTTPException (403 or 401),
            # construct and send the response manually.
            response = JSONResponse(
                status_code=http_exc.status_code,
                content={"detail": http_exc.detail},
                headers=http_exc.headers,  # Include headers like WWW-Authenticate
            )
            await response(scope, receive, send)
            return  # Stop processing here

        except Exception as e:
            # Catch any other unexpected errors during the auth process
            logger.exception(f"Unexpected error during authentication middleware for path {path}: {e}")
            response = JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={"detail": "Internal Server Error during authentication process"},
            )
            await response(scope, receive, send)
            return  # Stop processing here


================================================================================

Filename: models/friend.py
Content:
from datetime import datetime, timezone  # Import timezone
from enum import Enum
from typing import Optional

from pydantic import BaseModel, Field


class FriendRequestStatus(str, Enum):
    PENDING = "pending"
    ACCEPTED = "accepted"
    REJECTED = "rejected"


class FriendRequest(BaseModel):
    request_id: str = Field(..., description="Unique request identifier")
    sender_id: str = Field(..., description="UID of the request sender")
    receiver_id: str = Field(..., description="UID of the request receiver")
    status: FriendRequestStatus = Field(default=FriendRequestStatus.PENDING)
    # FIX: Use datetime.now(timezone.utc) for default factory
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    message: Optional[str] = None

    class Config:
        json_schema_extra = {
            "example": {
                "request_id": "req123",
                "sender_id": "user1",
                "receiver_id": "user2",
                "status": "pending",
                "message": "Let's play some chess!"
            }
        }


class FriendStatus(BaseModel):
    user_id: str
    friend_id: str
    # FIX: Use datetime.now(timezone.utc) for default factory
    became_friends: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    games_played: int = Field(default=0)
    last_game: Optional[str] = None  # Reference to last game_id
    # FIX: Use datetime.now(timezone.utc) for default factory
    last_interaction: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))


================================================================================

Filename: models/game_history.py
Content:
from datetime import datetime, timezone  # Import timezone
from enum import Enum
from typing import Optional, List

from pydantic import BaseModel, Field


class GameResult(str, Enum):
    WHITE_WIN = "white_win"
    BLACK_WIN = "black_win"
    DRAW = "draw"
    ABANDONED = "abandoned"


class GameHistory(BaseModel):
    game_id: str = Field(..., description="Unique game identifier")
    white_player_id: str = Field(..., description="UID of white player")
    black_player_id: str = Field(..., description="UID of black player")
    # FIX: Use datetime.now(timezone.utc) for default factory
    start_time: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    end_time: datetime  # Should be set when game ends
    result: GameResult
    winner_id: Optional[str] = None
    moves: List[str] = Field(..., description="List of moves in algebraic notation")
    initial_position: str = Field(default="standard", description="Starting position FEN")
    white_rating: int
    black_rating: int
    rating_change: dict = Field(..., description="Rating changes for both players")
    game_type: str = Field(default="portal_gambit", description="Variant type")
    time_control: dict = Field(..., description="Time control settings")

    class Config:
        json_schema_extra = {
            "example": {
                "game_id": "game123",
                "white_player_id": "user1",
                "black_player_id": "user2",
                "result": "white_win",
                "winner_id": "user1",
                "moves": ["e4", "e5", "Nf3"],
                "white_rating": 1200,
                "black_rating": 1150,
                "rating_change": {"white": 8, "black": -8},
                "time_control": {"initial": 600, "increment": 5}
            }
        }


================================================================================

Filename: models/user_profile.py
Content:
from pydantic import BaseModel, Field
from typing import Optional, List
from datetime import datetime, timezone  # Import timezone


class UserProfile(BaseModel):
    uid: str = Field(..., description="Firebase User ID")
    username: str = Field(..., min_length=3, max_length=30)
    email: str
    display_name: Optional[str] = None
    avatar_url: Optional[str] = None
    rating: int = Field(default=1200, description="Chess rating")
    games_played: int = Field(default=0)
    wins: int = Field(default=0)
    losses: int = Field(default=0)
    draws: int = Field(default=0)
    # FIX: Use datetime.now(timezone.utc) for default factory
    created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    # FIX: Use datetime.now(timezone.utc) for default factory
    last_active: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    friends: List[str] = Field(default_factory=list, description="List of friend UIDs")
    achievements: List[str] = Field(default_factory=list)
    preferences: dict = Field(default_factory=dict)

    class Config:
        json_schema_extra = {
            "example": {
                "uid": "abc123",
                "username": "chessMaster",
                "email": "user@example.com",
                "display_name": "Chess Master",
                "rating": 1200,
                "games_played": 0,
                "wins": 0,
                "losses": 0,
                "draws": 0
            }
        }


================================================================================

Filename: pytest.ini
Content:
[pytest]
asyncio_mode = auto
pythonpath = .
testpaths = tests 

================================================================================

Filename: requirements.txt
Content:
firebase-admin~=6.7.0
fastapi~=0.115.12
uvicorn~=0.34.0
pydantic~=2.11.1
python-dotenv~=1.1.0
python-jose[cryptography]~=3.4.0
python-multipart
email-validator
httpx
pytest~=8.3.5
pytest-asyncio
pytest-mock
pytest-cov

requests~=2.32.3
starlette~=0.46.1
protobuf~=5.29.4

================================================================================

Filename: routes/analytics_routes.py
Content:
from datetime import datetime

from fastapi import APIRouter, Depends, HTTPException, status  # import status

from schemas.analytics_schemas import (
    GameAnalyticsCreate,
    DailyStats,
    PlayerPerformance,
    GlobalStats,
    AnalyticsResponse
)
from schemas.auth_schemas import TokenData
from services.analytics_service import AnalyticsService
from utils.dependencies import get_current_user, get_analytics_service

router = APIRouter(prefix="/analytics", tags=["analytics"])


@router.post("/games/{game_id}", response_model=AnalyticsResponse)
async def record_game_analytics(
        game_id: str,
        game_data: GameAnalyticsCreate,
        current_user: TokenData = Depends(get_current_user),
        analytics_service: AnalyticsService = Depends(get_analytics_service)
):
    """Record analytics data for a completed game."""
    # Verify that the current user was a participant in the game
    if current_user.uid not in [game_data.white_player_id, game_data.black_player_id]:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN,
                            detail="Can only record analytics for games you participated in")

    # FIX: Use model_dump() instead of dict()
    game_dict = game_data.model_dump()
    # Add game_id from path parameter, as it might not be in the body schema required by FastAPI
    game_dict['game_id'] = game_id

    success = await analytics_service.record_game_analytics(game_dict)
    if not success:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to record game analytics")

    return AnalyticsResponse(
        status="success",
        message="Game analytics recorded successfully"
    )


@router.get("/daily/{date}", response_model=DailyStats)
async def get_daily_stats(
        date: datetime,  # FastAPI handles path param conversion
        current_user: TokenData = Depends(get_current_user),
        analytics_service: AnalyticsService = Depends(get_analytics_service)
):
    """Get aggregated statistics for a specific day."""
    # Add try-except block if service method can raise specific errors
    try:
        stats = await analytics_service.get_daily_stats(date)
        return stats
    except Exception as e:
        # Log the error e
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Error fetching daily statistics")


@router.get("/players/{user_id}/performance", response_model=PlayerPerformance)
async def get_player_performance(
        user_id: str,
        days: int = 30,
        current_user: TokenData = Depends(get_current_user),  # Auth needed to view performance?
        analytics_service: AnalyticsService = Depends(get_analytics_service)
):
    """Get detailed performance analytics for a player."""
    # Add try-except block
    try:
        performance = await analytics_service.get_player_performance(user_id, days)
        return performance
    except Exception as e:
        # Log the error e
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                            detail="Error fetching player performance")


@router.get("/global", response_model=GlobalStats)
async def get_global_stats(
        current_user: TokenData = Depends(get_current_user),  # Auth needed?
        analytics_service: AnalyticsService = Depends(get_analytics_service)
):
    """Get global game statistics."""
    # Add try-except block
    try:
        global_stats = await analytics_service.get_global_stats()
        return global_stats
    except Exception as e:
        # Log the error e
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                            detail="Error fetching global statistics")


================================================================================

Filename: routes/auth_routes.py
Content:
from fastapi import APIRouter, HTTPException, Depends
from firebase_admin import auth
from schemas.auth_schemas import FirebaseTokenRequest, TokenResponse, TokenData
from utils.jwt_utils import create_tokens_for_user, verify_token
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

router = APIRouter(prefix="/auth", tags=["authentication"])
security = HTTPBearer()


@router.post("/token", response_model=TokenResponse)
async def get_token(request: FirebaseTokenRequest):
    """Exchange Firebase token for backend JWT token."""
    try:
        # Verify Firebase token
        decoded_token = auth.verify_id_token(request.firebase_token)

        # Create our own JWT token
        tokens = create_tokens_for_user(decoded_token)
        return tokens
    except Exception as e:
        raise HTTPException(
            status_code=401,
            detail=f"Invalid Firebase token: {str(e)}",
            headers={"WWW-Authenticate": "Bearer"}
        )


@router.get("/verify", response_model=TokenData)
async def verify_access_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Verify the backend JWT token."""
    payload = verify_token(credentials.credentials)
    return TokenData(
        uid=payload["uid"],
        email=payload.get("email"),
        email_verified=payload.get("email_verified", False))


================================================================================

Filename: routes/friend_routes.py
Content:
from typing import List

from fastapi import APIRouter, Depends, HTTPException, status  # Import status

from models.friend import FriendRequest, FriendStatus
from schemas.auth_schemas import TokenData
from schemas.friend_schemas import (
    FriendRequestCreate,
    FriendResponse,
    FriendInteractionUpdate,
    FriendRequestAction
)
from services.friend_service import FriendService
from utils.dependencies import get_current_user, get_friend_service

router = APIRouter(prefix="/friends", tags=["friends"])


@router.post("/requests", response_model=FriendResponse)
async def send_friend_request(
        request: FriendRequestCreate,
        current_user: TokenData = Depends(get_current_user),
        friend_service: FriendService = Depends(get_friend_service)
):
    """Send a friend request to another user."""
    success = await friend_service.send_friend_request(
        sender_id=current_user.uid,
        receiver_id=request.receiver_id,
        message=request.message
    )
    # FIX: Return 409 Conflict if service layer failed (e.g., duplicate/already friends)
    if not success:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="Failed to send friend request (already friends or pending request exists)"
        )

    return FriendResponse(
        status="success",
        message="Friend request sent successfully"
    )


@router.get("/requests/pending", response_model=List[FriendRequest])
async def get_pending_requests(
        current_user: TokenData = Depends(get_current_user),
        friend_service: FriendService = Depends(get_friend_service)
):
    """Get all pending friend requests for the current user."""
    return await friend_service.get_pending_requests(current_user.uid)


@router.post("/requests/{request_id}/respond", response_model=FriendResponse)
async def respond_to_request(
        request_id: str,
        # Change the body parameter to use the new schema
        action: FriendRequestAction,
        current_user: TokenData = Depends(get_current_user),
        friend_service: FriendService = Depends(get_friend_service)
):
    """Accept or reject a friend request."""
    # ... (rest of the logic remains the same, use action.accept now)
    request_obj = await friend_service.get_friend_request(request_id)  # Renamed variable
    if not request_obj:
        raise HTTPException(status_code=404, detail="Friend request not found")

    if request_obj.receiver_id != current_user.uid:
        raise HTTPException(status_code=403, detail="Cannot respond to requests for other users")

    # Use action.accept here
    success = await friend_service.respond_to_request(request_id, action.accept)
    # Return 400 if service fails (e.g., request wasn't pending)
    if not success:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Failed to respond to friend request (e.g., request not pending or db error)"
        )
    return FriendResponse(
        status="success",
        message=f"Friend request {action.accept and 'accepted' or 'rejected'} successfully"
    )


@router.get("/list", response_model=List[FriendStatus])
async def get_friends(
        current_user: TokenData = Depends(get_current_user),
        friend_service: FriendService = Depends(get_friend_service)
):
    """Get all friends of the current user."""
    return await friend_service.get_friends(current_user.uid)


@router.delete("/{friend_id}", response_model=FriendResponse)
async def remove_friend(
        friend_id: str,
        current_user: TokenData = Depends(get_current_user),
        friend_service: FriendService = Depends(get_friend_service)
):
    """Remove a friend."""
    success = await friend_service.remove_friend(current_user.uid, friend_id)
    # Return 400 if service fails
    if not success:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Failed to remove friend (e.g., not friends or db error)"
        )
    return FriendResponse(
        status="success",
        message="Friend removed successfully"
    )


@router.post("/{friend_id}/interactions", response_model=FriendResponse)
async def update_friend_interaction(
        friend_id: str,
        interaction: FriendInteractionUpdate,
        current_user: TokenData = Depends(get_current_user),
        friend_service: FriendService = Depends(get_friend_service)
):
    """Update the last interaction with a friend."""
    success = await friend_service.update_last_interaction(
        current_user.uid,
        friend_id,
        interaction.game_id
    )
    # FIX: Route already raises 400 on failure, which is correct. Keep as is.
    if not success:
        raise HTTPException(status_code=400, detail="Failed to update interaction")
    return FriendResponse(
        status="success",
        message="Interaction updated successfully"
    )


================================================================================

Filename: routes/history_routes.py
Content:
from typing import List

from fastapi import APIRouter, Depends, HTTPException

from models.game_history import GameHistory
from schemas.auth_schemas import TokenData
from schemas.history_schemas import (
    GameHistoryParams,
    GamesBetweenPlayersParams,
    UserStatsParams,
    PopularOpeningsParams,
    GameHistoryResponse,
    UserGameStats,
    OpeningStats
)
from services.history_service import HistoryService
from utils.dependencies import get_current_user, get_history_service

router = APIRouter(prefix="/history", tags=["history"])


@router.post("/games", response_model=GameHistoryResponse)
async def archive_game(
        game: GameHistory,
        current_user: TokenData = Depends(get_current_user),
        history_service: HistoryService = Depends(get_history_service)
):
    """Archive a completed game."""
    # Verify that the current user was a participant in the game
    if current_user.uid not in [game.white_player_id, game.black_player_id]:
        raise HTTPException(status_code=403, detail="Can only archive games you participated in")
    success = await history_service.archive_game(game)
    return GameHistoryResponse(
        status="success" if success else "error",
        message="Game archived successfully" if success else "Failed to archive game"
    )


@router.get("/games/{game_id}", response_model=GameHistory)
async def get_game(
        game_id: str,
        current_user: TokenData = Depends(get_current_user),
        history_service: HistoryService = Depends(get_history_service)
):
    """Get a specific game by ID."""
    game = await history_service.get_game(game_id)
    if not game:
        raise HTTPException(status_code=404, detail="Game not found")
    return game


@router.get("/users/{user_id}/games", response_model=List[GameHistory])
async def get_user_games(
        user_id: str,
        params: GameHistoryParams = Depends(),
        current_user: TokenData = Depends(get_current_user),
        history_service: HistoryService = Depends(get_history_service)
):
    """Get recent games for a user."""
    return await history_service.get_user_games(user_id, params.limit)


@router.get("/games/between/{player1_id}/{player2_id}", response_model=List[GameHistory])
async def get_games_between_players(
        player1_id: str,
        player2_id: str,
        params: GamesBetweenPlayersParams = Depends(),
        current_user: TokenData = Depends(get_current_user),
        history_service: HistoryService = Depends(get_history_service)
):
    """Get recent games between two specific players."""
    return await history_service.get_games_between_players(player1_id, player2_id, params.limit)


@router.get("/users/{user_id}/stats", response_model=UserGameStats)
async def get_user_stats(
        user_id: str,
        params: UserStatsParams = Depends(),
        current_user: TokenData = Depends(get_current_user),
        history_service: HistoryService = Depends(get_history_service)
):
    """Get user's game statistics for a specific time period."""
    return await history_service.get_user_stats(user_id, params.days)


@router.get("/openings/popular", response_model=List[OpeningStats])
async def get_popular_openings(
        params: PopularOpeningsParams = Depends(),
        current_user: TokenData = Depends(get_current_user),
        history_service: HistoryService = Depends(get_history_service)
):
    """Get most popular opening moves from recent games."""
    return await history_service.get_popular_openings(params.limit)


================================================================================

Filename: routes/profile_routes.py
Content:
from typing import List

from fastapi import APIRouter, Depends, HTTPException, Path, status  # Import status

from models.user_profile import UserProfile
from schemas.auth_schemas import TokenData
from schemas.profile_schemas import (
    ProfileUpdate,
    ProfileResponse,
    LeaderboardParams,
    SearchProfilesParams
)
from services.profile_service import ProfileService
from utils.dependencies import get_current_user, get_profile_service

router = APIRouter(prefix="/profiles", tags=["profiles"])


@router.post("/", response_model=ProfileResponse,
             status_code=status.HTTP_201_CREATED)  # Use 201 for successful creation
async def create_profile(
        profile: UserProfile,
        current_user: TokenData = Depends(get_current_user),
        profile_service: ProfileService = Depends(get_profile_service)
):
    """Create a new user profile."""
    if profile.uid != current_user.uid:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot create profile for another user")

    # Check if profile already exists? BaseService.set will overwrite, maybe check first?
    existing_profile = await profile_service.get_profile(profile.uid)
    if existing_profile:
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="Profile already exists for this user")

    success = await profile_service.create_profile(profile)
    if not success:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                            detail="Failed to create profile in database")

    return ProfileResponse(
        status="success",
        message="Profile created successfully"
    )


@router.get("/{uid}", response_model=UserProfile)
async def get_profile(
        uid: str,
        current_user: TokenData = Depends(get_current_user),  # Keep auth for now, maybe public later?
        profile_service: ProfileService = Depends(get_profile_service)
):
    """Get a user profile by UID."""
    profile = await profile_service.get_profile(uid)
    if not profile:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Profile not found")
    return profile


@router.patch("/{uid}", response_model=ProfileResponse)
async def update_profile(
        uid: str,
        updates: ProfileUpdate,
        current_user: TokenData = Depends(get_current_user),
        profile_service: ProfileService = Depends(get_profile_service)
):
    """Update a user profile."""
    if uid != current_user.uid:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot update another user's profile")

    # FIX: Use model_dump() instead of dict()
    update_data = updates.model_dump(exclude_unset=True)
    if not update_data:  # Prevent empty updates if needed
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="No update data provided")

    success = await profile_service.update_profile(uid, update_data)
    if not success:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                            detail="Failed to update profile in database")

    return ProfileResponse(
        status="success",
        message="Profile updated successfully"
    )


@router.get("/search/{username_prefix}", response_model=List[UserProfile])
async def search_profiles(
        username_prefix: str,
        params: SearchProfilesParams = Depends(),
        current_user: TokenData = Depends(get_current_user),  # Auth needed?
        profile_service: ProfileService = Depends(get_profile_service)
):
    """Search for profiles by username prefix."""
    if not username_prefix or len(username_prefix) < 1:  # Add basic validation
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST,
                            detail="Username prefix must be at least 1 character")
    return await profile_service.search_profiles(username_prefix, params.limit)


@router.get("/leaderboard/top", response_model=List[UserProfile])
async def get_leaderboard(
        params: LeaderboardParams = Depends(),
        current_user: TokenData = Depends(get_current_user),  # Auth needed?
        profile_service: ProfileService = Depends(get_profile_service)
):
    """Get the top rated players."""
    return await profile_service.get_leaderboard(params.limit)


@router.post("/{uid}/achievements/{achievement_id}", response_model=ProfileResponse)
async def add_achievement(
        uid: str = Path(..., description="User ID"),
        achievement_id: str = Path(..., description="Achievement ID to add"),
        current_user: TokenData = Depends(get_current_user),
        profile_service: ProfileService = Depends(get_profile_service)
):
    """Add an achievement to a user's profile."""
    if uid != current_user.uid:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Cannot modify another user's achievements")

    # Consider validating achievement_id format or against a predefined list
    if not achievement_id:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Achievement ID cannot be empty")

    success = await profile_service.add_achievement(uid, achievement_id)
    if not success:
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to add achievement")

    return ProfileResponse(
        status="success",
        message="Achievement added successfully"
    )


================================================================================

Filename: run.sh
Content:
#!/bin/bash

# Exit on any error
set -e

# Convert Firebase config
config/convert.sh FIREBASE_CONFIG config/firebase_service_account.json

# Start the application using uvicorn
exec uvicorn main:app --host 0.0.0.0 --port "${PORT:-8080}"

================================================================================

Filename: schemas/analytics_schemas.py
Content:
from datetime import datetime
from typing import Dict, Any, Optional, List

from pydantic import BaseModel


class GameAnalyticsCreate(BaseModel):
    """Schema for creating game analytics."""
    game_id: str
    white_player_id: str
    black_player_id: str
    start_time: datetime
    end_time: datetime
    result: str
    moves: List[str]
    rating_change: Dict[str, int]
    game_type: str
    time_control: Dict[str, int]


class DailyStats(BaseModel):
    """Schema for daily statistics."""
    total_games: int
    average_duration: float
    average_moves: float
    white_wins: int
    black_wins: int
    draws: int
    abandoned: int
    game_types: Dict[str, int]
    time_controls: Dict[str, int]


class PlayerPerformance(BaseModel):
    """Schema for player performance statistics."""
    rating_progression: List[Dict[str, Any]]
    average_game_duration: float
    preferred_time_control: Optional[str]
    preferred_game_type: Optional[str]
    win_rate: float
    performance_by_color: Dict[str, Dict[str, int]]
    average_moves_per_game: float


class GlobalStats(BaseModel):
    """Schema for global game statistics."""
    total_games: int
    white_win_rate: float
    average_game_duration: float
    average_moves_per_game: float
    popular_time_controls: Dict[str, int]
    popular_game_types: Dict[str, int]
    last_updated: datetime


class AnalyticsResponse(BaseModel):
    """Schema for generic analytics operation response."""
    status: str
    message: Optional[str] = None


================================================================================

Filename: schemas/auth_schemas.py
Content:
from pydantic import BaseModel
from typing import Optional

class FirebaseTokenRequest(BaseModel):
    """Schema for Firebase token authentication request."""
    firebase_token: str

class TokenResponse(BaseModel):
    """Schema for token response."""
    access_token: str
    token_type: str
    expires_in: int

class TokenData(BaseModel):
    """Schema for JWT token payload."""
    uid: str
    email: Optional[str] = None
    email_verified: Optional[bool] = False 

================================================================================

Filename: schemas/friend_schemas.py
Content:
from typing import Optional

from pydantic import BaseModel


class FriendRequestCreate(BaseModel):
    """Schema for creating a friend request."""
    receiver_id: str
    message: Optional[str] = None


class FriendRequestResponse(BaseModel):
    """Schema for friend request response."""
    request_id: str
    accept: bool


class FriendResponse(BaseModel):
    """Schema for generic friend operation response."""
    status: str
    message: Optional[str] = None


class FriendInteractionUpdate(BaseModel):
    """Schema for updating friend interaction."""
    game_id: Optional[str] = None


class FriendRequestAction(BaseModel):
    """Schema for the body of the respond request."""
    accept: bool


================================================================================

Filename: schemas/history_schemas.py
Content:
from typing import Optional

from pydantic import BaseModel


class GameHistoryParams(BaseModel):
    """Schema for game history query parameters."""
    limit: int = 50
    days: Optional[int] = 30

class GamesBetweenPlayersParams(BaseModel):
    """Schema for querying games between players."""
    player1_id: str
    player2_id: str
    limit: int = 10

class UserStatsParams(BaseModel):
    """Schema for user stats query parameters."""
    user_id: str
    days: int = 30

class PopularOpeningsParams(BaseModel):
    """Schema for popular openings query parameters."""
    limit: int = 10

class GameHistoryResponse(BaseModel):
    """Schema for game history operation response."""
    status: str
    message: Optional[str] = None

class OpeningStats(BaseModel):
    """Schema for opening statistics."""
    moves: str
    count: int
    wins: int

class UserGameStats(BaseModel):
    """Schema for user game statistics."""
    total_games: int
    wins: int
    losses: int
    draws: int
    white_games: int
    black_games: int
    rating_change: int
    average_game_length: float
    total_moves: int 

================================================================================

Filename: schemas/profile_schemas.py
Content:
from pydantic import BaseModel
from typing import Dict, Any, Optional

class ProfileUpdate(BaseModel):
    """Schema for profile update request."""
    display_name: Optional[str] = None
    avatar_url: Optional[str] = None
    preferences: Optional[Dict[str, Any]] = None

class ProfileResponse(BaseModel):
    """Schema for generic profile operation response."""
    status: str
    message: Optional[str] = None

class LeaderboardParams(BaseModel):
    """Schema for leaderboard query parameters."""
    limit: int = 100

class SearchProfilesParams(BaseModel):
    """Schema for profile search parameters."""
    username_prefix: str
    limit: int = 10

class AchievementParams(BaseModel):
    """Schema for achievement parameters."""
    achievement_id: str 

================================================================================

Filename: services/analytics_service.py
Content:
from datetime import datetime, timedelta, timezone
from typing import Dict, Any

from firebase_admin import firestore

from models.game_history import GameResult
from .base_service import BaseService


class AnalyticsService(BaseService):
    def __init__(self, db: firestore.Client):
        super().__init__(db)
        self.collection = 'analytics'
        self.cache_collection = 'analytics_cache'

    async def record_game_analytics(self, game_data: Dict[str, Any]) -> bool:
        """Record analytics data for a completed game."""
        analytics_id = f"game_{game_data['game_id']}"
        analytics = {
            'timestamp': datetime.now(timezone.utc),
            'game_id': game_data['game_id'],
            'duration': (game_data['end_time'] - game_data['start_time']).total_seconds(),
            'total_moves': len(game_data['moves']),
            'result': game_data['result'],
            'white_player_id': game_data['white_player_id'],
            'black_player_id': game_data['black_player_id'],
            'rating_change': game_data['rating_change'],
            'game_type': game_data['game_type'],
            'time_control': game_data['time_control']
        }
        return await self.set_document(self.collection, analytics_id, analytics)

    async def get_daily_stats(self, date: datetime) -> Dict[str, Any]:
        """Get aggregated statistics for a specific day."""
        cache_key = f"daily_stats_{date.strftime('%Y-%m-%d')}"
        
        # Try to get from cache first
        cached_stats = await self.get_document(self.cache_collection, cache_key)
        if cached_stats:
            return cached_stats

        start_time = datetime.combine(date, datetime.min.time())
        end_time = start_time + timedelta(days=1)
        
        filters = [
            ('timestamp', '>=', start_time),
            ('timestamp', '<', end_time)
        ]
        
        games = await self.query_collection(self.collection, filters=filters)
        
        stats = {
            'total_games': len(games),
            'average_duration': 0,
            'average_moves': 0,
            'white_wins': 0,
            'black_wins': 0,
            'draws': 0,
            'abandoned': 0,
            'game_types': {},
            'time_controls': {}
        }
        
        total_duration = 0
        total_moves = 0
        
        for game in games:
            total_duration += game['duration']
            total_moves += game['total_moves']
            
            if game['result'] == GameResult.WHITE_WIN:
                stats['white_wins'] += 1
            elif game['result'] == GameResult.BLACK_WIN:
                stats['black_wins'] += 1
            elif game['result'] == GameResult.DRAW:
                stats['draws'] += 1
            else:
                stats['abandoned'] += 1
            
            # Count game types
            game_type = game['game_type']
            stats['game_types'][game_type] = stats['game_types'].get(game_type, 0) + 1
            
            # Count time controls
            time_control = f"{game['time_control']['initial']}/{game['time_control']['increment']}"
            stats['time_controls'][time_control] = stats['time_controls'].get(time_control, 0) + 1
        
        if stats['total_games'] > 0:
            stats['average_duration'] = total_duration / stats['total_games']
            stats['average_moves'] = total_moves / stats['total_games']
        
        # Cache the results
        await self.set_document(self.cache_collection, cache_key, stats)
        
        return stats

    async def get_player_performance(self, user_id: str, days: int = 30) -> Dict[str, Any]:
        """Get detailed performance analytics for a player."""
        start_date = datetime.now(timezone.utc) - timedelta(days=days)
        
        filters = [
            [('white_player_id', '==', user_id), ('timestamp', '>=', start_date)],
            [('black_player_id', '==', user_id), ('timestamp', '>=', start_date)]
        ]
        
        performance = {
            'rating_progression': [],
            'average_game_duration': 0,
            'preferred_time_control': None,
            'preferred_game_type': None,
            'win_rate': 0,
            'performance_by_color': {
                'white': {'games': 0, 'wins': 0},
                'black': {'games': 0, 'wins': 0}
            },
            'average_moves_per_game': 0
        }
        
        games = []
        for filter_set in filters:
            results = await self.query_collection(self.collection, filters=filter_set)
            games.extend(results)
        
        if not games:
            return performance
        
        # Sort games by timestamp
        games.sort(key=lambda x: x['timestamp'])
        
        total_duration = 0
        total_moves = 0
        time_controls = {}
        game_types = {}
        
        for game in games:
            # Track rating progression
            is_white = game['white_player_id'] == user_id
            rating_change = game['rating_change']['white' if is_white else 'black']
            performance['rating_progression'].append({
                'timestamp': game['timestamp'],
                'rating_change': rating_change
            })
            
            # Track color performance
            color = 'white' if is_white else 'black'
            performance['performance_by_color'][color]['games'] += 1
            if (is_white and game['result'] == GameResult.WHITE_WIN) or \
               (not is_white and game['result'] == GameResult.BLACK_WIN):
                performance['performance_by_color'][color]['wins'] += 1
            
            # Track time controls and game types
            time_control = f"{game['time_control']['initial']}/{game['time_control']['increment']}"
            time_controls[time_control] = time_controls.get(time_control, 0) + 1
            game_types[game['game_type']] = game_types.get(game['game_type'], 0) + 1
            
            total_duration += game['duration']
            total_moves += game['total_moves']
        
        # Calculate averages and preferences
        total_games = len(games)
        performance['average_game_duration'] = total_duration / total_games
        performance['average_moves_per_game'] = total_moves / total_games
        
        # Find preferred time control and game type
        performance['preferred_time_control'] = max(time_controls.items(), key=lambda x: x[1])[0]
        performance['preferred_game_type'] = max(game_types.items(), key=lambda x: x[1])[0]
        
        # Calculate overall win rate
        total_wins = sum(color['wins'] for color in performance['performance_by_color'].values())
        performance['win_rate'] = total_wins / total_games
        
        return performance

    async def get_global_stats(self) -> Dict[str, Any]:
        """Get global game statistics."""
        cache_key = 'global_stats'
        cached_stats = await self.get_document(self.cache_collection, cache_key)
        
        # Return cached stats if less than 1 hour old
        if cached_stats and \
           (datetime.now(timezone.utc) - cached_stats['last_updated']).total_seconds() < 3600:
            return cached_stats
        
        # Calculate new stats
        results = await self.query_collection(
            self.collection,
            order_by=('timestamp', 'DESCENDING'),
            limit=10000  # Get a good sample size
        )
        
        stats = {
            'total_games': len(results),
            'white_win_rate': 0,
            'average_game_duration': 0,
            'average_moves_per_game': 0,
            'popular_time_controls': {},
            'popular_game_types': {},
            'last_updated': datetime.now(timezone.utc)
        }
        
        if not results:
            return stats
        
        white_wins = 0
        total_duration = 0
        total_moves = 0
        
        for game in results:
            if game['result'] == GameResult.WHITE_WIN:
                white_wins += 1
            
            total_duration += game['duration']
            total_moves += game['total_moves']
            
            time_control = f"{game['time_control']['initial']}/{game['time_control']['increment']}"
            stats['popular_time_controls'][time_control] = \
                stats['popular_time_controls'].get(time_control, 0) + 1
            
            stats['popular_game_types'][game['game_type']] = \
                stats['popular_game_types'].get(game['game_type'], 0) + 1
        
        stats['white_win_rate'] = white_wins / stats['total_games']
        stats['average_game_duration'] = total_duration / stats['total_games']
        stats['average_moves_per_game'] = total_moves / stats['total_games']
        
        # Sort and limit popular lists
        stats['popular_time_controls'] = dict(
            sorted(stats['popular_time_controls'].items(), key=lambda x: x[1], reverse=True)[:5]
        )
        stats['popular_game_types'] = dict(
            sorted(stats['popular_game_types'].items(), key=lambda x: x[1], reverse=True)[:5]
        )
        
        # Cache the results
        await self.set_document(self.cache_collection, cache_key, stats)
        
        return stats


================================================================================

Filename: services/base_service.py
Content:
from typing import Optional, Any, Dict, List

from firebase_admin import auth
from google.cloud.firestore_v1 import FieldFilter, Query  # Keep for constants if needed
from google.cloud.firestore_v1.async_client import AsyncClient
from google.cloud.firestore_v1.async_query import AsyncQuery
from google.cloud.firestore_v1.base_document import BaseDocumentReference  # For type hint
from google.cloud.firestore_v1.types import WriteResult


class BaseService:
    def __init__(self, db: AsyncClient):  # Correct type hint
        self.db = db
        self._auth = auth  # auth is sync, okay here

    async def get_document(self, collection: str, doc_id: str) -> Optional[Dict[str, Any]]:
        """Retrieve a document from Firestore."""
        try:
            doc_ref: BaseDocumentReference = self.db.collection(collection).document(doc_id)
            # await the get() call
            doc = await doc_ref.get()
            return doc.to_dict() if doc.exists else None
        except Exception as e:
            print(f"Error getting document {collection}/{doc_id}: {e}")
            return None  # Return None on error

    async def set_document(self, collection: str, doc_id: str, data: Dict[str, Any]) -> bool:
        """Create or update a document in Firestore."""
        try:
            doc_ref: BaseDocumentReference = self.db.collection(collection).document(doc_id)
            # await the set() call
            _: WriteResult = await doc_ref.set(data)  # Result is not usually awaited
            return True
        except Exception as e:
            print(f"Error setting document {collection}/{doc_id}: {e}")
            return False  # Return False on error

    async def update_document(self, collection: str, doc_id: str, data: Dict[str, Any]) -> bool:
        """Update fields in a document."""
        try:
            doc_ref: BaseDocumentReference = self.db.collection(collection).document(doc_id)
            # await the update() call
            _: WriteResult = await doc_ref.update(data)  # Result is not usually awaited
            return True
        except Exception as e:
            print(f"Error updating document {collection}/{doc_id}: {e}")
            return False  # Return False on error

    async def delete_document(self, collection: str, doc_id: str) -> bool:
        """Delete a document from Firestore."""
        try:
            doc_ref: BaseDocumentReference = self.db.collection(collection).document(doc_id)
            # await the delete() call
            _: WriteResult = await doc_ref.delete()  # Result is not usually awaited
            return True
        except Exception as e:
            print(f"Error deleting document {collection}/{doc_id}: {e}")
            return False  # Return False on error

    async def query_collection(self, collection: str, filters: Optional[List[tuple]] = None,
                               order_by: Optional[tuple] = None, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """Query a collection with optional filters, ordering, and limit."""
        try:
            query: AsyncQuery = self.db.collection(collection)

            if filters:
                for field, op, value in filters:
                    # Use keyword filter= argument
                    query = query.where(filter=FieldFilter(field, op, value))

            if order_by:
                field, direction_str = order_by
                direction = Query.DESCENDING if direction_str == 'DESCENDING' else Query.ASCENDING
                query = query.order_by(field, direction=direction)

            if limit:
                query = query.limit(limit)

            # Use await query.get()
            docs_snapshot = await query.get()
            return [doc.to_dict() for doc in docs_snapshot if doc.exists]

        except Exception as e:
            print(f"Error querying collection {collection}: {e}")
            return []  # Return empty list on error

    # verify_token remains the same (it's synchronous)
    def verify_token(self, id_token: str) -> Optional[Dict[str, Any]]:
        """Verify Firebase ID token."""
        try:
            decoded_token = self._auth.verify_id_token(id_token)
            return decoded_token
        except Exception as e:
            print(f"Error verifying token: {e}")
            return None


================================================================================

Filename: services/friend_service.py
Content:
import uuid
from datetime import datetime, timezone
from typing import Optional, List

# Import necessary types for async Firestore
from google.cloud.firestore_v1.async_client import AsyncClient
from google.cloud.firestore_v1.async_query import AsyncQuery
from google.cloud.firestore_v1.transaction import Transaction # Correct import
from google.cloud.firestore_v1 import FieldFilter, Increment, ArrayUnion, async_transactional
# Keep models
from models.friend import FriendRequest, FriendStatus, FriendRequestStatus
from .base_service import BaseService


class FriendService(BaseService):
    def __init__(self, db: AsyncClient): # Use AsyncClient
        super().__init__(db)
        self.requests_collection = 'friend_requests'
        self.friends_collection = 'friend_status'

    async def send_friend_request(self, sender_id: str, receiver_id: str, message: Optional[str] = None) -> bool:
        if sender_id == receiver_id:
            print(f"Attempt to send friend request to self blocked: {sender_id}")
            return False

        status_key = f"{sender_id}_{receiver_id}"
        # Ensure get_document is awaited (fixed in BaseService)
        existing_friendship = await self.get_document(self.friends_collection, status_key)
        if existing_friendship:
            print(f"Users {sender_id} and {receiver_id} are already friends.")
            return False

        query1: AsyncQuery = self.db.collection(self.requests_collection).where(
            filter=FieldFilter('sender_id', '==', sender_id)
        ).where(
            filter=FieldFilter('receiver_id', '==', receiver_id)
        ).where(
            filter=FieldFilter('status', '==', FriendRequestStatus.PENDING.value)
        ).limit(1)

        query2: AsyncQuery = self.db.collection(self.requests_collection).where(
            filter=FieldFilter('sender_id', '==', receiver_id)
        ).where(
            filter=FieldFilter('receiver_id', '==', sender_id)
        ).where(
            filter=FieldFilter('status', '==', FriendRequestStatus.PENDING.value)
        ).limit(1)

        # Await query.get()
        existing_sent_docs = await query1.get()
        existing_received_docs = await query2.get()

        if existing_sent_docs or existing_received_docs:
            print(f"Pending friend request already exists between {sender_id} and {receiver_id}.")
            return False

        request = FriendRequest(
            request_id=f"req_{uuid.uuid4().hex}", # Add prefix for clarity
            sender_id=sender_id,
            receiver_id=receiver_id,
            message=message,
        )
        # Ensure set_document is awaited (fixed in BaseService)
        return await self.set_document(self.requests_collection, request.request_id,
                                       request.model_dump(mode='json'))

    async def get_friend_request(self, request_id: str) -> Optional[FriendRequest]:
        # Uses get_document (fixed in BaseService)
        data = await self.get_document(self.requests_collection, request_id)
        return FriendRequest(**data) if data else None

    async def get_pending_requests(self, user_id: str) -> List[FriendRequest]:
        query: AsyncQuery = self.db.collection(self.requests_collection).where(
            filter=FieldFilter('receiver_id', '==', user_id)
        ).where(
            filter=FieldFilter('status', '==', FriendRequestStatus.PENDING.value)
        )
        # Await query.get()
        results_docs = await query.get()
        return [FriendRequest(**doc.to_dict()) for doc in results_docs if doc.exists]

    async def respond_to_request(self, request_id: str, accept: bool) -> bool:
        # Await get_document (fixed in BaseService)
        request_data = await self.get_document(self.requests_collection, request_id)
        if not request_data:
            return False
        try:
            request = FriendRequest(**request_data)
        except Exception as e:
             print(f"Error parsing friend request data {request_id}: {e}")
             return False

        if request.status != FriendRequestStatus.PENDING:
            print(f"Request {request_id} is not pending, cannot respond.")
            return False

        status = FriendRequestStatus.ACCEPTED if accept else FriendRequestStatus.REJECTED
        # Await update_document (fixed in BaseService)
        update_success = await self.update_document(
            self.requests_collection,
            request_id,
            {'status': status.value, 'updated_at': datetime.now(timezone.utc)}
        )
        if not update_success:
             print(f"Failed to update request status for {request_id}")
             return False # Return early if update failed

        if accept:
            friend_status1 = FriendStatus(user_id=request.sender_id, friend_id=request.receiver_id)
            friend_status2 = FriendStatus(user_id=request.receiver_id, friend_id=request.sender_id)
            status_key1 = f"{request.sender_id}_{request.receiver_id}"
            status_key2 = f"{request.receiver_id}_{request.sender_id}"

            # Await set_document (fixed in BaseService)
            set1_success = await self.set_document(self.friends_collection, status_key1, friend_status1.model_dump(mode='json'))
            set2_success = await self.set_document(self.friends_collection, status_key2, friend_status2.model_dump(mode='json'))

            if not (set1_success and set2_success):
                print(f"Warning: Failed to create one or both friend status entries for request {request_id}")
                # Consider cleanup logic here (e.g., delete the one that succeeded)
                return False # Return False if setting friend status fails

        return True # Return True only if all steps succeeded

    async def get_friends(self, user_id: str) -> List[FriendStatus]:
        query: AsyncQuery = self.db.collection(self.friends_collection).where(
            filter=FieldFilter('user_id', '==', user_id)
        )
        # Await query.get()
        results_docs = await query.get()
        return [FriendStatus(**doc.to_dict()) for doc in results_docs if doc.exists]

    async def remove_friend(self, user_id: str, friend_id: str) -> bool:
        status_key1 = f"{user_id}_{friend_id}"
        status_key2 = f"{friend_id}_{user_id}"

        # Get Async Transaction object
        transaction: Transaction = self.db.transaction()
        doc_ref1 = self.db.collection(self.friends_collection).document(status_key1)
        doc_ref2 = self.db.collection(self.friends_collection).document(status_key2)

        @async_transactional
        async def delete_in_transaction(transaction: Transaction, ref1, ref2):
            # Transaction operations are sync within the decorated func
            transaction.delete(ref1)
            transaction.delete(ref2)

        try:
            # Await the execution of the transactional function
            await delete_in_transaction(transaction, doc_ref1, doc_ref2)
            print(f"Successfully removed friend in transaction: {user_id} <-> {friend_id}")
            return True
        except Exception as e:
            print(f"Error removing friend in transaction for {user_id}-{friend_id}: {e}")
            return False

    async def update_last_interaction(self, user_id: str, friend_id: str, game_id: Optional[str] = None) -> bool:
        status_key = f"{user_id}_{friend_id}"
        updates = {
            'last_interaction': datetime.now(timezone.utc),
            'games_played': Increment(1)
        }
        if game_id:
            updates['last_game'] = game_id

        # Await update_document (fixed in BaseService)
        return await self.update_document(self.friends_collection, status_key, updates)

================================================================================

Filename: services/history_service.py
Content:
from datetime import datetime, timedelta, timezone  # Use timezone
from typing import Optional, List, Dict, Any

from google.cloud import firestore

from models.game_history import GameHistory, GameResult
from .base_service import BaseService
from services.profile_service import ProfileService  # Import at class level

class HistoryService(BaseService):
    def __init__(self, db: firestore.AsyncClient):
        super().__init__(db)
        self.collection = 'game_history'

    async def archive_game(self, game: GameHistory) -> bool:
        """Archive a completed game."""
        # FIX: Use model_dump() instead of dict()
        success = await self.set_document(self.collection, game.game_id, game.model_dump())
        
        # If game was successfully archived, update player profiles
        if success:
            # Create profile service
            profile_service = ProfileService(self.db)
            
            # Fetch current player profiles to get accurate ratings
            white_profile = await profile_service.get_profile(game.white_player_id)
            black_profile = await profile_service.get_profile(game.black_player_id)
            
            # Use current ratings from profiles if available, otherwise use game data
            white_current_rating = white_profile.rating if white_profile else game.white_rating
            black_current_rating = black_profile.rating if black_profile else game.black_rating
            
            # Calculate new ratings with rating changes
            white_new_rating = white_current_rating + game.rating_change.get('white', 0)
            black_new_rating = black_current_rating + game.rating_change.get('black', 0)
            
            # Update white player profile
            white_result = {'result': 'win' if game.result == GameResult.WHITE_WIN else 
                                     'loss' if game.result == GameResult.BLACK_WIN else 'draw'}
            await profile_service.update_rating(
                game.white_player_id, 
                white_new_rating, 
                white_result
            )
            
            # Update black player profile
            black_result = {'result': 'win' if game.result == GameResult.BLACK_WIN else 
                                     'loss' if game.result == GameResult.WHITE_WIN else 'draw'}
            await profile_service.update_rating(
                game.black_player_id, 
                black_new_rating, 
                black_result
            )
        
        return success

    async def get_game(self, game_id: str) -> Optional[GameHistory]:
        """Retrieve a specific game by ID."""
        data = await self.get_document(self.collection, game_id)
        return GameHistory(**data) if data else None

    async def get_user_games(self, user_id: str, limit: int = 50) -> List[GameHistory]:
        """Get recent games for a user."""
        # BaseService query needs adjustment for OR logic simulation or use two queries
        # Assuming BaseService query is adapted or this method runs two queries
        # If using BaseService's current implementation, it might only query one field.
        # Let's assume the service logic ORs the results from two queries if necessary.

        # Query for games where user is white
        filters_white = [('white_player_id', '==', user_id)]
        white_games_data = await self.query_collection(
            self.collection,
            filters=filters_white,
            order_by=('end_time', 'DESCENDING'),
            limit=limit  # Apply limit here too, although final sort/limit is better
        )

        # Query for games where user is black
        filters_black = [('black_player_id', '==', user_id)]
        black_games_data = await self.query_collection(
            self.collection,
            filters=filters_black,
            order_by=('end_time', 'DESCENDING'),
            limit=limit
        )

        # Combine, remove duplicates (if any, though unlikely with unique IDs), sort, and limit
        all_games_data = {game['game_id']: game for game in white_games_data + black_games_data}
        sorted_games = sorted(all_games_data.values(), key=lambda x: x['end_time'], reverse=True)

        return [GameHistory(**data) for data in sorted_games[:limit]]

    async def get_games_between_players(self, player1_id: str, player2_id: str, limit: int = 10) -> List[GameHistory]:
        """Get recent games between two specific players."""
        # Query for player1 as white, player2 as black
        filters1 = [('white_player_id', '==', player1_id), ('black_player_id', '==', player2_id)]
        games1_data = await self.query_collection(
            self.collection,
            filters=filters1,
            order_by=('end_time', 'DESCENDING'),
            limit=limit
        )

        # Query for player2 as white, player1 as black
        filters2 = [('white_player_id', '==', player2_id), ('black_player_id', '==', player1_id)]
        games2_data = await self.query_collection(
            self.collection,
            filters=filters2,
            order_by=('end_time', 'DESCENDING'),
            limit=limit
        )

        # Combine, sort by end_time descending, and take the top 'limit' results
        all_games_data = {game['game_id']: game for game in games1_data + games2_data}
        sorted_games = sorted(all_games_data.values(), key=lambda x: x['end_time'], reverse=True)

        return [GameHistory(**data) for data in sorted_games[:limit]]

    async def get_user_stats(self, user_id: str, days: int = 30) -> Dict[str, Any]:
        """Get user's game statistics for a specific time period."""
        # FIX: Use timezone.utc
        start_date = datetime.now(timezone.utc) - timedelta(days=days)

        # Combine filters for BaseService or run two queries as above
        # Running two queries for clarity:
        filters_white = [('white_player_id', '==', user_id), ('end_time', '>=', start_date)]
        white_games = await self.query_collection(self.collection, filters=filters_white)

        filters_black = [('black_player_id', '==', user_id), ('end_time', '>=', start_date)]
        black_games = await self.query_collection(self.collection, filters=filters_black)

        all_user_games_data = {game['game_id']: game for game in white_games + black_games}

        stats = {
            'total_games': 0, 'wins': 0, 'losses': 0, 'draws': 0,
            'white_games': 0, 'black_games': 0, 'rating_change': 0,
            'average_game_length': 0, 'total_moves': 0
        }
        total_duration = 0

        for game_data in all_user_games_data.values():
            try:
                game = GameHistory(**game_data)
                stats['total_games'] += 1

                is_white = game.white_player_id == user_id
                if is_white:
                    stats['white_games'] += 1
                    stats['rating_change'] += game.rating_change.get('white', 0)  # Use .get for safety
                else:
                    stats['black_games'] += 1
                    stats['rating_change'] += game.rating_change.get('black', 0)  # Use .get for safety

                if game.result == GameResult.WHITE_WIN:
                    if is_white:
                        stats['wins'] += 1
                    else:
                        stats['losses'] += 1
                elif game.result == GameResult.BLACK_WIN:
                    if not is_white:
                        stats['wins'] += 1
                    else:
                        stats['losses'] += 1
                elif game.result == GameResult.DRAW:
                    stats['draws'] += 1

                stats['total_moves'] += len(game.moves)
                # Ensure end_time and start_time are datetime objects
                end_time = game.end_time if isinstance(game.end_time, datetime) else datetime.fromisoformat(
                    str(game.end_time))
                start_time = game.start_time if isinstance(game.start_time, datetime) else datetime.fromisoformat(
                    str(game.start_time))
                total_duration += (end_time - start_time).total_seconds()
            except Exception as e:
                print(f"Warning: Skipping game data due to parsing error: {game_data.get('game_id')}, Error: {e}")
                continue  # Skip problematic game data

        if stats['total_games'] > 0:
            stats['average_game_length'] = total_duration / stats['total_games']

        return stats

    async def get_popular_openings(self, limit: int = 10) -> List[Dict[str, Any]]:
        """Get most popular opening moves from recent games."""
        # Consider adding a date filter here for performance (e.g., last 30 days)
        results = await self.query_collection(
            self.collection,
            order_by=('end_time', 'DESCENDING'),
            limit=1000  # Sample size limit
        )

        openings = {}
        for game_data in results:
            try:
                # Ensure data is parsed into the model
                game = GameHistory(**game_data)
                if len(game.moves) >= 3:  # Consider first 3 moves as opening
                    opening_key = ' '.join(game.moves[:3])
                    if opening_key not in openings:
                        openings[opening_key] = {'count': 0, 'wins': 0}  # Initialize wins
                    openings[opening_key]['count'] += 1

                    # FIX: Correctly count wins based on result, regardless of winner_id presence
                    # Count decisive wins (not draws or abandoned)
                    if game.result == GameResult.WHITE_WIN or game.result == GameResult.BLACK_WIN:
                        openings[opening_key]['wins'] += 1

            except Exception as e:
                print(
                    f"Warning: Skipping game data in opening stats due to parsing error: "
                    f"{game_data.get('game_id')}, Error: {e}")
                continue

        # Sort by popularity
        popular_openings = sorted(
            [{'moves': k, **v} for k, v in openings.items()],
            key=lambda x: x['count'],
            reverse=True
        )

        return popular_openings[:limit]


================================================================================

Filename: services/profile_service.py
Content:
from datetime import datetime, timezone  # Use timezone
from typing import Optional, Dict, Any, List

from firebase_admin import firestore
from google.cloud import firestore
from models.user_profile import UserProfile
from .base_service import BaseService


class ProfileService(BaseService):
    def __init__(self, db: firestore.AsyncClient):
        super().__init__(db)
        self.collection = 'user_profiles'

    async def create_profile(self, profile: UserProfile) -> bool:
        """Create a new user profile."""
        # FIX: Use model_dump() instead of dict()
        return await self.set_document(self.collection, profile.uid, profile.model_dump())

    async def get_profile(self, uid: str) -> Optional[UserProfile]:
        """Retrieve a user profile by UID."""
        data = await self.get_document(self.collection, uid)
        return UserProfile(**data) if data else None

    async def update_profile(self, uid: str, updates: Dict[str, Any]) -> bool:
        """Update specific fields in a user profile."""
        # FIX: Use timezone.utc
        updates['last_active'] = datetime.now(timezone.utc)
        return await self.update_document(self.collection, uid, updates)

    async def update_rating(self, uid: str, new_rating: int, game_result: Dict[str, Any]) -> bool:
        """Update user's rating and game statistics."""
        updates = {
            'rating': new_rating,
            'games_played': firestore.Increment(1),
        }

        if game_result['result'] == 'win':
            updates['wins'] = firestore.Increment(1)
        elif game_result['result'] == 'loss':
            updates['losses'] = firestore.Increment(1)
        else:
            updates['draws'] = firestore.Increment(1)

        return await self.update_document(self.collection, uid, updates)

    async def search_profiles(self, username_prefix: str, limit: int = 10) -> List[UserProfile]:
        """Search for profiles by username prefix."""
        filters = [
            ('username', '>=', username_prefix),
            ('username', '<=', username_prefix + '\uf8ff')
        ]
        results = await self.query_collection(
            self.collection,
            filters=filters,
            order_by=('username', 'ASCENDING'),
            limit=limit
        )
        return [UserProfile(**data) for data in results]

    async def get_leaderboard(self, limit: int = 100) -> List[UserProfile]:
        """Get top rated players."""
        results = await self.query_collection(
            self.collection,
            order_by=('rating', 'DESCENDING'),
            limit=limit
        )
        return [UserProfile(**data) for data in results]

    async def add_achievement(self, uid: str, achievement_id: str) -> bool:
        """Add an achievement to user's profile."""
        # Use ArrayUnion from google.cloud.firestore_v1, not firebase_admin.firestore
        from google.cloud.firestore_v1 import ArrayUnion
        return await self.update_document(
            self.collection,
            uid,
            {'achievements': ArrayUnion([achievement_id])}
        )


================================================================================

Filename: tests/api_blackbox/test_b_analytics_flow.py
Content:
# Filename: tests/api_blackbox/test_b_analytics_flow.py

import os
import uuid
from datetime import datetime, timezone, timedelta

import pytest
import requests

# --- Test Configuration ---
BASE_URL = os.getenv("TEST_BASE_URL", "http://localhost:8080").rstrip('/')
API_DELAY = float(os.getenv("TEST_API_DELAY", "0.5"))

# !!! IMPORTANT: Requires valid token/UID for at least one user !!!
USER1_TOKEN = os.getenv("TEST_USER1_BACKEND_TOKEN")
USER1_UID = os.getenv("TEST_USER1_UID")
# Optional: Use a second user's UID if available
USER2_UID = os.getenv("TEST_USER2_UID", f"opponent-uid-{uuid.uuid4().hex[:6]}")  # Default to generated opponent

config_present = USER1_TOKEN and USER1_UID
if not config_present:
    print(
        "\nWARNING: Missing environment variables for analytics flow tests (TEST_USER1_BACKEND_TOKEN, "
        "TEST_USER1_UID). Tests will be skipped.")


# --- Helper ---
def get_auth_headers(token):
    return {"Authorization": f"Bearer {token}"} if token else {}


# --- Global state for the flow ---
recorded_game_ids = []  # Store IDs of games whose analytics were recorded


# --- Test Cases ---

@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_record_game_analytics_valid():
    """Tests recording analytics for a valid game where the user participated."""
    headers = get_auth_headers(USER1_TOKEN)
    game_id = f"bb_ana_{uuid.uuid4().hex}"
    now = datetime.now(timezone.utc)
    # Payload should match the GameAnalyticsCreate schema
    analytics_payload = {
        "game_id": game_id,  # Make sure schema matches this (or if it's only path param)
        "white_player_id": USER1_UID,  # Authenticated user is white
        "black_player_id": USER2_UID,
        "start_time": (now - timedelta(minutes=10)).isoformat(),
        "end_time": now.isoformat(),
        "result": "black_win",  # Match GameResult enum values
        "moves": ["d4", "Nf6", "c4", "g6", "Nc3", "Bg7", "e4", "d6"],  # King's Indian start
        "rating_change": {"white": -7, "black": 7},  # Schema expects dict, e.g. {"white": -7, "black": 7} or similar
        "game_type": "portal_gambit",
        "time_control": {"initial": 300, "increment": 3}  # Schema expects dict, e.g. {"initial": 300, "increment": 3}
    }

    # Route: POST /analytics/games/{game_id}
    response = requests.post(f"{BASE_URL}/analytics/games/{game_id}", headers=headers, json=analytics_payload)
    assert response.status_code == 200, f"Record analytics failed: {response.text}"
    data = response.json()
    # Response should match AnalyticsResponse schema
    assert data.get("status") == "success"
    assert "recorded successfully" in data.get("message", "")
    recorded_game_ids.append(game_id)
    print(f"\nRecorded analytics for game ID: {game_id}")


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_daily_stats():
    """Tests retrieving daily statistics for today."""
    headers = get_auth_headers(USER1_TOKEN)
    # Use today's date in the required format (likely ISO 8601 for the path param)
    # The route expects a datetime, requests needs a string. FastAPI handles parsing.
    # Sending just the date part might work depending on route implementation.
    # Let's try sending a full ISO timestamp for today.
    today_iso = datetime.now(timezone.utc).isoformat()

    # Route: GET /analytics/daily/{date}
    response = requests.get(f"{BASE_URL}/analytics/daily/{today_iso}", headers=headers)
    assert response.status_code == 200, f"Get daily stats failed: {response.text}"
    stats = response.json()

    # Check structure based on DailyStats schema
    assert "total_games" in stats
    assert isinstance(stats["total_games"], int)
    assert stats["total_games"] >= 0  # Should have at least the game recorded above if run today
    assert "average_duration" in stats
    assert isinstance(stats["average_duration"], (float, int))
    assert "average_moves" in stats
    assert isinstance(stats["average_moves"], (float, int))
    assert "white_wins" in stats
    assert "black_wins" in stats
    assert "draws" in stats
    assert "abandoned" in stats
    assert "game_types" in stats
    assert isinstance(stats["game_types"], dict)
    assert "time_controls" in stats
    assert isinstance(stats["time_controls"], dict)

    # If the test game was recorded today, check for its contribution
    # (This is fragile as other games might exist)
    # if recorded_game_ids and datetime.fromisoformat(today_iso).date() == datetime.now(timezone.utc).date():
    #    assert stats["total_games"] > 0
    #    assert "portal_gambit" in stats["game_types"]
    #    assert stats["game_types"]["portal_gambit"] > 0


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_player_performance_self():
    """Tests retrieving performance statistics for the authenticated user."""
    headers = get_auth_headers(USER1_TOKEN)
    user_id = USER1_UID
    days = 30

    # Route: GET /analytics/players/{user_id}/performance
    response = requests.get(f"{BASE_URL}/analytics/players/{user_id}/performance?days={days}", headers=headers)
    assert response.status_code == 200, f"Get player performance failed: {response.text}"
    perf = response.json()

    # Check structure based on PlayerPerformance schema
    assert "rating_progression" in perf
    assert isinstance(perf["rating_progression"], list)
    assert "average_game_duration" in perf
    assert isinstance(perf["average_game_duration"], (float, int))
    # Preferred fields can be None if no games played
    assert "preferred_time_control" in perf
    assert "preferred_game_type" in perf
    assert "win_rate" in perf
    assert isinstance(perf["win_rate"], (float, int))
    assert "performance_by_color" in perf
    assert isinstance(perf["performance_by_color"], dict)
    assert "white" in perf["performance_by_color"]
    assert "black" in perf["performance_by_color"]
    assert "games" in perf["performance_by_color"]["white"]
    assert "wins" in perf["performance_by_color"]["white"]
    assert "average_moves_per_game" in perf
    assert isinstance(perf["average_moves_per_game"], (float, int))

    # If game recorded, check rating progression might have entries
    # if recorded_game_ids and len(perf["rating_progression"]) > 0:
    #    assert "timestamp" in perf["rating_progression"][0]
    #    assert "rating_change" in perf["rating_progression"][0]


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_player_performance_other():
    """Tests retrieving performance statistics for another user (allowed)."""
    headers = get_auth_headers(USER1_TOKEN)
    user_id = USER2_UID  # Get stats for the opponent
    days = 60

    response = requests.get(f"{BASE_URL}/analytics/players/{user_id}/performance?days={days}", headers=headers)
    assert response.status_code == 200
    # Check structure again, data will be for USER2_UID
    perf = response.json()
    assert "rating_progression" in perf
    assert "win_rate" in perf


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_global_stats():
    """Tests retrieving global game statistics."""
    headers = get_auth_headers(USER1_TOKEN)

    # Route: GET /analytics/global
    response = requests.get(f"{BASE_URL}/analytics/global", headers=headers)
    assert response.status_code == 200, f"Get global stats failed: {response.text}"
    stats = response.json()

    # Check structure based on GlobalStats schema
    assert "total_games" in stats
    assert isinstance(stats["total_games"], int)
    assert stats["total_games"] >= 0  # Should have at least one if tests run
    assert "white_win_rate" in stats
    assert isinstance(stats["white_win_rate"], (float, int))
    assert "average_game_duration" in stats
    assert isinstance(stats["average_game_duration"], (float, int))
    assert "average_moves_per_game" in stats
    assert isinstance(stats["average_moves_per_game"], (float, int))
    assert "popular_time_controls" in stats
    assert isinstance(stats["popular_time_controls"], dict)
    assert "popular_game_types" in stats
    assert isinstance(stats["popular_game_types"], dict)
    assert "last_updated" in stats  # Should be an ISO datetime string


# --- Negative Test Cases ---

@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_record_game_analytics_forbidden():
    """Tests recording analytics for a game the user did NOT participate in."""
    headers = get_auth_headers(USER1_TOKEN)
    game_id = f"bb_ana_forbidden_{uuid.uuid4().hex}"
    now = datetime.now(timezone.utc)
    analytics_payload = {
        "game_id": game_id,
        "white_player_id": f"other-a-{uuid.uuid4().hex[:4]}",  # Not USER1_UID
        "black_player_id": f"other-b-{uuid.uuid4().hex[:4]}",  # Not USER1_UID
        "start_time": (now - timedelta(minutes=8)).isoformat(),
        "end_time": now.isoformat(),
        "result": "draw",
        "moves": ["Nf3", "Nf6"],
        "rating_change": {"white": 0, "black": 0},
        "game_type": "standard",
        "time_control": {"initial": 60, "increment": 0}
    }
    response = requests.post(f"{BASE_URL}/analytics/games/{game_id}", headers=headers, json=analytics_payload)
    assert response.status_code == 403  # Forbidden


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_record_game_analytics_missing_data():
    """Tests recording analytics with missing required fields."""
    headers = get_auth_headers(USER1_TOKEN)
    game_id = f"bb_ana_invalid_{uuid.uuid4().hex}"
    analytics_payload = {
        "game_id": game_id,
        "white_player_id": USER1_UID,
        # Missing black_player_id, result, times, moves etc.
    }
    response = requests.post(f"{BASE_URL}/analytics/games/{game_id}", headers=headers, json=analytics_payload)
    assert response.status_code == 422  # Unprocessable Entity


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_daily_stats_invalid_date():
    """Tests retrieving daily stats with an invalid date format."""
    headers = get_auth_headers(USER1_TOKEN)
    invalid_date_str = "27th-October-2023"
    response = requests.get(f"{BASE_URL}/analytics/daily/{invalid_date_str}", headers=headers)
    assert response.status_code == 422  # Unprocessable Entity due to path param validation


================================================================================

Filename: tests/api_blackbox/test_b_auth_flow.py
Content:
# Filename: tests/api_blackbox/test_b_auth_flow.py

import os

import pytest
import requests

# --- Test Configuration ---
BASE_URL = os.getenv("TEST_BASE_URL", "http://localhost:8080").rstrip('/')
# Seconds to wait for potential eventual consistency if needed
API_DELAY = float(os.getenv("TEST_API_DELAY", "0.5"))

# !!! IMPORTANT: Obtain REAL tokens for these environment variables !!!
# 1. Get a Firebase ID Token for a test user (e.g., via Firebase Auth client SDK)
VALID_FIREBASE_ID_TOKEN = os.getenv("TEST_FIREBASE_ID_TOKEN")
# 2. Set the expected UID for the user associated with the Firebase token
EXPECTED_UID_FROM_FIREBASE_TOKEN = os.getenv("TEST_FIREBASE_UID")

# Store the backend token obtained during the test
backend_access_token = None


# --- Helper Functions ---
def get_auth_headers(token):
    """Creates authorization headers if a token is provided."""
    return {"Authorization": f"Bearer {token}"} if token else {}


# --- Test Cases ---

def test_api_ping_root():
    """Tests the root endpoint, which should be public."""
    response = requests.get(f"{BASE_URL}/")
    assert response.status_code == 200
    data = response.json()
    assert data["name"] == "Portal Gambit Backend API"
    assert data["status"] == "running"


def test_api_access_protected_route_no_token():
    """Tests accessing a protected route without any token."""
    # Using /profiles/some-uid as an example protected route
    response = requests.get(f"{BASE_URL}/profiles/some-uid")
    # Expect 401 (Unauthorized) or 403 (Forbidden) depending on FastAPI/middleware setup
    # FastAPI's default for missing HTTPBearer is 403, but our middleware might raise 401
    assert response.status_code in [401, 403]


def test_api_access_protected_route_invalid_token():
    """Tests accessing a protected route with an invalid/malformed token."""
    headers = get_auth_headers("invalid.jwt.token")
    response = requests.get(f"{BASE_URL}/profiles/some-uid", headers=headers)
    assert response.status_code == 401  # Expect 401 due to JWT validation failure
    assert "WWW-Authenticate" in response.headers  # Should indicate Bearer scheme


# --- /auth/token Endpoint Tests ---

@pytest.mark.skipif(not VALID_FIREBASE_ID_TOKEN, reason="Requires TEST_FIREBASE_ID_TOKEN environment variable")
def test_api_get_token_valid_firebase():
    """
    Tests exchanging a valid Firebase ID token for backend access token.
    This is the crucial step to get the token for other tests.
    """
    global backend_access_token
    payload = {"firebase_token": VALID_FIREBASE_ID_TOKEN}
    response = requests.post(f"{BASE_URL}/auth/token", json=payload)

    assert response.status_code == 200, f"Request failed: {response.text}"
    data = response.json()
    assert "access_token" in data
    assert isinstance(data["access_token"], str)
    assert len(data["access_token"]) > 50  # Basic sanity check
    assert data["token_type"].lower() == "bearer"
    assert "expires_in" in data
    assert isinstance(data["expires_in"], int)
    assert data["expires_in"] > 0

    # Store the obtained token for subsequent verification test
    backend_access_token = data["access_token"]
    print(f"\nSuccessfully obtained backend token: {backend_access_token[:10]}...")  # Log snippet


def test_api_get_token_invalid_firebase_token():
    """Tests using an invalid Firebase token."""
    payload = {"firebase_token": "this-is-not-a-valid-firebase-token"}
    response = requests.post(f"{BASE_URL}/auth/token", json=payload)
    assert response.status_code == 401
    assert "Invalid Firebase token" in response.json().get("detail", "")


def test_api_get_token_missing_firebase_token():
    """Tests calling the endpoint without the firebase_token field."""
    payload = {}  # Missing required field
    response = requests.post(f"{BASE_URL}/auth/token", json=payload)
    assert response.status_code == 422  # Unprocessable Entity (Validation Error)


def test_api_get_token_wrong_field_name():
    """Tests calling the endpoint with a misspelled field."""
    payload = {"firebaseToken": VALID_FIREBASE_ID_TOKEN or "placeholder"}
    response = requests.post(f"{BASE_URL}/auth/token", json=payload)
    assert response.status_code == 422  # Unprocessable Entity


# --- /auth/verify Endpoint Tests ---

@pytest.mark.skipif(not backend_access_token or not EXPECTED_UID_FROM_FIREBASE_TOKEN,
                    reason="Requires backend token from test_api_get_token_valid_firebase and TEST_FIREBASE_UID")
def test_api_verify_valid_backend_token():
    """
    Tests verifying the backend token obtained from /auth/token.
    Relies on test_api_get_token_valid_firebase having run successfully.
    """
    assert backend_access_token is not None, "Backend token was not obtained in previous step"
    headers = get_auth_headers(backend_access_token)
    response = requests.get(f"{BASE_URL}/auth/verify", headers=headers)

    assert response.status_code == 200, f"Verification failed: {response.text}"
    data = response.json()
    assert "uid" in data
    assert data["uid"] == EXPECTED_UID_FROM_FIREBASE_TOKEN  # Verify UID matches expectation
    assert "email" in data  # Based on TokenData schema
    assert "email_verified" in data


def test_api_verify_invalid_backend_token():
    """Tests verifying an invalid/malformed backend token."""
    headers = get_auth_headers("clearly-invalid-backend-token")
    response = requests.get(f"{BASE_URL}/auth/verify", headers=headers)
    assert response.status_code == 401
    assert "Could not validate credentials" in response.json().get("detail", "")
    assert "WWW-Authenticate" in response.headers


def test_api_verify_missing_token():
    """Tests calling /auth/verify without an Authorization header."""
    response = requests.get(f"{BASE_URL}/auth/verify")
    # As noted before, expect 403 from FastAPI default or 401 from middleware
    assert response.status_code in [401, 403]

# --- Optional: Test with expired token (Harder in Black Box) ---
# def test_api_verify_expired_backend_token():
#    # 1. Obtain a token using test_api_get_token_valid_firebase
#    # 2. Wait for longer than the token's expiry time (e.g., ACCESS_TOKEN_EXPIRE_MINUTES)
#    # 3. Call /auth/verify with the expired token
#    # 4. Assert status code is 401 and detail indicates expiration
#    pass # This test takes a long time, often skipped or handled in white-box


================================================================================

Filename: tests/api_blackbox/test_b_friend_flow.py
Content:
import os
import time
import uuid

import pytest
import requests

# --- Test Configuration ---
BASE_URL = os.getenv("TEST_BASE_URL", "http://localhost:8080").rstrip('/')
# Increased delay slightly to potentially help with consistency issues
API_DELAY = float(os.getenv("TEST_API_DELAY", "1.5"))

USER1_TOKEN = os.getenv("TEST_USER1_BACKEND_TOKEN")
USER1_UID = os.getenv("TEST_USER1_UID")
USER2_TOKEN = os.getenv("TEST_USER2_BACKEND_TOKEN")
USER2_UID = os.getenv("TEST_USER2_UID")

config_present = USER1_TOKEN and USER1_UID and USER2_TOKEN and USER2_UID
if not config_present:
    print(
        "\nWARNING: Missing environment variables for friend flow tests (TEST_USER1/2_BACKEND_TOKEN, "
        "TEST_USER1/2_UID). Tests will be skipped.")


def get_auth_headers(token):
    return {"Authorization": f"Bearer {token}"} if token else {}


pending_request_id = None  # Keep track of request ID across tests


def poll_for_condition(check_function, expected_value, max_attempts=5, delay=1.0):
    """
    Polls a check_function until it returns the expected_value or times out.

    Args:
        check_function: A callable that performs the check and returns a value.
        expected_value: The value we expect check_function to return.
        max_attempts: Maximum number of times to try.
        delay: Seconds to wait between attempts.

    Returns:
        True if the condition was met within max_attempts, False otherwise.
    """
    for attempt in range(max_attempts):
        try:
            result = check_function()
            if result == expected_value:
                print(f"Polling successful on attempt {attempt + 1}.")
                return True
        except Exception as e:
            print(f"Polling check function raised an exception: {e}")
            # Decide if you want to retry on exceptions or fail immediately
            # For now, we'll just print and continue polling

        # Avoid printing the last "waiting" message if it's the final attempt
        if attempt < max_attempts - 1:
            print(f"Polling attempt {attempt + 1}/{max_attempts} failed, waiting {delay}s...")
            time.sleep(delay)
        else:
            print(f"Polling failed on final attempt {attempt + 1}/{max_attempts}.")

    return False


# Fixture to clean up *after* tests run
@pytest.fixture(scope="module", autouse=True)
def cleanup_friendship():
    yield  # Run tests first
    if not config_present:
        return
    print("\n--- Post-module Cleanup: Removing Friend State ---")
    headers1 = get_auth_headers(USER1_TOKEN)
    headers2 = get_auth_headers(USER2_TOKEN)

    # Attempt to reject any pending requests from User1 to User2 first
    try:
        pending_resp = requests.get(f"{BASE_URL}/friends/requests/pending", headers=headers2)
        if pending_resp.status_code == 200:
            pending_reqs = pending_resp.json()
            for req in pending_reqs:
                if req.get("sender_id") == USER1_UID:
                    req_id = req["request_id"]
                    print(f"Cleanup: User2 rejecting pending request {req_id} from User1...")
                    reject_resp = requests.post(f"{BASE_URL}/friends/requests/{req_id}/respond", headers=headers2,
                                                json={"accept": False})
                    print(f"  Reject response status: {reject_resp.status_code}")
                    time.sleep(0.2)  # Small delay between actions
    except Exception as e:
        print(f"Cleanup Warning: Error checking/rejecting pending requests: {e}")

    # Remove friendship status
    remove_resp1 = requests.delete(f"{BASE_URL}/friends/{USER2_UID}", headers=headers1)
    print(f"Cleanup: User1 remove User2 -> Status {remove_resp1.status_code}")
    time.sleep(0.2)
    remove_resp2 = requests.delete(f"{BASE_URL}/friends/{USER1_UID}", headers=headers2)
    print(f"Cleanup: User2 remove User1 -> Status {remove_resp2.status_code}")
    print("--- Cleanup Complete ---")


# Helper to ensure clean state *before* a specific test
def ensure_not_friends_or_pending(headers1, headers2, user1_uid, user2_uid):
    print(f"\nPre-test Check: Ensuring {user1_uid} and {user2_uid} are not friends/pending...")
    # Check if friends and remove
    resp1_list = requests.get(f"{BASE_URL}/friends/list", headers=headers1)
    if resp1_list.status_code == 200 and any(f["friend_id"] == user2_uid for f in resp1_list.json()):
        print(f"  Pre-check: Found friendship (U1->U2), removing...")
        requests.delete(f"{BASE_URL}/friends/{user2_uid}", headers=headers1)
        time.sleep(API_DELAY / 2)  # Allow time for removal
    resp2_list = requests.get(f"{BASE_URL}/friends/list", headers=headers2)
    if resp2_list.status_code == 200 and any(f["friend_id"] == user1_uid for f in resp2_list.json()):
        print(f"  Pre-check: Found friendship (U2->U1), removing...")
        requests.delete(f"{BASE_URL}/friends/{user1_uid}", headers=headers2)
        time.sleep(API_DELAY / 2)

    # Check pending requests and reject
    pending_resp = requests.get(f"{BASE_URL}/friends/requests/pending", headers=headers2)
    if pending_resp.status_code == 200:
        req_to_reject = next((r for r in pending_resp.json() if r.get("sender_id") == user1_uid), None)
        if req_to_reject:
            req_id = req_to_reject['request_id']
            print(f"  Pre-check: Found pending request {req_id}, rejecting...")
            requests.post(f"{BASE_URL}/friends/requests/{req_id}/respond", headers=headers2, json={"accept": False})
            time.sleep(API_DELAY / 2)
    print("Pre-test Check: State should be clean.")


@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs for two users")
def test_api_initial_friend_list_empty():
    headers1 = get_auth_headers(USER1_TOKEN)
    headers2 = get_auth_headers(USER2_TOKEN)
    ensure_not_friends_or_pending(headers1, headers2, USER1_UID, USER2_UID)
    time.sleep(API_DELAY)
    resp1 = requests.get(f"{BASE_URL}/friends/list", headers=headers1)
    assert resp1.status_code == 200, f"Failed to get User1 friends: {resp1.text}"
    friends1 = resp1.json()
    assert not any(
        f["friend_id"] == USER2_UID for f in friends1), f"User2 found in User1's list unexpectedly: {friends1}"

    resp2 = requests.get(f"{BASE_URL}/friends/list", headers=headers2)
    assert resp2.status_code == 200
    friends2 = resp2.json()
    assert not any(
        f["friend_id"] == USER1_UID for f in friends2), f"User1 found in User2's list unexpectedly: {friends2}"


@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs for two users")
def test_api_send_friend_request():
    global pending_request_id
    headers1 = get_auth_headers(USER1_TOKEN)
    headers2 = get_auth_headers(USER2_TOKEN)

    # Ensure clean state before sending
    ensure_not_friends_or_pending(headers1, headers2, USER1_UID, USER2_UID)
    time.sleep(API_DELAY)  # Wait after potential cleanup

    payload = {
        "receiver_id": USER2_UID,
        "message": f"Hello from blackbox test! {uuid.uuid4().hex[:6]}"
    }
    response = requests.post(f"{BASE_URL}/friends/requests", headers=headers1, json=payload)

    # Assert the request *itself* succeeded, regardless of business logic outcome initially
    assert response.status_code == 200, f"POST /friends/requests failed (expected 200): {response.status_code} - {response.text}"
    data = response.json()
    assert data.get("status") == "success", f"Expected status 'success', got: {data}"

    # Assert business logic success *specifically*
    data = response.json()
    assert data.get(
        "status") == "success", f"Expected status 'success', got: {data}"  # FIX: This is the core assertion that failed

    print(f"Send request response: {response.status_code} -> {data}")

    time.sleep(API_DELAY)
    pending_resp = requests.get(f"{BASE_URL}/friends/requests/pending", headers=headers2)
    assert pending_resp.status_code == 200
    pending_reqs = pending_resp.json()
    assert isinstance(pending_reqs, list)
    found_req = next((req for req in pending_resp.json() if req.get("sender_id") == USER1_UID), None)
    assert found_req is not None
    pending_request_id = found_req["request_id"]
    print(f"\nStored pending request ID: {pending_request_id}")


@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs")
def test_api_accept_and_interact():
    """User2 accepts the friend request, then User1 updates interaction."""
    global pending_request_id
    # FIX: Attempt to send request if ID is missing
    if pending_request_id is None:
        print("pending_request_id not set in test_api_accept_and_interact, attempting to send request...")
        # Ensure clean state before attempting to send
        headers1_fix = get_auth_headers(USER1_TOKEN)
        headers2_fix = get_auth_headers(USER2_TOKEN)
        ensure_not_friends_or_pending(headers1_fix, headers2_fix, USER1_UID, USER2_UID)
        time.sleep(API_DELAY)
        test_api_send_friend_request()  # Call the send function to set the ID
        assert pending_request_id is not None, "Failed to get pending_request_id even after retry in accept test."
        print(f"Obtained pending_request_id: {pending_request_id}")
        time.sleep(API_DELAY)  # Allow time for request to be processed

    # --- Step 1: User2 Accepts Request ---
    print(f"\nAccepting request ID: {pending_request_id}")
    headers2 = get_auth_headers(USER2_TOKEN)
    headers1 = get_auth_headers(USER1_TOKEN)
    response_accept = requests.post(f"{BASE_URL}/friends/requests/{pending_request_id}/respond", headers=headers2,
                                    json={"accept": True})
    # Rest of the test remains the same...
    assert response_accept.status_code == 200, f"Accept request failed: {response_accept.text}"
    data_accept = response_accept.json()
    assert data_accept.get("status") == "success"
    assert "accepted successfully" in data_accept.get("message", "")

    # Allow time for friend status creation
    print("Waiting for friendship creation...")
    time.sleep(API_DELAY * 2)  # Increase delay slightly just in case

    # --- Step 2: Verify Friendship ---
    print("Polling for friendship confirmation...")
    # FIX: Increase polling time/attempts
    poll_delay = API_DELAY * 1.5  # Slightly longer delay between checks
    max_attempts = 8  # More attempts

    # Poll U1 list
    poll_u1 = poll_for_condition(
        lambda: any(
            f["friend_id"] == USER2_UID for f in requests.get(f"{BASE_URL}/friends/list", headers=headers1).json()),
        expected_value=True, delay=poll_delay, max_attempts=max_attempts
    )
    assert poll_u1, "User2 never appeared in User1's friend list after polling."

    # Poll U2 list
    poll_u2 = poll_for_condition(
        lambda: any(
            f["friend_id"] == USER1_UID for f in requests.get(f"{BASE_URL}/friends/list", headers=headers2).json()),
        expected_value=True, delay=poll_delay, max_attempts=max_attempts
    )
    assert poll_u2, "User1 never appeared in User2's friend list after polling."
    print("Friendship confirmed via polling.")

    # --- Step 3: User1 Updates Interaction ---
    print(f"Updating interaction for friend: {USER2_UID}")
    headers1_interact = get_auth_headers(USER1_TOKEN)
    game_id = f"bb_game_{uuid.uuid4().hex[:8]}"
    payload_interact = {
        "game_id": game_id
    }
    response_interact = requests.post(f"{BASE_URL}/friends/{USER2_UID}/interactions", headers=headers1_interact,
                                      json=payload_interact)

    assert response_interact.status_code == 200, f"Update interaction failed: {response_interact.text}"
    data_interact = response_interact.json()
    assert data_interact.get("status") == "success"
    print("Interaction update successful.")

    # --- Step 4: Verify Interaction Update (Optional) ---
    time.sleep(API_DELAY)
    resp1_list_final = requests.get(f"{BASE_URL}/friends/list", headers=headers1_interact)
    assert resp1_list_final.status_code == 200
    friends1_final = resp1_list_final.json()
    friend_status_final = next((f for f in friends1_final if f.get("friend_id") == USER2_UID), None)

    assert friend_status_final is not None, f"Friend status for {USER2_UID} not found in final check."
    assert friend_status_final.get("last_game") == game_id


@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs for two users")
def test_api_remove_friend():
    """User1 removes User2 as a friend."""
    # This assumes they might be friends from the accept_and_interact test
    headers1 = get_auth_headers(USER1_TOKEN)
    headers2 = get_auth_headers(USER2_TOKEN)

    # Ensure they are friends first (maybe redundant if accept test runs before)
    resp1_list_pre = requests.get(f"{BASE_URL}/friends/list", headers=headers1)
    if resp1_list_pre.status_code != 200 or not any(f["friend_id"] == USER2_UID for f in resp1_list_pre.json()):
        print("Pre-remove check: Users not friends, attempting to accept request first (if any)...")
        test_api_accept_and_interact()  # Try to ensure they are friends
        time.sleep(API_DELAY)

    # Proceed with removal
    response = requests.delete(f"{BASE_URL}/friends/{USER2_UID}", headers=headers1)
    assert response.status_code == 200, f"Remove friend failed: {response.text}"
    data = response.json()
    assert data.get("status") == "success"

    time.sleep(API_DELAY)

    resp1_list = requests.get(f"{BASE_URL}/friends/list", headers=headers1)
    assert resp1_list.status_code == 200
    friends1 = resp1_list.json()
    assert not any(f["friend_id"] == USER2_UID for f in friends1), "User2 still in User1's list after remove"

    resp2_list = requests.get(f"{BASE_URL}/friends/list", headers=headers2)
    assert resp2_list.status_code == 200
    friends2 = resp2_list.json()
    assert not any(f["friend_id"] == USER1_UID for f in friends2), "User1 still in User2's list after remove"


# --- Negative and Edge Case Tests ---

@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs for two users")
def test_api_send_friend_request_to_self():
    headers1 = get_auth_headers(USER1_TOKEN)
    payload = {"receiver_id": USER1_UID}
    response = requests.post(f"{BASE_URL}/friends/requests", headers=headers1, json=payload)
    # Expect 400 or 409 if route logic is fixed, otherwise check status field
    # assert response.status_code in [400, 409]
    assert response.status_code == 409
    assert "Failed to send friend request" in response.json().get("detail", "")


@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs for two users")
def test_api_send_duplicate_friend_request():
    headers1 = get_auth_headers(USER1_TOKEN)
    headers2 = get_auth_headers(USER2_TOKEN)
    ensure_not_friends_or_pending(headers1, headers2, USER1_UID, USER2_UID)

    # FIX: Add extra polling here to ensure the state allows sending
    print("Polling to confirm state allows sending friend request...")
    poll_delay = API_DELAY / 2  # Use smaller delay for this check

    # Check U2 has no pending from U1
    poll_p2_clear = poll_for_condition(
        lambda: not any(r.get("sender_id") == USER1_UID for r in
                        requests.get(f"{BASE_URL}/friends/requests/pending", headers=headers2).json()),
        expected_value=True, delay=poll_delay, max_attempts=6
    )
    # Check U1 has no pending from U2 (less likely to interfere, but good practice)
    poll_p1_clear = poll_for_condition(
        lambda: not any(r.get("sender_id") == USER2_UID for r in
                        requests.get(f"{BASE_URL}/friends/requests/pending", headers=headers1).json()),
        expected_value=True, delay=poll_delay, max_attempts=6
    )

    if not (poll_p1_clear and poll_p2_clear):
        pytest.fail("Polling failed to confirm clear pending request state before sending first request.")
    print("Confirmed state is clear via polling.")

    time.sleep(API_DELAY / 2)  # Short extra delay

    payload = {"receiver_id": USER2_UID, "message": "Duplicate request test"}
    print("Sending first request...")
    resp1 = requests.post(f"{BASE_URL}/friends/requests", headers=headers1, json=payload)
    assert resp1.status_code == 200, f"First request failed (expected 200): {resp1.status_code} - {resp1.text}"
    assert resp1.json().get("status") == "success"
    print("First request sent successfully.")

    # ... (rest of the test: poll for request ID, send duplicate, assert 409, cleanup) ...
    # (Polling for ID is already added in the previous fix for test_api_send_friend_request logic)
    first_req_id = None

    def check_pending_dup():
        pending_resp_check = requests.get(f"{BASE_URL}/friends/requests/pending", headers=headers2)
        if pending_resp_check.status_code == 200:
            return next((r.get("request_id") for r in pending_resp_check.json() if r.get("sender_id") == USER1_UID),
                        None)
        return None

    if not poll_for_condition(lambda: check_pending_dup() is not None, expected_value=True):
        print("Warning: Could not confirm first request appeared via polling for cleanup ID.")
    else:
        first_req_id = check_pending_dup()
        print(f"Obtained ID of first request for potential cleanup: {first_req_id}")

    # Send duplicate
    print("Sending duplicate request...")
    resp2 = requests.post(f"{BASE_URL}/friends/requests", headers=headers1, json=payload)
    assert resp2.status_code == 409, f"Duplicate request did not fail with 409: {resp2.status_code} - {resp2.text}"
    assert "Failed to send friend request" in resp2.json().get("detail", "")
    print("Duplicate request correctly failed with 409.")

    # Cleanup the first pending request if its ID was found
    if first_req_id:
        print(f"Cleaning up first request: {first_req_id}")
        reject_resp = requests.post(f"{BASE_URL}/friends/requests/{first_req_id}/respond",
                                    headers=headers2, json={"accept": False})
        print(f"  Cleanup reject status: {reject_resp.status_code}")
        assert reject_resp.status_code == 200  # Ensure cleanup worked
    else:
        print("Skipping cleanup as first request ID was not found.")


@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs for two users")
def test_api_respond_to_non_existent_request():
    headers2 = get_auth_headers(USER2_TOKEN)
    non_existent_req_id = f"req_fake_{uuid.uuid4().hex}"
    response = requests.post(f"{BASE_URL}/friends/requests/{non_existent_req_id}/respond", headers=headers2,
                             json={"accept": True})
    assert response.status_code == 404


@pytest.mark.skipif(not config_present, reason="Requires tokens/UIDs for two users")
def test_api_respond_to_request_not_for_user():
    headers1 = get_auth_headers(USER1_TOKEN)
    headers2 = get_auth_headers(USER2_TOKEN)
    # Ensure clean state
    ensure_not_friends_or_pending(headers1, headers2, USER1_UID, USER2_UID)
    time.sleep(API_DELAY)

    payload1 = {"receiver_id": USER2_UID, "message": "Request for User2"}
    resp_send = requests.post(f"{BASE_URL}/friends/requests", headers=headers1, json=payload1)
    assert resp_send.status_code == 200, f"Send request failed (expected 200): {resp_send.status_code} - {resp_send.text}"
    assert resp_send.json().get("status") == "success"

    time.sleep(API_DELAY)

    pending_resp = requests.get(f"{BASE_URL}/friends/requests/pending", headers=headers2)
    assert pending_resp.status_code == 200
    req_for_u2 = next((r for r in pending_resp.json() if r.get("sender_id") == USER1_UID), None)
    assert req_for_u2 is not None, "Failed to find request for User2"
    req_id = req_for_u2["request_id"]

    # User1 (sender) tries to respond - should fail
    response = requests.post(f"{BASE_URL}/friends/requests/{req_id}/respond", headers=headers1,
                             json={"accept": True})
    assert response.status_code == 403

    # Cleanup: User2 rejects the request
    reject_resp = requests.post(f"{BASE_URL}/friends/requests/{req_id}/respond", headers=headers2,
                                json={"accept": False})
    print(f"\nCleanup: User2 rejected request {req_id} -> Status {reject_resp.status_code}")


================================================================================

Filename: tests/api_blackbox/test_b_history_flow.py
Content:
# Filename: tests/api_blackbox/test_b_history_flow.py

import os
import uuid
from datetime import datetime, timezone, timedelta

import pytest
import requests

# --- Test Configuration ---
BASE_URL = os.getenv("TEST_BASE_URL", "http://localhost:8080").rstrip('/')
API_DELAY = float(os.getenv("TEST_API_DELAY", "0.5"))

# !!! IMPORTANT: Requires valid token/UID for at least one user !!!
USER1_TOKEN = os.getenv("TEST_USER1_BACKEND_TOKEN")
USER1_UID = os.getenv("TEST_USER1_UID")
# Optional: Use a second user's UID if available for between_players tests
USER2_UID = os.getenv("TEST_USER2_UID", f"opponent-uid-{uuid.uuid4().hex[:6]}")  # Default to generated opponent

config_present = USER1_TOKEN and USER1_UID
if not config_present:
    print(
        "\nWARNING: Missing environment variables for history flow tests (TEST_USER1_BACKEND_TOKEN, TEST_USER1_UID). "
        "Tests will be skipped.")


# --- Helper ---
def get_auth_headers(token):
    return {"Authorization": f"Bearer {token}"} if token else {}


# --- Global state for the flow ---
# Store IDs of games archived during the tests for later retrieval/verification
archived_game_ids = []


# --- Fixture for Optional Cleanup ---
# Note: Deleting history might not be a feature, so cleanup is less common here.
# We'll rely on unique game IDs per run.

# --- Test Cases ---

@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_archive_game_valid():
    """Tests archiving a valid game where the user participated."""
    headers = get_auth_headers(USER1_TOKEN)
    game_id = f"bb_hist_{uuid.uuid4().hex}"
    now = datetime.now(timezone.utc)
    # Payload must match the GameHistory model structure
    game_payload = {
        "game_id": game_id,
        "white_player_id": USER1_UID,  # Authenticated user is white
        "black_player_id": USER2_UID,  # Can be any opponent ID
        "start_time": (now - timedelta(minutes=20)).isoformat(),
        "end_time": now.isoformat(),
        "result": "white_win",  # Match GameResult enum values
        "winner_id": USER1_UID,
        "moves": ["e4", "c5", "Nf3", "d6", "d4", "cxd4", "Nxd4", "Nf6", "Nc3", "a6"],  # Sicilian Najdorf start
        "initial_position": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1",
        "white_rating": 1300,
        "black_rating": 1280,
        "rating_change": {"white": 9, "black": -9},
        "game_type": "portal_gambit",
        "time_control": {"initial": 900, "increment": 10}
    }

    response = requests.post(f"{BASE_URL}/history/games", headers=headers, json=game_payload)
    assert response.status_code == 200, f"Archive game failed: {response.text}"
    data = response.json()
    assert data.get("status") == "success"
    assert "archived successfully" in data.get("message", "")
    archived_game_ids.append(game_id)  # Store for later tests
    print(f"\nArchived game ID: {game_id}")


@pytest.mark.skipif(not config_present or not archived_game_ids, reason="Requires token/UID and an archived game")
def test_api_get_archived_game_valid():
    """Tests retrieving a specific game that was just archived."""
    headers = get_auth_headers(USER1_TOKEN)
    game_id = archived_game_ids[-1]  # Get the most recently archived game
    response = requests.get(f"{BASE_URL}/history/games/{game_id}", headers=headers)
    assert response.status_code == 200, f"Get game failed: {response.text}"
    game_data = response.json()
    # Verify key fields match the archived game
    assert game_data["game_id"] == game_id
    assert game_data["white_player_id"] == USER1_UID
    assert game_data["black_player_id"] == USER2_UID
    assert game_data["result"] == "white_win"
    assert len(game_data["moves"]) == 10
    assert game_data["rating_change"]["white"] == 9


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_user_games():
    """Tests retrieving the list of games for the authenticated user."""
    # This assumes test_api_archive_game_valid ran and archived at least one game
    headers = get_auth_headers(USER1_TOKEN)
    limit = 5
    response = requests.get(f"{BASE_URL}/history/users/{USER1_UID}/games?limit={limit}", headers=headers)
    assert response.status_code == 200
    user_games = response.json()
    assert isinstance(user_games, list)
    assert len(user_games) <= limit
    # Check if the recently archived game(s) are present (likely at the start)
    if archived_game_ids:
        found = any(game["game_id"] in archived_game_ids for game in user_games)
        assert found, f"Archived games ({archived_game_ids}) not found in user's history"
        # Verify sorting (most recent first)
        if len(user_games) > 1:
            # Parse end_time strings to datetime objects for comparison
            time_format = "%Y-%m-%dT%H:%M:%S.%f%z" if '.' in user_games[0]["end_time"] else "%Y-%m-%dT%H:%M:%S%z"
            try:
                dt1 = datetime.strptime(user_games[0]["end_time"].replace("Z", "+00:00"), time_format)
                dt2 = datetime.strptime(user_games[1]["end_time"].replace("Z", "+00:00"), time_format)
                assert dt1 >= dt2, "User games not sorted by end_time descending"
            except ValueError as e:
                print(f"Warning: Could not parse datetime for sorting check: {e}")


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_games_between_players():
    """Tests retrieving games between User1 and User2."""
    # Assumes at least one game was archived between USER1_UID and USER2_UID
    headers = get_auth_headers(USER1_TOKEN)
    limit = 10
    player1 = USER1_UID
    player2 = USER2_UID
    response = requests.get(f"{BASE_URL}/history/games/between/{player1}/{player2}?limit={limit}", headers=headers)
    assert response.status_code == 200
    between_games = response.json()
    assert isinstance(between_games, list)
    assert len(between_games) <= limit
    if archived_game_ids:
        found = any(game["game_id"] in archived_game_ids for game in between_games)
        assert found, f"Archived game between {player1} and {player2} not found"
        # Verify participants are correct
        for game in between_games:
            assert (game["white_player_id"] == player1 and game["black_player_id"] == player2) or \
                   (game["white_player_id"] == player2 and game["black_player_id"] == player1)


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_user_stats():
    """Tests retrieving game statistics for the user."""
    headers = get_auth_headers(USER1_TOKEN)
    days = 90
    response = requests.get(f"{BASE_URL}/history/users/{USER1_UID}/stats?days={days}", headers=headers)
    assert response.status_code == 200
    stats = response.json()
    # Check structure based on UserGameStats schema
    assert "total_games" in stats
    assert isinstance(stats["total_games"], int)
    assert stats["total_games"] >= 0  # Should be non-negative
    assert "wins" in stats
    assert "losses" in stats
    assert "draws" in stats
    assert "white_games" in stats
    assert "black_games" in stats
    assert "rating_change" in stats
    assert "average_game_length" in stats
    assert "total_moves" in stats
    # Basic sanity check
    assert stats["wins"] + stats["losses"] + stats["draws"] <= stats["total_games"]
    assert stats["white_games"] + stats["black_games"] == stats["total_games"]


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_popular_openings():
    """Tests retrieving popular openings."""
    headers = get_auth_headers(USER1_TOKEN)
    limit = 5
    response = requests.get(f"{BASE_URL}/history/openings/popular?limit={limit}", headers=headers)
    assert response.status_code == 200
    openings = response.json()
    assert isinstance(openings, list)
    assert len(openings) <= limit
    # Check structure based on OpeningStats schema if results exist
    if openings:
        opening = openings[0]
        assert "moves" in opening  # String of first few moves
        assert isinstance(opening["moves"], str)
        assert "count" in opening  # How many times played
        assert isinstance(opening["count"], int)
        assert "wins" in opening  # How many non-abandoned games with this opening
        assert isinstance(opening["wins"], int)
        # Check sorting (most popular first)
        if len(openings) > 1:
            assert openings[0]["count"] >= openings[1]["count"]


# --- Negative Test Cases ---

@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_archive_game_forbidden():
    """Tests archiving a game where the user did NOT participate."""
    headers = get_auth_headers(USER1_TOKEN)
    game_id = f"bb_hist_forbidden_{uuid.uuid4().hex}"
    now = datetime.now(timezone.utc)
    game_payload = {
        "game_id": game_id,
        "white_player_id": f"other-player-a-{uuid.uuid4().hex[:4]}",  # Not USER1_UID
        "black_player_id": f"other-player-b-{uuid.uuid4().hex[:4]}",  # Not USER1_UID
        "start_time": (now - timedelta(minutes=5)).isoformat(),
        "end_time": now.isoformat(),
        "result": "draw",
        "winner_id": None,
        "moves": ["e4", "e5"],
        "initial_position": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1",
        "white_rating": 1100, "black_rating": 1110,
        "rating_change": {"white": 0, "black": 0},
        "game_type": "standard",
        "time_control": {"initial": 180, "increment": 0}
    }
    response = requests.post(f"{BASE_URL}/history/games", headers=headers, json=game_payload)
    assert response.status_code == 403  # Forbidden


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_archive_game_missing_data():
    """Tests archiving a game with missing required fields."""
    headers = get_auth_headers(USER1_TOKEN)
    game_payload = {
        "game_id": f"bb_hist_invalid_{uuid.uuid4().hex}",
        "white_player_id": USER1_UID,
        # Missing black_player_id, result, end_time, moves etc.
    }
    response = requests.post(f"{BASE_URL}/history/games", headers=headers, json=game_payload)
    assert response.status_code == 422  # Unprocessable Entity


@pytest.mark.skipif(not config_present, reason="Requires token/UID for User1")
def test_api_get_non_existent_game():
    """Tests retrieving a game ID that doesn't exist."""
    headers = get_auth_headers(USER1_TOKEN)
    non_existent_id = f"non-existent-game-{uuid.uuid4().hex}"
    response = requests.get(f"{BASE_URL}/history/games/{non_existent_id}", headers=headers)
    assert response.status_code == 404  # Not Found


================================================================================

Filename: tests/api_blackbox/test_b_profile_flow.py
Content:
import os
import time
import uuid

import pytest
import requests

# --- Test Configuration ---
BASE_URL = os.getenv("TEST_BASE_URL", "http://localhost:8080").rstrip('/')
# Increased default delay, can be overridden by environment variable
API_DELAY = float(os.getenv("TEST_API_DELAY", "1.5"))

USER1_TOKEN = os.getenv("TEST_USER1_BACKEND_TOKEN")
USER1_UID = os.getenv("TEST_USER1_UID")

config_present = USER1_TOKEN and USER1_UID
if not config_present:
    print(
        "\nWARNING: Missing environment variables for profile flow tests (TEST_USER1_BACKEND_TOKEN, "
        "TEST_USER1_UID). Tests will be skipped.")


def get_auth_headers(token):
    return {"Authorization": f"Bearer {token}"} if token else {}


# --- Combined Test Case ---

@pytest.mark.skipif(not config_present, reason="Requires TEST_USER1_BACKEND_TOKEN and TEST_USER1_UID")
def test_api_profile_crud_search_achievement():
    """Tests profile creation/get, update, search, and adding achievements sequentially."""
    headers = get_auth_headers(USER1_TOKEN)
    test_run_username = f"bb_user_{uuid.uuid4().hex[:8]}"  # Use local variable
    profile_data = None  # Use local variable

    # --- Step 1: Create or Get Profile ---
    print(f"\n--- Profile Step 1: Ensuring profile exists for {USER1_UID} ---")
    get_response = requests.get(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers)

    profile_created_or_updated = False  # Flag to indicate if we should wait

    if get_response.status_code == 404:
        print(f"Profile for {USER1_UID} not found (404). Attempting creation with username {test_run_username}...")
        create_payload = {
            "uid": USER1_UID,
            "username": test_run_username,
            "email": f"{test_run_username}@example.com",
            "rating": 1200, "games_played": 0, "wins": 0, "losses": 0, "draws": 0,
            "friends": [], "achievements": [], "preferences": {},
            "display_name": "BB Test User", "avatar_url": None
        }
        create_response = requests.post(f"{BASE_URL}/profiles/", headers=headers, json=create_payload)

        if create_response.status_code == 409:  # Conflict (profile likely created between GET and POST)
            print(f"Profile creation returned 409 Conflict. Getting existing profile...")
            get_response = requests.get(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers)
            assert get_response.status_code == 200, "Failed to get profile after 409 on create."
            profile_data = get_response.json()
            # If it existed, it might have a different username, try to update
            if profile_data["username"] != test_run_username:
                print(
                    f"Profile existed with username {profile_data['username']}, "
                    f"attempting update to {test_run_username}")
                update_resp = requests.patch(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers,
                                             json={"username": test_run_username})
                if update_resp.status_code == 200:
                    print("Username updated successfully for search test.")
                    profile_data["username"] = test_run_username
                    profile_created_or_updated = True
                else:
                    print(
                        f"Warning: Failed to update username for existing profile after 409 ({update_resp.status_code})"
            
                        f". Search test might use old username.")
                    test_run_username = profile_data["username"]  # Use existing name for search
            else:
                test_run_username = profile_data["username"]  # Ensure local var matches DB

        elif create_response.status_code == 200:
            assert create_response.json().get("status") == "success", f"Create request failed: {create_response.text}"
            print(f"Profile for {USER1_UID} created successfully.")
            profile_created_or_updated = True
            # Get profile data after creation
            get_response = requests.get(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers)
            assert get_response.status_code == 200, "Failed to get profile immediately after creation."
            profile_data = get_response.json()
        else:
            pytest.fail(
                f"Unexpected status code {create_response.status_code} during profile creation: {create_response.text}")

    elif get_response.status_code == 200:
        print(f"\nProfile for {USER1_UID} already exists.")
        profile_data = get_response.json()
        # If it existed, it might have a different username, try to update
        if profile_data["username"] != test_run_username:
            print(f"Profile existed with username {profile_data['username']}, attempting update to {test_run_username}")
            update_resp = requests.patch(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers,
                                         json={"username": test_run_username})
            if update_resp.status_code == 200:
                print("Username updated successfully for search test.")
                profile_data["username"] = test_run_username
                profile_created_or_updated = True
            else:
                print(
                    f"Warning: Failed to update username for existing profile ({update_resp.status_code})."
                    f" Search test might use old username.")
                test_run_username = profile_data["username"]  # Use existing name for search
        else:
            test_run_username = profile_data["username"]  # Ensure local var matches DB

    else:  # Handle unexpected status codes from initial GET
        pytest.fail(
            f"Unexpected status code {get_response.status_code} when checking profile existence: {get_response.text}")

    assert profile_data is not None, "Failed to get or create profile data"
    assert profile_data["uid"] == USER1_UID
    original_rating = profile_data["rating"]

    # FIX: Add delay if profile was just created or username updated
    if profile_created_or_updated:
        print(f"Waiting {API_DELAY}s after profile creation/update for consistency...")
        time.sleep(API_DELAY)

    # --- Step 2: Update Profile (other fields) ---
    print("\n--- Profile Step 2: Updating profile ---")
    new_display_name = f"Updated BB {int(time.time())}"
    new_avatar_url = f"http://example.com/new_avatar_{uuid.uuid4().hex[:4]}.png"
    new_preferences = {"theme": "chesscom", "sound_volume": 8}
    update_payload = {
        "display_name": new_display_name,
        "avatar_url": new_avatar_url,
        "preferences": new_preferences
    }
    response_update = requests.patch(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers, json=update_payload)
    assert response_update.status_code == 200, f"Update failed: {response_update.text}"
    assert response_update.json().get("status") == "success"
    print("Profile update successful.")

    # --- Step 3: Verify Update ---
    # FIX: Add delay before verifying the update
    print(f"Waiting {API_DELAY}s after update before verification...")
    time.sleep(API_DELAY)
    get_response_updated = requests.get(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers)
    assert get_response_updated.status_code == 200
    updated_data = get_response_updated.json()
    assert updated_data["display_name"] == new_display_name
    assert updated_data["avatar_url"] == new_avatar_url
    assert updated_data["preferences"] == new_preferences
    assert updated_data["rating"] == original_rating  # Check rating didn't change

    # --- Step 4: Search Profile ---
    # FIX: Add significant delay before search, especially if username was updated
    search_delay = API_DELAY * 2  # Double delay before search
    print(f"\n--- Profile Step 4: Waiting {search_delay}s before searching for profile '{test_run_username}' ---")
    time.sleep(search_delay)
    search_prefix = test_run_username[:5]  # Use potentially updated username
    response_search = requests.get(f"{BASE_URL}/profiles/search/{search_prefix}?limit=5", headers=headers)
    assert response_search.status_code == 200
    search_results = response_search.json()
    print(f"Search results for prefix '{search_prefix}': {search_results}")  # Log search results
    assert isinstance(search_results, list)
    found = any(profile["uid"] == USER1_UID and profile["username"] == test_run_username for profile in search_results)
    assert found, f"Profile with username {test_run_username} not found in search results for prefix '{search_prefix}'"
    print("Profile search successful.")

    # --- Step 5: Add Achievement ---
    print("\n--- Profile Step 5: Adding achievement ---")
    achievement_id = f"bb_achieve_{uuid.uuid4().hex[:6]}"
    response_achieve = requests.post(f"{BASE_URL}/profiles/{USER1_UID}/achievements/{achievement_id}", headers=headers)
    assert response_achieve.status_code == 200, f"Add achievement failed: {response_achieve.text}"
    assert response_achieve.json().get("status") == "success"
    print("Add achievement successful.")

    # --- Step 6: Verify Achievement ---
    # FIX: Add delay before verifying achievement
    print(f"Waiting {API_DELAY}s after adding achievement...")
    time.sleep(API_DELAY)
    get_response_final = requests.get(f"{BASE_URL}/profiles/{USER1_UID}", headers=headers)
    assert get_response_final.status_code == 200
    final_data = get_response_final.json()
    assert achievement_id in final_data.get("achievements", [])
    print("Achievement verification successful.")


# Keep other tests like leaderboard, negative cases etc. as they were

@pytest.mark.skipif(not config_present, reason="Requires TEST_USER1_BACKEND_TOKEN and TEST_USER1_UID")
def test_api_get_leaderboard():
    """Tests fetching the leaderboard."""
    headers = get_auth_headers(USER1_TOKEN)
    limit = 10
    response = requests.get(f"{BASE_URL}/profiles/leaderboard/top?limit={limit}", headers=headers)
    assert response.status_code == 200
    leaderboard = response.json()
    assert isinstance(leaderboard, list)
    assert len(leaderboard) <= limit
    if len(leaderboard) > 1:
        for i in range(len(leaderboard) - 1):
            assert leaderboard[i].get("rating", 0) >= leaderboard[i + 1].get("rating", 0)


@pytest.mark.skipif(not config_present, reason="Requires TEST_USER1_BACKEND_TOKEN and TEST_USER1_UID")
def test_api_create_profile_missing_data():
    """Tests creating a profile with missing required fields."""
    headers = get_auth_headers(USER1_TOKEN)
    payload = {"uid": USER1_UID}  # Missing username, email
    response = requests.post(f"{BASE_URL}/profiles/", headers=headers, json=payload)
    assert response.status_code == 422


@pytest.mark.skipif(not config_present, reason="Requires TEST_USER1_BACKEND_TOKEN and TEST_USER1_UID")
def test_api_create_profile_forbidden():
    """Tests creating a profile for a different UID than the authenticated user."""
    headers = get_auth_headers(USER1_TOKEN)
    different_uid = f"other-uid-{uuid.uuid4().hex}"
    payload = {
        "uid": different_uid, "username": f"forbidden_{uuid.uuid4().hex[:6]}", "email": "forbidden@example.com",
        "rating": 1200, "games_played": 0, "wins": 0, "losses": 0, "draws": 0,
        "friends": [], "achievements": [], "preferences": {}
    }
    response = requests.post(f"{BASE_URL}/profiles/", headers=headers, json=payload)
    assert response.status_code == 403


@pytest.mark.skipif(not config_present, reason="Requires TEST_USER1_BACKEND_TOKEN and TEST_USER1_UID")
def test_api_update_other_user_profile_forbidden():
    """Tests attempting to update another user's profile."""
    headers = get_auth_headers(USER1_TOKEN)
    other_user_uid = f"other-profile-uid-{uuid.uuid4().hex}"
    update_payload = {"display_name": "Hacker"}
    response = requests.patch(f"{BASE_URL}/profiles/{other_user_uid}", headers=headers, json=update_payload)
    assert response.status_code == 403


@pytest.mark.skipif(not config_present, reason="Requires TEST_USER1_BACKEND_TOKEN and TEST_USER1_UID")
def test_api_add_achievement_other_user_forbidden():
    """Tests attempting to add an achievement to another user's profile."""
    headers = get_auth_headers(USER1_TOKEN)
    other_user_uid = f"other-achieve-uid-{uuid.uuid4().hex}"
    achievement_id = "hack_achievement"
    response = requests.post(f"{BASE_URL}/profiles/{other_user_uid}/achievements/{achievement_id}", headers=headers)
    # This route doesn't expect a body, so 403 is the correct expectation
    assert response.status_code == 403


@pytest.mark.skipif(not config_present, reason="Requires TEST_USER1_BACKEND_TOKEN and TEST_USER1_UID")
def test_api_get_non_existent_profile():
    """Tests getting a profile that definitely does not exist."""
    headers = get_auth_headers(USER1_TOKEN)
    non_existent_uid = f"non-existent-uid-{uuid.uuid4().hex}"
    response = requests.get(f"{BASE_URL}/profiles/{non_existent_uid}", headers=headers)
    assert response.status_code == 404


================================================================================

Filename: tests/conftest.py
Content:
# Filename: tests/conftest.py
import os
import time
import uuid
from datetime import datetime, timezone, timedelta
from unittest.mock import patch, AsyncMock, MagicMock

import pytest
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.testclient import TestClient

from middleware.auth_middleware import FirebaseAuthMiddleware  # Import middleware
# Import models/schemas...
from models.friend import FriendRequest, FriendStatus, FriendRequestStatus
from models.game_history import GameHistory, GameResult
from models.user_profile import UserProfile
# Import the original app instance AND the routers separately
from routes import profile_routes, friend_routes, history_routes, analytics_routes, auth_routes
from schemas.analytics_schemas import DailyStats, PlayerPerformance, GlobalStats
from schemas.auth_schemas import TokenData
from schemas.history_schemas import OpeningStats, UserGameStats
from services.analytics_service import AnalyticsService
from services.friend_service import FriendService
from services.history_service import HistoryService
from services.profile_service import ProfileService
from utils import dependencies

load_dotenv()


# --- Test Data Fixtures --- (Keep these as they are) ---
@pytest.fixture(scope="session")
def test_user_1_uid() -> str:
    return os.getenv("TEST_USER1_UID_FIXTURE", "fixture-user-1-uid")

@pytest.fixture(scope="session")
def test_user_2_uid() -> str:
    return os.getenv("TEST_USER2_UID_FIXTURE", "fixture-user-2-uid")

@pytest.fixture
def test_user_1_token_data(test_user_1_uid) -> TokenData:
    return TokenData(
        uid=test_user_1_uid,
        email="test1@example.com",
        email_verified=True
    )


# ... (keep sample_user_profile, sample_game_history, etc.) ...
@pytest.fixture
def sample_user_profile(test_user_1_uid, test_user_2_uid) -> UserProfile:
    """Provides a sample UserProfile object."""
    return UserProfile(
        uid=test_user_1_uid,
        username=f"testuser_{uuid.uuid4().hex[:6]}",
        email="test1@example.com",
        display_name="Test User One",
        avatar_url="http://example.com/avatar.png",
        rating=1250,
        games_played=10,
        wins=5,
        losses=3,
        draws=2,
        created_at=datetime.now(timezone.utc) - timedelta(days=5),
        last_active=datetime.now(timezone.utc) - timedelta(hours=1),
        friends=[test_user_2_uid],  # Reference the other test user
        achievements=["first_win", "portal_master"],
        preferences={"theme": "dark", "sound": True}
    )


@pytest.fixture
def sample_game_history(test_user_1_uid, test_user_2_uid) -> GameHistory:
    """Provides a sample GameHistory object."""
    now = datetime.now(timezone.utc)
    return GameHistory(
        game_id=f"game_{uuid.uuid4().hex}",
        white_player_id=test_user_1_uid,
        black_player_id=test_user_2_uid,
        start_time=now - timedelta(minutes=15),
        end_time=now - timedelta(minutes=2),
        result=GameResult.WHITE_WIN,
        winner_id=test_user_1_uid,
        moves=["e4", "e5", "Nf3", "Nc6", "Bb5", "a6", "Bxc6", "dxc6", "O-O"],  # Example
        initial_position="rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1",
        white_rating=1250,
        black_rating=1230,
        rating_change={"white": 8, "black": -8},
        game_type="portal_gambit",
        time_control={"initial": 600, "increment": 5}
    )


@pytest.fixture
def sample_friend_request(test_user_1_uid, test_user_2_uid) -> FriendRequest:
    """Provides a sample pending FriendRequest object."""
    return FriendRequest(
        request_id=f"req_{uuid.uuid4().hex}",
        sender_id=test_user_2_uid,  # User 2 sent to User 1
        receiver_id=test_user_1_uid,
        status=FriendRequestStatus.PENDING,
        created_at=datetime.now(timezone.utc) - timedelta(days=1),
        updated_at=datetime.now(timezone.utc) - timedelta(days=1),
        message="Wanna be friends and test portals?"
    )


@pytest.fixture
def sample_friend_status(test_user_1_uid, test_user_2_uid, sample_game_history) -> FriendStatus:
    """Provides a sample FriendStatus object."""
    return FriendStatus(
        user_id=test_user_1_uid,
        friend_id=test_user_2_uid,
        became_friends=datetime.now(timezone.utc) - timedelta(days=2),
        games_played=1,
        last_game=sample_game_history.game_id,
        last_interaction=sample_game_history.end_time
    )


# --- Mocking Fixtures (Firebase init, token verify - keep as is) ---
@pytest.fixture(scope="session", autouse=True)
def mock_firebase_admin_init():
    try:
        import firebase_admin
        if firebase_admin._DEFAULT_APP_NAME in firebase_admin._apps:
            print("Firebase Admin already initialized, skipping init mock patch.")
            yield None
            return
    except ImportError:
        pass
    with patch("firebase_admin.initialize_app") as mock_init:
        print("Firebase Admin Initialized (Mocked via Patch)")
        yield mock_init

@pytest.fixture
def mock_verify_firebase_token():
    with patch("firebase_admin.auth.verify_id_token") as mock_verify:
        mock_verify.return_value = {
            "uid": "mock_firebase_uid_from_token", "email": "firebase_user@example.com", "email_verified": True,
            "name": "Firebase Mock User", "picture": "http://example.com/firebase_pic.jpg",
            "iss": "https://securetoken.google.com/your-project-id", "aud": "your-project-id",
            "auth_time": int(time.time()) - 300, "user_id": "mock_firebase_uid_from_token",
            "sub": "mock_firebase_uid_from_token", "iat": int(time.time()) - 300, "exp": int(time.time()) + 3600,
            "firebase": {"identities": {"email": ["firebase_user@example.com"]}, "sign_in_provider": "password"}
        }
        yield mock_verify


# --- Mock Services (Keep as is) ---
@pytest.fixture
def mock_analytics_service(test_user_1_uid, test_user_2_uid):
    service = MagicMock(spec=AnalyticsService)
    service.record_game_analytics = AsyncMock(return_value=True)
    service.get_daily_stats = AsyncMock(
        return_value=DailyStats(total_games=7, average_duration=410.2, average_moves=51.8, white_wins=3, black_wins=3,
                                draws=1, abandoned=0, game_types={"portal_gambit": 7},
                                time_controls={"600/5": 4, "300/3": 3}))
    service.get_player_performance = AsyncMock(return_value=PlayerPerformance(
        rating_progression=[{"timestamp": datetime.now(timezone.utc) - timedelta(days=2), "rating_change": 8},
                            {"timestamp": datetime.now(timezone.utc) - timedelta(days=1), "rating_change": -6}],
        average_game_duration=450.0, preferred_time_control="600/5", preferred_game_type="portal_gambit", win_rate=0.5,
        performance_by_color={"white": {"games": 4, "wins": 2}, "black": {"games": 3, "wins": 1}},
        average_moves_per_game=55.0))
    service.get_global_stats = AsyncMock(
        return_value=GlobalStats(total_games=1500, white_win_rate=0.475, average_game_duration=430.0,
                                 average_moves_per_game=53.5, popular_time_controls={"600/5": 700, "900/10": 300},
                                 popular_game_types={"portal_gambit": 1450, "standard": 50},
                                 last_updated=datetime.now(timezone.utc) - timedelta(minutes=30)))
    return service

@pytest.fixture
def mock_friend_service(sample_friend_request, sample_friend_status, test_user_1_uid, test_user_2_uid):
    service = MagicMock(spec=FriendService)
    service.send_friend_request = AsyncMock(return_value=True)
    service.get_pending_requests = AsyncMock(return_value=[sample_friend_request])
    service.get_friend_request = AsyncMock(return_value=sample_friend_request)
    service.respond_to_request = AsyncMock(return_value=True)
    service.get_friends = AsyncMock(return_value=[sample_friend_status])
    service.remove_friend = AsyncMock(return_value=True)
    service.update_last_interaction = AsyncMock(return_value=True)
    return service

@pytest.fixture
def mock_history_service(sample_game_history, test_user_1_uid, test_user_2_uid):
    service = MagicMock(spec=HistoryService)
    service.archive_game = AsyncMock(return_value=True)
    service.get_game = AsyncMock(return_value=sample_game_history)
    service.get_user_games = AsyncMock(return_value=[sample_game_history])
    service.get_games_between_players = AsyncMock(return_value=[sample_game_history])
    service.get_user_stats = AsyncMock(
        return_value=UserGameStats(total_games=12, wins=6, losses=4, draws=2, white_games=6, black_games=6,
                                   rating_change=15, average_game_length=510.0, total_moves=612))
    service.get_popular_openings = AsyncMock(return_value=[OpeningStats(moves="e4 c5 Nf3", count=120, wins=65)])
    return service

@pytest.fixture
def mock_profile_service(sample_user_profile, test_user_1_uid):
    service = MagicMock(spec=ProfileService)
    service.create_profile = AsyncMock(return_value=True)
    service.get_profile = AsyncMock(return_value=sample_user_profile)
    service.update_profile = AsyncMock(return_value=True)
    service.search_profiles = AsyncMock(return_value=[sample_user_profile])
    service.get_leaderboard = AsyncMock(return_value=[sample_user_profile])
    service.add_achievement = AsyncMock(return_value=True)
    service.update_rating = AsyncMock(return_value=True)
    return service


# --- Mock Firestore Client (Keep revised version without specs for Firestore types) ---
@pytest.fixture
def mock_firestore_increment():
    with patch('firebase_admin.firestore.Increment', spec=True) as MockIncrement:
        yield MockIncrement

@pytest.fixture
def mock_firestore_array_union():
    with patch('firebase_admin.firestore.ArrayUnion', spec=True) as MockArrayUnion:
        yield MockArrayUnion

@pytest.fixture
def mock_db_client(mock_firestore_increment, mock_firestore_array_union):
    # Mocks without specs for Firestore types, AsyncMock for methods
    doc_snapshot_mock = MagicMock()
    doc_snapshot_mock.exists = True
    doc_snapshot_mock.to_dict.return_value = {"mock_field": "mock_value_from_db"}
    doc_snapshot_mock.id = "mock_doc_id"
    doc_ref_mock = MagicMock()
    doc_ref_mock.get = AsyncMock(return_value=doc_snapshot_mock)
    doc_ref_mock.set = AsyncMock(return_value=None)
    doc_ref_mock.update = AsyncMock(return_value=None)
    doc_ref_mock.delete = AsyncMock(return_value=None)
    query_mock = MagicMock()
    query_mock.where.return_value = query_mock
    query_mock.order_by.return_value = query_mock
    query_mock.limit.return_value = query_mock

    async def mock_stream_gen(*args, **kwargs):
        snap = MagicMock()
        snap.exists = True
        snap.to_dict.return_value = {"mock_query_field": "mock_query_value"}
        snap.id = "mock_query_doc_id"
        yield snap

    query_mock.stream = mock_stream_gen
    collection_ref_mock = MagicMock()
    collection_ref_mock.document = MagicMock(return_value=doc_ref_mock)
    collection_ref_mock.where.return_value = query_mock
    collection_ref_mock.order_by.return_value = query_mock
    collection_ref_mock.limit.return_value = query_mock
    collection_ref_mock.stream = mock_stream_gen
    db_mock = MagicMock()
    db_mock.collection = MagicMock(return_value=collection_ref_mock)
    yield db_mock


# --- Test Client Fixtures ---

@pytest.fixture(scope="function")  # Use function scope to ensure clean app state per test
def app_instance_for_test():
    """Creates a fresh FastAPI app instance for testing."""
    app = FastAPI()
    # Include routers
    app.include_router(profile_routes.router)
    app.include_router(friend_routes.router)
    app.include_router(history_routes.router)
    app.include_router(analytics_routes.router)
    app.include_router(auth_routes.router)
    return app


@pytest.fixture
def client(
        app_instance_for_test,  # Use the fresh app instance
        test_user_1_token_data,
        mock_analytics_service,
        mock_friend_service,
        mock_history_service,
        mock_profile_service,
):
    """
    Provides a TestClient using a temporary app instance WHERE:
    - Auth middleware is NOT added.
    - get_current_user dependency IS overridden.
    - Service dependencies ARE overridden.
    """
    app = app_instance_for_test  # Get the fresh app

    # Apply overrides directly to the app instance
    app.dependency_overrides[dependencies.get_analytics_service] = lambda: mock_analytics_service
    app.dependency_overrides[dependencies.get_friend_service] = lambda: mock_friend_service
    app.dependency_overrides[dependencies.get_history_service] = lambda: mock_history_service
    app.dependency_overrides[dependencies.get_profile_service] = lambda: mock_profile_service
    app.dependency_overrides[dependencies.get_current_user] = lambda: test_user_1_token_data

    with TestClient(app) as test_client:
        yield test_client

    # Clean up overrides (important with function-scoped app)
    app.dependency_overrides = {}


@pytest.fixture
def client_no_auth_bypass(
        app_instance_for_test,  # Use the fresh app instance
        mock_analytics_service,
        mock_friend_service,
        mock_history_service,
        mock_profile_service,
):
    """
    Provides a TestClient using a temporary app instance WHERE:
    - Auth middleware IS added.
    - get_current_user dependency is NOT overridden.
    - Service dependencies ARE overridden.
    """
    app = app_instance_for_test  # Get the fresh app

    # Apply service overrides
    app.dependency_overrides[dependencies.get_analytics_service] = lambda: mock_analytics_service
    app.dependency_overrides[dependencies.get_friend_service] = lambda: mock_friend_service
    app.dependency_overrides[dependencies.get_history_service] = lambda: mock_history_service
    app.dependency_overrides[dependencies.get_profile_service] = lambda: mock_profile_service

    # Add the *real* middleware to this test app instance
    excluded_paths = [r"^/$", r"^/docs$", r"^/openapi.json$", r"^/redoc$"]
    app.add_middleware(FirebaseAuthMiddleware, exclude_paths=excluded_paths)

    with TestClient(app) as test_client:
        yield test_client

    # Clean up overrides
    app.dependency_overrides = {}

# Remove the autouse=True override fixture if it still exists
# @pytest.fixture(autouse=True) def override_dependencies_in_app(...): pass


================================================================================

Filename: tests/integration_whitebox/test_i_analytics_routes.py
Content:
# Filename: tests/integration_whitebox/test_i_analytics_routes.py
import uuid
from datetime import datetime, timezone, timedelta

from models.game_history import GameResult  # For result values
# Import models/schemas for validation
from schemas.analytics_schemas import (
    DailyStats, PlayerPerformance, GlobalStats
)


# Fixtures: client, mock_analytics_service, test_user_1_uid, test_user_2_uid from conftest.py

# --- Test Cases for /analytics/games/{game_id} POST ---

def test_record_game_analytics_success(client, mock_analytics_service, test_user_1_uid, test_user_2_uid):
    """Test successfully recording analytics for a game the user participated in."""
    # Arrange
    game_id = f"int_ana_{uuid.uuid4().hex}"
    now = datetime.now(timezone.utc)
    # Payload must match GameAnalyticsCreate schema
    analytics_payload = {
        "game_id": game_id,  # Note: Also in path, check if schema needs it
        "white_player_id": test_user_1_uid,  # Matches authenticated user
        "black_player_id": test_user_2_uid,
        "start_time": (now - timedelta(minutes=7)).isoformat(),
        "end_time": now.isoformat(),
        "result": GameResult.WHITE_WIN.value,
        "moves": ["e4", "e5", "Nf3", "Nc6"],
        "rating_change": {"white": 9, "black": -9},
        "game_type": "portal_gambit",
        "time_control": {"initial": 600, "increment": 0}
    }
    # Mock service success
    mock_analytics_service.record_game_analytics.return_value = True

    # Act
    response = client.post(f"/analytics/games/{game_id}", json=analytics_payload)

    # Assert
    assert response.status_code == 200
    assert response.json() == {"status": "success", "message": "Game analytics recorded successfully"}
    # Verify service call
    mock_analytics_service.record_game_analytics.assert_called_once()
    call_arg = mock_analytics_service.record_game_analytics.call_args[0][0]
    # Service receives a dictionary matching the payload + game_id from path
    assert isinstance(call_arg, dict)
    assert call_arg['game_id'] == game_id
    assert call_arg['white_player_id'] == test_user_1_uid
    assert call_arg['result'] == GameResult.WHITE_WIN.value  # Ensure correct data passed


def test_record_game_analytics_forbidden(client, mock_analytics_service, test_user_1_uid):
    """Test recording analytics for a game the user did NOT participate in."""
    # Arrange
    game_id = f"int_ana_forbidden_{uuid.uuid4().hex}"
    now = datetime.now(timezone.utc)
    analytics_payload = {
        "game_id": game_id,
        "white_player_id": "other_player_A",  # Not authenticated user
        "black_player_id": "other_player_B",  # Not authenticated user
        "start_time": (now - timedelta(minutes=3)).isoformat(),
        "end_time": now.isoformat(),
        "result": GameResult.DRAW.value,
        "moves": ["c4", "c5"],
        "rating_change": {"white": 0, "black": 0},
        "game_type": "standard",
        "time_control": {"initial": 180, "increment": 2}
    }

    # Act
    response = client.post(f"/analytics/games/{game_id}", json=analytics_payload)

    # Assert: Route should return 403
    assert response.status_code == 403
    assert "Can only record analytics for games you participated in" in response.json().get("detail", "")
    mock_analytics_service.record_game_analytics.assert_not_called()


def test_record_game_analytics_service_fails(client, mock_analytics_service, test_user_1_uid):
    """Test recording analytics when the service layer returns False."""
    # Arrange: Payload is valid (contains all required fields), but service fails
    game_id = f"int_ana_fail_{uuid.uuid4().hex}"
    now = datetime.now(timezone.utc)
    start_time = now - timedelta(minutes=6)
    analytics_payload = {
        "game_id": game_id,  # Required
        "white_player_id": test_user_1_uid,  # Required
        "black_player_id": "opponent_p2_fail",  # Required
        "start_time": start_time.isoformat(),  # Required
        "end_time": now.isoformat(),  # Required
        "result": GameResult.DRAW.value,  # Required
        "moves": ["e4", "e5", "Nf3"],  # Required
        "rating_change": {"white": 0, "black": 0},  # Required
        "game_type": "portal_gambit_fail",  # Required
        "time_control": {"initial": 300, "increment": 1}  # Required
    }
    mock_analytics_service.record_game_analytics.return_value = False  # Simulate failure

    # Act
    response = client.post(f"/analytics/games/{game_id}", json=analytics_payload)

    # Assert: Check response reflects service failure
    assert response.status_code == 500  # Route succeeded (service failed)
    assert "Failed to record game analytics" in response.json().get("detail", "")
    mock_analytics_service.record_game_analytics.assert_called_once()
    # Optional: Check the argument passed
    call_arg = mock_analytics_service.record_game_analytics.call_args[0][0]
    assert isinstance(call_arg, dict)
    assert call_arg['game_id'] == game_id
    assert call_arg['result'] == GameResult.DRAW.value


def test_record_game_analytics_validation_error(client, mock_analytics_service):
    """Test recording analytics with missing required fields in payload."""
    # Arrange: Missing 'black_player_id', 'result', 'moves', etc.
    game_id = f"int_ana_invalid_{uuid.uuid4().hex}"
    analytics_payload = {
        "game_id": game_id,
        "white_player_id": "some_user",  # Need at least one field
    }

    # Act
    response = client.post(f"/analytics/games/{game_id}", json=analytics_payload)

    # Assert: FastAPI validation should return 422
    assert response.status_code == 422
    mock_analytics_service.record_game_analytics.assert_not_called()


# --- Test Cases for /analytics/daily/{date} GET ---

def test_get_daily_stats_success(client, mock_analytics_service):
    """Test getting daily stats when service returns data."""
    # Arrange
    test_date_str = "2024-02-15T12:00:00Z"  # Valid ISO date string
    # Mock service to return DailyStats object (use fixture or create instance)
    mock_stats = DailyStats(
        total_games=10, average_duration=500.0, average_moves=55.0, white_wins=4,
        black_wins=5, draws=1, abandoned=0, game_types={'portal': 10}, time_controls={'300/5': 10}
    )
    mock_analytics_service.get_daily_stats.return_value = mock_stats

    # Act
    response = client.get(f"/analytics/daily/{test_date_str}")

    # Assert: Response should be the serialized DailyStats data
    assert response.status_code == 200
    response_data = response.json()
    assert response_data["total_games"] == mock_stats.total_games
    assert response_data["white_wins"] == mock_stats.white_wins
    assert response_data["game_types"] == mock_stats.game_types
    # Assert service call (FastAPI parses path date string to datetime)
    mock_analytics_service.get_daily_stats.assert_called_once()
    call_arg = mock_analytics_service.get_daily_stats.call_args[0][0]
    assert isinstance(call_arg, datetime)
    assert call_arg.year == 2024
    assert call_arg.month == 2
    assert call_arg.day == 15


def test_get_daily_stats_invalid_date(client, mock_analytics_service):
    """Test getting daily stats with an invalid date format in path."""
    # Arrange
    invalid_date_str = "15-Feb-2024"

    # Act
    response = client.get(f"/analytics/daily/{invalid_date_str}")

    # Assert: FastAPI path param validation should fail
    assert response.status_code == 422
    mock_analytics_service.get_daily_stats.assert_not_called()


# --- Test Cases for /analytics/players/{user_id}/performance GET ---

def test_get_player_performance_success(client, mock_analytics_service, test_user_2_uid):
    """Test getting player performance when service returns data."""
    # Arrange
    user_id_to_get = test_user_2_uid
    days = 90
    # Mock service returns PlayerPerformance object
    mock_perf = PlayerPerformance(
        rating_progression=[{'ts': '...', 'change': 5}], average_game_duration=600.0,
        preferred_time_control='900/10', preferred_game_type='portal', win_rate=0.65,
        performance_by_color={'white': {'games': 10, 'wins': 7}, 'black': {'games': 12, 'wins': 7}},
        average_moves_per_game=62.0
    )
    mock_analytics_service.get_player_performance.return_value = mock_perf

    # Act
    response = client.get(f"/analytics/players/{user_id_to_get}/performance?days={days}")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    # Check some key fields match serialized mock data
    assert response_data["win_rate"] == mock_perf.win_rate
    assert response_data["preferred_game_type"] == mock_perf.preferred_game_type
    assert response_data["performance_by_color"]["white"]["wins"] == 7
    # Assert service call with correct params
    mock_analytics_service.get_player_performance.assert_called_once_with(user_id_to_get, days)


def test_get_player_performance_default_days(client, mock_analytics_service, test_user_1_uid):
    """Test getting player performance using the default days parameter."""
    # Arrange
    user_id_to_get = test_user_1_uid
    default_days = 30  # From route definition default
    mock_analytics_service.get_player_performance.return_value = PlayerPerformance(rating_progression=[],
                                                                                   average_game_duration=0,
                                                                                   preferred_time_control=None,
                                                                                   preferred_game_type=None, win_rate=0,
                                                                                   performance_by_color={},
                                                                                   average_moves_per_game=0)

    # Act: Call without explicit days param
    response = client.get(f"/analytics/players/{user_id_to_get}/performance")

    # Assert
    assert response.status_code == 200
    assert response.json()["win_rate"] == 0  # Check against mock return
    # Verify service called with default days
    mock_analytics_service.get_player_performance.assert_called_once_with(user_id_to_get, default_days)


# --- Test Cases for /analytics/global GET ---

def test_get_global_stats_success(client, mock_analytics_service):
    """Test getting global stats when service returns data."""
    # Arrange: Mock service returns GlobalStats object
    now = datetime.now(timezone.utc)
    mock_global = GlobalStats(
        total_games=5000, white_win_rate=0.485, average_game_duration=550.0,
        average_moves_per_game=58.2, popular_time_controls={'600/5': 2000},
        popular_game_types={'portal': 4800}, last_updated=now
    )
    mock_analytics_service.get_global_stats.return_value = mock_global

    # Act
    response = client.get("/analytics/global")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    # Check response matches serialized mock data
    assert response_data["total_games"] == mock_global.total_games
    assert response_data["white_win_rate"] == mock_global.white_win_rate
    assert response_data["last_updated"] == mock_global.last_updated.isoformat().replace('+00:00', 'Z')
    # Assert service call
    mock_analytics_service.get_global_stats.assert_called_once_with()


================================================================================

Filename: tests/integration_whitebox/test_i_auth_routes.py
Content:
# Filename: tests/integration_whitebox/test_i_auth_routes.py
from unittest.mock import patch

import pytest
from fastapi import HTTPException

from utils import jwt_utils


# Fixtures: client_no_auth_bypass, mock_verify_firebase_token from conftest.py

# --- Test Cases for /auth/token ---

# @patch("utils.jwt_utils.create_tokens_for_user")  # Mock our internal token creation
def test_get_token_success(
        mocker,  # Mocked jwt_utils function
        client_no_auth_bypass,  # TestClient without auth middleware bypassed
        mock_verify_firebase_token  # Mocked firebase_admin.auth.verify_id_token
):
    """Test successfully exchanging a Firebase token for backend tokens."""
    # Arrange: Configure mocks
    firebase_token_input = "valid-firebase-id-token-string"
    # mock_verify_firebase_token is already configured in conftest to return sample data
    expected_firebase_payload = mock_verify_firebase_token.return_value
    mock_create_tokens = mocker.patch(
        "routes.auth_routes.create_tokens_for_user",
        return_value={
            "access_token": jwt_utils.create_access_token(expected_firebase_payload), # Generate a real token for verification
            "token_type": "bearer",
            "expires_in": 3600
        }
    )
    # Act: Call the endpoint
    response = client_no_auth_bypass.post("/auth/token", json={"firebase_token": firebase_token_input})

    # Assert: Check status code and response body
    assert response.status_code == 200
    data = response.json()
    assert "access_token" in data
    assert isinstance(data["access_token"], str)
    assert data["token_type"] == "bearer"
    assert data["expires_in"] > 0

    # Decode the ACTUAL token returned to verify claims
    try:
        # Use the actual verify_token function (or jwt.decode directly)
        # Make sure your test environment has JWT_SECRET_KEY set correctly
        payload = jwt_utils.verify_token(data["access_token"])
        assert payload["uid"] == expected_firebase_payload["uid"]  # Verify claims
        assert payload["email"] == expected_firebase_payload.get("email")
    except Exception as e:
        pytest.fail(f"Failed to decode/verify the generated token: {e}")

    # Assert: Check that mocks were called correctly
    mock_verify_firebase_token.assert_called_once_with(firebase_token_input)
    mock_create_tokens.assert_called_once_with(expected_firebase_payload)  # Assert the patched function was called


def test_get_token_invalid_firebase_token(client_no_auth_bypass, mock_verify_firebase_token):
    """Test exchanging an invalid Firebase token."""
    # Arrange: Configure mock to raise exception
    firebase_token_input = "invalid-firebase-token"
    mock_verify_firebase_token.side_effect = Exception("Firebase verification failed mock")

    # Act
    response = client_no_auth_bypass.post("/auth/token", json={"firebase_token": firebase_token_input})

    # Assert
    assert response.status_code == 401
    assert "Invalid Firebase token" in response.json().get("detail", "")
    mock_verify_firebase_token.assert_called_once_with(firebase_token_input)


def test_get_token_missing_payload_field(client_no_auth_bypass):
    """Test calling /auth/token with missing 'firebase_token' field."""
    response = client_no_auth_bypass.post("/auth/token", json={"wrong_field": "some_token"})
    assert response.status_code == 422  # Validation error


def test_get_token_empty_payload(client_no_auth_bypass):
    """Test calling /auth/token with an empty JSON body."""
    response = client_no_auth_bypass.post("/auth/token", json={})
    assert response.status_code == 422  # Validation error


# --- Test Cases for /auth/verify ---

@patch(
    "utils.jwt_utils.verify_token")  # Keep mocking verify_token for this test? Maybe not needed if testing the route directly
def test_verify_token_success(mock_verify_jwt, client_no_auth_bypass):
    # Arrange
    # Generate a valid token using the utils
    valid_payload = {"uid": "verified-user-uid", "email": "verified@example.com"}
    backend_token_input = jwt_utils.create_access_token(valid_payload)  # Use the util!

    # Set up the mock to return the payload IF verify_token is still mocked
    mock_verify_jwt.return_value = valid_payload
    headers = {"Authorization": f"Bearer {backend_token_input}"}

    # Act
    response = client_no_auth_bypass.get("/auth/verify", headers=headers)

    # Assert
    assert response.status_code == 200
    data = response.json()
    assert data["uid"] == "verified-user-uid"
    # Assert mock called correctly (if still mocking)
    # mock_verify_jwt.assert_called_once_with(backend_token_input)


# @patch("utils.jwt_utils.verify_token")
def test_verify_token_invalid(client_no_auth_bypass): # Remove the mock argument
    # ... rest of the test ...
    # Make sure the token is structurally invalid enough to cause jose error
    backend_token_input = "this.is.invalid"
    headers = {"Authorization": f"Bearer {backend_token_input}"}
    response = client_no_auth_bypass.get("/auth/verify", headers=headers)
    # Assert based on the HTTPException raised by the middleware when it catches JWTError
    assert response.status_code == 401
    assert "Could not validate credentials" in response.json().get("detail", "")


def test_verify_token_missing_header(client_no_auth_bypass):
    """Test calling /auth/verify without the Authorization header."""
    response = client_no_auth_bypass.get("/auth/verify")
    # FastAPI's dependency injection for Security raises 403 if header is missing
    assert response.status_code == 403


def test_verify_token_malformed_header(client_no_auth_bypass):
    """Test calling /auth/verify with a malformed Authorization header."""
    headers = {"Authorization": "NotBearer some_token"}
    response = client_no_auth_bypass.get("/auth/verify", headers=headers)
    # FastAPI's HTTPBearer dependency raises 403 if scheme doesn't match
    assert response.status_code == 403


================================================================================

Filename: tests/integration_whitebox/test_i_friend_routes.py
Content:
# Filename: tests/integration_whitebox/test_i_friend_routes.py

# Import models/schemas used for request/response validation

# Fixtures: client, mock_friend_service, sample_friend_request, sample_friend_status,
# test_user_1_uid, test_user_2_uid from conftest.py

# --- Test Cases for /friends/requests POST ---

def test_send_friend_request_success(client, mock_friend_service, test_user_1_uid, test_user_2_uid):
    """Test successfully sending a friend request."""
    # Arrange: Prepare payload matching FriendRequestCreate schema
    request_payload = {
        "receiver_id": test_user_2_uid,
        "message": "Integration test request!"
    }
    # Mock service success
    mock_friend_service.send_friend_request.return_value = True

    # Act: Make the POST request
    response = client.post("/friends/requests", json=request_payload)

    # Assert: Check response and service call
    assert response.status_code == 200
    assert response.json() == {"status": "success", "message": "Friend request sent successfully"}
    # Verify service called with correct sender (authenticated user) and payload data
    mock_friend_service.send_friend_request.assert_called_once_with(
        sender_id=test_user_1_uid,  # From authenticated user context
        receiver_id=test_user_2_uid,
        message="Integration test request!"
    )


def test_send_friend_request_service_fails(client, mock_friend_service, test_user_1_uid, test_user_2_uid):
    """Test sending request when the service layer returns False."""
    # Arrange
    request_payload = {"receiver_id": test_user_2_uid}
    mock_friend_service.send_friend_request.return_value = False  # Simulate service failure

    # Act
    response = client.post("/friends/requests", json=request_payload)

    # Assert: Check response reflects service failure
    assert response.status_code == 409  # Route succeeded
    assert "Failed to send friend request" in response.json().get("detail", "")
    mock_friend_service.send_friend_request.assert_called_once()


def test_send_friend_request_validation_error(client, mock_friend_service):
    """Test sending request with missing required 'receiver_id'."""
    # Arrange: Invalid payload
    request_payload = {"message": "Missing receiver"}

    # Act
    response = client.post("/friends/requests", json=request_payload)

    # Assert: FastAPI validation should return 422
    assert response.status_code == 422
    mock_friend_service.send_friend_request.assert_not_called()


# --- Test Cases for /friends/requests/pending GET ---

def test_get_pending_requests_success(client, mock_friend_service, sample_friend_request, test_user_1_uid):
    """Test getting pending requests when service returns data."""
    # Arrange: Mock service to return a list containing the sample request
    mock_friend_service.get_pending_requests.return_value = [sample_friend_request]

    # Act
    response = client.get("/friends/requests/pending")

    # Assert: Check response matches serialized mock data
    assert response.status_code == 200
    response_data = response.json()
    assert isinstance(response_data, list)
    assert len(response_data) == 1
    # Compare key fields (datetime will be serialized)
    assert response_data[0]["request_id"] == sample_friend_request.request_id
    assert response_data[0]["sender_id"] == sample_friend_request.sender_id
    assert response_data[0]["receiver_id"] == sample_friend_request.receiver_id
    assert response_data[0]["status"] == sample_friend_request.status.value  # Enum serialized to value

    # Assert service called with authenticated user's ID
    mock_friend_service.get_pending_requests.assert_called_once_with(test_user_1_uid)


def test_get_pending_requests_empty(client, mock_friend_service, test_user_1_uid):
    """Test getting pending requests when service returns an empty list."""
    # Arrange: Mock service returns empty list
    mock_friend_service.get_pending_requests.return_value = []

    # Act
    response = client.get("/friends/requests/pending")

    # Assert
    assert response.status_code == 200
    assert response.json() == []
    mock_friend_service.get_pending_requests.assert_called_once_with(test_user_1_uid)


# --- Test Cases for /friends/requests/{request_id}/respond POST ---

def test_respond_to_request_accept_success(client, mock_friend_service, sample_friend_request, test_user_1_uid):
    """Test accepting a pending friend request successfully."""
    # Arrange
    request_id = sample_friend_request.request_id
    # Ensure the sample request is directed TO the authenticated user
    sample_friend_request.receiver_id = test_user_1_uid
    # Mock service calls
    mock_friend_service.get_friend_request.return_value = sample_friend_request
    mock_friend_service.respond_to_request.return_value = True
    respond_payload = {"accept": True}  # Matches schema (used in route logic, not FriendRequestResponse schema)

    # Act
    response = client.post(f"/friends/requests/{request_id}/respond", json=respond_payload)

    # Assert
    assert response.status_code == 200
    assert response.json()["status"] == "success"
    assert "accepted successfully" in response.json()["message"]
    mock_friend_service.get_friend_request.assert_called_once_with(request_id)
    mock_friend_service.respond_to_request.assert_called_once_with(request_id, True)


def test_respond_to_request_reject_success(client, mock_friend_service, sample_friend_request, test_user_1_uid):
    """Test rejecting a pending friend request successfully."""
    # Arrange
    request_id = sample_friend_request.request_id
    sample_friend_request.receiver_id = test_user_1_uid
    mock_friend_service.get_friend_request.return_value = sample_friend_request
    mock_friend_service.respond_to_request.return_value = True
    respond_payload = {"accept": False}

    # Act
    response = client.post(f"/friends/requests/{request_id}/respond", json=respond_payload)

    # Assert
    assert response.status_code == 200
    assert response.json()["status"] == "success"
    assert "rejected successfully" in response.json()["message"]
    mock_friend_service.get_friend_request.assert_called_once_with(request_id)
    mock_friend_service.respond_to_request.assert_called_once_with(request_id, False)


def test_respond_to_request_not_found(client, mock_friend_service):
    """Test responding when the request_id doesn't exist."""
    # Arrange
    request_id = "non-existent-req"
    mock_friend_service.get_friend_request.return_value = None  # Simulate not found
    respond_payload = {"accept": True}

    # Act
    response = client.post(f"/friends/requests/{request_id}/respond", json=respond_payload)

    # Assert: Route should raise 404
    assert response.status_code == 404
    assert "Friend request not found" in response.json().get("detail", "")
    mock_friend_service.get_friend_request.assert_called_once_with(request_id)
    mock_friend_service.respond_to_request.assert_not_called()


def test_respond_to_request_forbidden(client, mock_friend_service, sample_friend_request, test_user_1_uid):
    """Test responding to a request not intended for the authenticated user."""
    # Arrange
    request_id = sample_friend_request.request_id
    # Ensure receiver is NOT the authenticated user
    sample_friend_request.receiver_id = "another_user_id"
    mock_friend_service.get_friend_request.return_value = sample_friend_request
    respond_payload = {"accept": True}

    # Act
    response = client.post(f"/friends/requests/{request_id}/respond", json=respond_payload)

    # Assert: Route should raise 403
    assert response.status_code == 403
    assert "Cannot respond to requests for other users" in response.json().get("detail", "")
    mock_friend_service.get_friend_request.assert_called_once_with(request_id)
    mock_friend_service.respond_to_request.assert_not_called()


def test_respond_to_request_service_fails(client, mock_friend_service, sample_friend_request, test_user_1_uid):
    """Test responding when the service layer fails the operation."""
    # Arrange
    request_id = sample_friend_request.request_id
    sample_friend_request.receiver_id = test_user_1_uid
    mock_friend_service.get_friend_request.return_value = sample_friend_request
    mock_friend_service.respond_to_request.return_value = False  # Simulate service failure
    respond_payload = {"accept": True}

    # Act
    response = client.post(f"/friends/requests/{request_id}/respond", json=respond_payload)

    # Assert: Check response reflects service failure
    assert response.status_code == 400
    # FIX: Assert detail format
    assert response.json() == {"detail": "Failed to respond to friend request (e.g., request not pending or db error)"}
    mock_friend_service.get_friend_request.assert_called_once_with(request_id)
    mock_friend_service.respond_to_request.assert_called_once_with(request_id, True)


# --- Test Cases for /friends/list GET ---

def test_get_friends_list_success(client, mock_friend_service, sample_friend_status, test_user_1_uid):
    """Test getting the friend list when service returns data."""
    # Arrange: Mock service returns a list containing the sample status
    mock_friend_service.get_friends.return_value = [sample_friend_status]

    # Act
    response = client.get("/friends/list")

    # Assert: Check response matches serialized mock data
    assert response.status_code == 200
    response_data = response.json()
    assert isinstance(response_data, list)
    assert len(response_data) == 1
    assert response_data[0]["user_id"] == sample_friend_status.user_id
    assert response_data[0]["friend_id"] == sample_friend_status.friend_id
    assert response_data[0]["games_played"] == sample_friend_status.games_played

    # Assert service called correctly
    mock_friend_service.get_friends.assert_called_once_with(test_user_1_uid)


def test_get_friends_list_empty(client, mock_friend_service, test_user_1_uid):
    """Test getting the friend list when the user has no friends."""
    # Arrange: Mock service returns empty list
    mock_friend_service.get_friends.return_value = []

    # Act
    response = client.get("/friends/list")

    # Assert
    assert response.status_code == 200
    assert response.json() == []
    mock_friend_service.get_friends.assert_called_once_with(test_user_1_uid)


# --- Test Cases for /friends/{friend_id} DELETE ---

def test_remove_friend_success(client, mock_friend_service, test_user_1_uid, test_user_2_uid):
    """Test successfully removing a friend."""
    # Arrange
    friend_id_to_remove = test_user_2_uid
    mock_friend_service.remove_friend.return_value = True

    # Act
    response = client.delete(f"/friends/{friend_id_to_remove}")

    # Assert
    assert response.status_code == 200
    assert response.json() == {"status": "success", "message": "Friend removed successfully"}
    # Verify service called with authenticated user and the friend ID from path
    mock_friend_service.remove_friend.assert_called_once_with(test_user_1_uid, friend_id_to_remove)


def test_remove_friend_service_fails(client, mock_friend_service, test_user_1_uid, test_user_2_uid):
    """Test removing a friend when the service layer fails."""
    # Arrange
    friend_id_to_remove = test_user_2_uid
    mock_friend_service.remove_friend.return_value = False  # Simulate failure

    # Act
    response = client.delete(f"/friends/{friend_id_to_remove}")

    # Assert
    assert response.status_code == 400  # Route succeeded
    assert response.json() == {"detail": "Failed to remove friend (e.g., not friends or db error)"}
    mock_friend_service.remove_friend.assert_called_once_with(test_user_1_uid, friend_id_to_remove)


# --- Test Cases for /friends/{friend_id}/interactions POST ---

def test_update_friend_interaction_success(client, mock_friend_service, test_user_1_uid, test_user_2_uid):
    """Test successfully updating friend interaction."""
    # Arrange
    friend_id = test_user_2_uid
    interaction_payload = {"game_id": "game_xyz_123"}  # Matches FriendInteractionUpdate
    mock_friend_service.update_last_interaction.return_value = True

    # Act
    response = client.post(f"/friends/{friend_id}/interactions", json=interaction_payload)

    # Assert
    assert response.status_code == 200
    assert response.json() == {"status": "success", "message": "Interaction updated successfully"}
    # Verify service call
    mock_friend_service.update_last_interaction.assert_called_once_with(
        test_user_1_uid,
        friend_id,
        "game_xyz_123"  # game_id from payload
    )


def test_update_friend_interaction_no_game_id(client, mock_friend_service, test_user_1_uid, test_user_2_uid):
    """Test updating interaction without a game_id (payload is optional)."""
    # Arrange
    friend_id = test_user_2_uid
    interaction_payload = {}  # Empty payload, game_id is optional in schema
    mock_friend_service.update_last_interaction.return_value = True

    # Act
    response = client.post(f"/friends/{friend_id}/interactions", json=interaction_payload)

    # Assert
    assert response.status_code == 200
    assert response.json()["status"] == "success"
    # Verify service call with game_id=None
    mock_friend_service.update_last_interaction.assert_called_once_with(
        test_user_1_uid,
        friend_id,
        None  # Default or None passed when game_id is missing
    )


def test_update_friend_interaction_service_fails(client, mock_friend_service, test_user_1_uid, test_user_2_uid):
    """Test updating interaction when the service layer fails."""
    # Arrange
    friend_id = test_user_2_uid
    interaction_payload = {"game_id": "game_fail"}
    mock_friend_service.update_last_interaction.return_value = False  # Simulate failure

    # Act
    response = client.post(f"/friends/{friend_id}/interactions", json=interaction_payload)

    # Assert: Route raises 400 on service failure
    assert response.status_code == 400
    assert "Failed to update interaction" in response.json().get("detail", "")
    mock_friend_service.update_last_interaction.assert_called_once()


================================================================================

Filename: tests/integration_whitebox/test_i_history_routes.py
Content:
# Filename: tests/integration_whitebox/test_i_history_routes.py
import uuid
from datetime import datetime, timezone, timedelta

# Import models/schemas for validation
from models.game_history import GameHistory, GameResult
from schemas.history_schemas import (
    UserGameStats, OpeningStats
)


# Fixtures: client, mock_history_service, sample_game_history,
# test_user_1_uid, test_user_2_uid from conftest.py

# --- Test Cases for /history/games POST ---

def test_archive_game_success(client, mock_history_service, test_user_1_uid, test_user_2_uid):
    """Test successfully archiving a game where the authenticated user participated."""
    # Arrange: Create payload matching GameHistory model
    now = datetime.now(timezone.utc)
    game_payload = {
        "game_id": f"int_hist_{uuid.uuid4().hex}",
        "white_player_id": test_user_1_uid,  # Authenticated user
        "black_player_id": test_user_2_uid,
        "start_time": (now - timedelta(minutes=12)).isoformat(),
        "end_time": now.isoformat(),
        "result": GameResult.BLACK_WIN.value,  # Use enum value
        "winner_id": test_user_2_uid,
        "moves": ["d4", "Nf6", "c4", "e6"],
        "initial_position": "rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1",
        "white_rating": 1400,
        "black_rating": 1410,
        "rating_change": {"white": -6, "black": 6},
        "game_type": "portal_gambit",
        "time_control": {"initial": 1800, "increment": 15}
    }
    # Mock service success
    mock_history_service.archive_game.return_value = True

    # Act
    response = client.post("/history/games", json=game_payload)

    # Assert
    assert response.status_code == 200
    assert response.json() == {"status": "success", "message": "Game archived successfully"}
    # Verify service called with a GameHistory object
    mock_history_service.archive_game.assert_called_once()
    call_arg = mock_history_service.archive_game.call_args[0][0]
    assert isinstance(call_arg, GameHistory)
    assert call_arg.game_id == game_payload["game_id"]
    assert call_arg.white_player_id == test_user_1_uid


def test_archive_game_forbidden(client, mock_history_service, test_user_1_uid):
    """Test archiving a game where the authenticated user did NOT participate."""
    # Arrange
    now = datetime.now(timezone.utc)
    game_payload = {
        "game_id": f"int_hist_forbidden_{uuid.uuid4().hex}",
        "white_player_id": "other_player_1",  # Not authenticated user
        "black_player_id": "other_player_2",  # Not authenticated user
        "start_time": (now - timedelta(minutes=5)).isoformat(),
        "end_time": now.isoformat(),
        "result": GameResult.DRAW.value,
        "winner_id": None,
        "moves": ["e4", "e5"],
        "white_rating": 1000, "black_rating": 1000,
        "rating_change": {"white": 0, "black": 0},
        "game_type": "standard", "time_control": {"initial": 60, "increment": 0}
    }

    # Act
    response = client.post("/history/games", json=game_payload)

    # Assert: Route should return 403
    assert response.status_code == 403
    assert "Can only archive games you participated in" in response.json().get("detail", "")
    mock_history_service.archive_game.assert_not_called()


def test_archive_game_service_fails(client, mock_history_service, test_user_1_uid):
    """Test archiving when the service layer returns False."""
    # Arrange: Payload is valid (contains all required fields), but service fails
    now = datetime.now(timezone.utc)
    start_time = now - timedelta(minutes=5)
    game_payload = {
        "game_id": "fail_game_archive",  # Required
        "white_player_id": test_user_1_uid,  # Required
        "black_player_id": "opponent_p2",  # Required
        "start_time": start_time.isoformat(),  # Optional (can be sent)
        "end_time": now.isoformat(),  # Required
        "result": GameResult.DRAW.value,  # Required
        "winner_id": None,  # Optional
        "moves": ["e4", "e5"],  # Required
        "initial_position": "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1",  # Optional (has default)
        "white_rating": 1190,  # Required
        "black_rating": 1185,  # Required
        "rating_change": {"white": 0, "black": 0},  # Required
        "game_type": "portal_gambit",  # Optional (has default)
        "time_control": {"initial": 300, "increment": 0}  # Required
    }
    mock_history_service.archive_game.return_value = False  # Simulate failure

    # Act
    response = client.post("/history/games", json=game_payload)

    # Assert
    assert response.status_code == 200  # Route succeeded
    assert response.json() == {"status": "error", "message": "Failed to archive game"}
    mock_history_service.archive_game.assert_called_once()
    # Optional check on the argument passed to the service
    call_arg = mock_history_service.archive_game.call_args[0][0]
    assert isinstance(call_arg, GameHistory)
    assert call_arg.game_id == "fail_game_archive"
    assert call_arg.result == GameResult.DRAW


def test_archive_game_validation_error(client, mock_history_service, test_user_1_uid):
    """Test archiving with missing required fields in payload."""
    # Arrange: Missing 'black_player_id', 'result', 'moves', etc.
    game_payload = {
        "game_id": "invalid_game",
        "white_player_id": test_user_1_uid,
    }

    # Act
    response = client.post("/history/games", json=game_payload)

    # Assert: FastAPI validation should return 422
    assert response.status_code == 422
    mock_history_service.archive_game.assert_not_called()


# --- Test Cases for /history/games/{game_id} GET ---

def test_get_game_found(client, mock_history_service, sample_game_history):
    """Test retrieving a specific game when found by the service."""
    # Arrange: Mock service returns the sample game
    game_id = sample_game_history.game_id
    mock_history_service.get_game.return_value = sample_game_history

    # Act
    response = client.get(f"/history/games/{game_id}")

    # Assert: Response should be the serialized game data
    assert response.status_code == 200
    response_data = response.json()
    assert response_data["game_id"] == game_id
    assert response_data["white_player_id"] == sample_game_history.white_player_id
    assert response_data["result"] == sample_game_history.result.value
    # Compare a datetime field
    assert response_data["end_time"] == sample_game_history.end_time.isoformat().replace('+00:00', 'Z')
    # Assert service call
    mock_history_service.get_game.assert_called_once_with(game_id)


def test_get_game_not_found(client, mock_history_service):
    """Test retrieving a game when the service returns None."""
    # Arrange: Mock service returns None
    game_id = "non_existent_game_id"
    mock_history_service.get_game.return_value = None

    # Act
    response = client.get(f"/history/games/{game_id}")

    # Assert: Route should return 404
    assert response.status_code == 404
    assert "Game not found" in response.json().get("detail", "")
    mock_history_service.get_game.assert_called_once_with(game_id)


# --- Test Cases for /history/users/{user_id}/games GET ---

def test_get_user_games_success(client, mock_history_service, sample_game_history, test_user_1_uid):
    """Test getting user games when service returns data."""
    # Arrange
    user_id_to_get = test_user_1_uid
    limit = 15
    # Mock service returns list with sample game
    mock_history_service.get_user_games.return_value = [sample_game_history]

    # Act
    response = client.get(f"/history/users/{user_id_to_get}/games?limit={limit}")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    assert isinstance(response_data, list)
    assert len(response_data) == 1
    assert response_data[0]["game_id"] == sample_game_history.game_id
    # Assert service call with correct params from path and query
    mock_history_service.get_user_games.assert_called_once_with(user_id_to_get, limit)


def test_get_user_games_default_limit(client, mock_history_service, test_user_1_uid):
    """Test getting user games using the default limit."""
    # Arrange
    user_id_to_get = test_user_1_uid
    default_limit = 50  # From GameHistoryParams schema default
    mock_history_service.get_user_games.return_value = []  # Return empty list for simplicity

    # Act: Call without explicit limit query param
    response = client.get(f"/history/users/{user_id_to_get}/games")

    # Assert
    assert response.status_code == 200
    assert response.json() == []
    # Verify service called with the default limit
    mock_history_service.get_user_games.assert_called_once_with(user_id_to_get, default_limit)


# --- Test Cases for /history/games/between/{player1_id}/{player2_id} GET ---

def test_get_games_between_players_success(client, mock_history_service, sample_game_history, test_user_1_uid,
                                           test_user_2_uid):
    """Test getting games between two players when service returns data."""
    # Arrange
    player1 = test_user_1_uid
    player2 = test_user_2_uid
    limit = 8
    # Mock service returns list with sample game
    mock_history_service.get_games_between_players.return_value = [sample_game_history]

    # Act
    response = client.get(f"/history/games/between/{player1}/{player2}?limit={limit}")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    assert isinstance(response_data, list)
    assert len(response_data) == 1
    assert response_data[0]["game_id"] == sample_game_history.game_id
    # Assert service call with correct params
    mock_history_service.get_games_between_players.assert_called_once_with(player1, player2, limit)


def test_get_games_between_players_default_limit(client, mock_history_service, test_user_1_uid, test_user_2_uid):
    """Test getting games between players using the default limit."""
    # Arrange
    player1 = test_user_1_uid
    player2 = test_user_2_uid
    default_limit = 10  # From GamesBetweenPlayersParams schema default
    mock_history_service.get_games_between_players.return_value = []

    # Act: Call without explicit limit
    response = client.get(f"/history/games/between/{player1}/{player2}")

    # Assert
    assert response.status_code == 200
    assert response.json() == []
    # Verify service called with default limit
    mock_history_service.get_games_between_players.assert_called_once_with(player1, player2, default_limit)


# --- Test Cases for /history/users/{user_id}/stats GET ---

def test_get_user_stats_success(client, mock_history_service, test_user_1_uid):
    """Test getting user stats when service returns data."""
    # Arrange
    user_id_to_get = test_user_1_uid
    days = 60
    # Mock service returns UserGameStats data (use fixture or create dict)
    mock_stats_data = UserGameStats(
        total_games=25, wins=15, losses=8, draws=2, white_games=12, black_games=13,
        rating_change=45, average_game_length=750.5, total_moves=1200
    )
    mock_history_service.get_user_stats.return_value = mock_stats_data

    # Act
    response = client.get(f"/history/users/{user_id_to_get}/stats?days={days}")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    # Check response structure matches UserGameStats
    assert response_data["total_games"] == mock_stats_data.total_games
    assert response_data["wins"] == mock_stats_data.wins
    assert response_data["rating_change"] == mock_stats_data.rating_change
    # Assert service call
    mock_history_service.get_user_stats.assert_called_once_with(user_id_to_get, days)


def test_get_user_stats_default_days(client, mock_history_service, test_user_1_uid):
    """Test getting user stats using the default days parameter."""
    # Arrange
    user_id_to_get = test_user_1_uid
    default_days = 30  # From UserStatsParams schema default
    mock_history_service.get_user_stats.return_value = UserGameStats(total_games=0, wins=0, losses=0, draws=0,
                                                                     white_games=0, black_games=0, rating_change=0,
                                                                     average_game_length=0, total_moves=0)

    # Act: Call without explicit days
    response = client.get(f"/history/users/{user_id_to_get}/stats")

    # Assert
    assert response.status_code == 200
    assert response.json()["total_games"] == 0  # Check against mock return
    # Verify service called with default days
    mock_history_service.get_user_stats.assert_called_once_with(user_id_to_get, default_days)


# --- Test Cases for /history/openings/popular GET ---

def test_get_popular_openings_success(client, mock_history_service):
    """Test getting popular openings when service returns data."""
    # Arrange
    limit = 3
    # Mock service returns list of OpeningStats data
    mock_openings_data = [
        OpeningStats(moves="e4 c5 Nf3", count=50, wins=28),
        OpeningStats(moves="d4 Nf6 c4", count=40, wins=20),
        OpeningStats(moves="e4 e5 Nf3", count=35, wins=19),
    ]
    mock_history_service.get_popular_openings.return_value = mock_openings_data

    # Act
    response = client.get(f"/history/openings/popular?limit={limit}")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    assert isinstance(response_data, list)
    assert len(response_data) == 3
    assert response_data[0]["moves"] == "e4 c5 Nf3"
    assert response_data[0]["count"] == 50
    # Assert service call
    mock_history_service.get_popular_openings.assert_called_once_with(limit)


def test_get_popular_openings_default_limit(client, mock_history_service):
    """Test getting popular openings using the default limit."""
    # Arrange
    default_limit = 10  # From PopularOpeningsParams schema default
    mock_history_service.get_popular_openings.return_value = []

    # Act: Call without explicit limit
    response = client.get("/history/openings/popular")

    # Assert
    assert response.status_code == 200
    assert response.json() == []
    # Verify service called with default limit
    mock_history_service.get_popular_openings.assert_called_once_with(default_limit)


================================================================================

Filename: tests/integration_whitebox/test_i_profile_routes.py
Content:
from datetime import datetime, timezone
from unittest.mock import patch

# Import models/schemas used for request/response validation if needed
from models.user_profile import UserProfile


# Fixtures: client, mock_profile_service, sample_user_profile, test_user_1_uid from conftest.py

# --- Test Cases for /profiles/ ---

def test_create_profile_success(client, mock_profile_service, test_user_1_uid):
    """Test successfully creating a profile for the authenticated user."""
    # ... (Arrange profile_payload) ...
    profile_payload = {
        "uid": test_user_1_uid, "username": "integration_tester",  # ... rest of payload
        "email": "integration@example.com", "rating": 1210, "games_played": 1,
        "wins": 1, "losses": 0, "draws": 0, "friends": [], "achievements": [],
        "preferences": {}, "created_at": datetime.now(timezone.utc).isoformat(),
        "last_active": datetime.now(timezone.utc).isoformat(),
        "display_name": "Integration Tester", "avatar_url": None
    }
    # Mock the service call for create_profile
    mock_profile_service.create_profile.return_value = True
    # FIX: Also mock get_profile used internally by the route to check existence
    with patch.object(mock_profile_service, 'get_profile', return_value=None) as mock_get:
        # Act: Make the request
        response = client.post("/profiles/", json=profile_payload)

    # Assert: Check response and mock calls
    assert response.status_code == 201  # Check for 201 Created
    assert response.json()["status"] == "success"
    mock_get.assert_called_once_with(test_user_1_uid)  # Verify existence check
    mock_profile_service.create_profile.assert_called_once()
    # Verify the data passed to the service matches the Pydantic model instance
    call_arg = mock_profile_service.create_profile.call_args[0][0]
    assert isinstance(call_arg, UserProfile)
    assert call_arg.uid == test_user_1_uid
    assert call_arg.username == "integration_tester"


def test_create_profile_forbidden(client, mock_profile_service, test_user_1_uid):
    """Test creating a profile for a UID other than the authenticated user."""
    # Arrange: Payload UID differs from authenticated user's UID
    profile_payload = {
        "uid": "some-other-uid",  # Different from test_user_1_uid
        "username": "forbidden_user",
        "email": "forbidden@example.com",
        "rating": 1200, "games_played": 0, "wins": 0, "losses": 0, "draws": 0,
        "friends": [], "achievements": [], "preferences": {},
        "created_at": datetime.now(timezone.utc).isoformat(),
        "last_active": datetime.now(timezone.utc).isoformat(),
    }

    # Act
    response = client.post("/profiles/", json=profile_payload)

    # Assert
    assert response.status_code == 403
    assert "Cannot create profile for another user" in response.json().get("detail", "")
    mock_profile_service.create_profile.assert_not_called()


def test_create_profile_service_fails(client, mock_profile_service, test_user_1_uid):
    """Test profile creation when the service layer returns False."""
    # ... (Arrange profile_payload) ...
    profile_payload = {
        "uid": test_user_1_uid, "username": "fail_user", "email": "fail@example.com",
    }
    mock_profile_service.create_profile.return_value = False  # Simulate service failure
    # FIX: Also mock get_profile used internally by the route to check existence
    with patch.object(mock_profile_service, 'get_profile', return_value=None) as mock_get:
        # Act
        response = client.post("/profiles/", json=profile_payload)

    # Assert: Route should now raise 500 on service failure
    assert response.status_code == 500 # Assuming 500 is correct for DB failure
    # FIX: Assert detail format
    assert response.json() == {"detail": "Failed to create profile in database"}
    mock_get.assert_called_once_with(test_user_1_uid)  # Verify existence check
    mock_profile_service.create_profile.assert_called_once()
    # Optional deeper check: Verify the model instance passed to the service
    call_arg = mock_profile_service.create_profile.call_args[0][0]
    assert isinstance(call_arg, UserProfile)
    assert call_arg.uid == test_user_1_uid
    assert call_arg.username == "fail_user"
    assert call_arg.email == "fail@example.com"
    # Check that default values were applied by Pydantic before service call
    assert call_arg.rating == 1200
    assert call_arg.friends == []
    assert call_arg.preferences == {}


def test_create_profile_validation_error(client, mock_profile_service, test_user_1_uid):
    """Test profile creation with invalid data (e.g., missing required field)."""
    # Arrange: Missing 'email', 'username' which are likely required by UserProfile model
    profile_payload = {
        "uid": test_user_1_uid,
        "rating": 1100,
    }

    # Act
    response = client.post("/profiles/", json=profile_payload)

    # Assert: FastAPI should return 422
    assert response.status_code == 422
    mock_profile_service.create_profile.assert_not_called()


# --- Test Cases for /profiles/{uid} GET ---

def test_get_profile_found(client, mock_profile_service, sample_user_profile):
    """Test retrieving an existing profile by UID."""
    # Arrange: Mock service to return the sample profile
    uid_to_get = sample_user_profile.uid
    mock_profile_service.get_profile.return_value = sample_user_profile

    # Act
    response = client.get(f"/profiles/{uid_to_get}")

    # Assert: Check response matches the sample profile data (serialized)
    assert response.status_code == 200
    response_data = response.json()
    assert response_data["uid"] == uid_to_get
    assert response_data["username"] == sample_user_profile.username
    assert response_data["rating"] == sample_user_profile.rating
    # Compare a datetime field (requires careful parsing or string comparison)
    # FastAPI serializes datetime to ISO string by default
    assert response_data["created_at"] == sample_user_profile.created_at.isoformat().replace('+00:00', 'Z')

    # Assert service was called correctly
    mock_profile_service.get_profile.assert_called_once_with(uid_to_get)


def test_get_profile_not_found(client, mock_profile_service):
    """Test retrieving a profile that the service indicates is not found."""
    # Arrange: Mock service to return None
    uid_to_get = "non-existent-user"
    mock_profile_service.get_profile.return_value = None

    # Act
    response = client.get(f"/profiles/{uid_to_get}")

    # Assert: Route should return 404
    assert response.status_code == 404
    assert "Profile not found" in response.json().get("detail", "")
    mock_profile_service.get_profile.assert_called_once_with(uid_to_get)


# --- Test Cases for /profiles/{uid} PATCH ---

def test_update_profile_success(client, mock_profile_service, test_user_1_uid):
    """Test successfully updating the authenticated user's profile."""
    # Arrange: Prepare update payload matching ProfileUpdate schema
    uid_to_update = test_user_1_uid  # Matches authenticated user
    update_payload = {
        "display_name": "Updated Int Name",
        "avatar_url": "http://example.com/updated.png",
        "preferences": {"sound": False}
    }
    # Mock service success
    mock_profile_service.update_profile.return_value = True

    # Act
    response = client.patch(f"/profiles/{uid_to_update}", json=update_payload)

    # Assert: Check response and service call
    assert response.status_code == 200
    assert response.json() == {"status": "success", "message": "Profile updated successfully"}
    # Service should be called with a dict containing only the fields present in the payload
    # (due to exclude_unset=True in the route)
    mock_profile_service.update_profile.assert_called_once_with(
        uid_to_update,
        update_payload  # exclude_unset means only these fields are passed
    )


def test_update_profile_partial(client, mock_profile_service, test_user_1_uid):
    """Test updating only one field in the profile."""
    # Arrange
    uid_to_update = test_user_1_uid
    update_payload = {"display_name": "Just Display Name"}  # Only one field
    mock_profile_service.update_profile.return_value = True

    # Act
    response = client.patch(f"/profiles/{uid_to_update}", json=update_payload)

    # Assert
    assert response.status_code == 200
    assert response.json()["status"] == "success"
    # Verify only the provided field was passed to the service
    mock_profile_service.update_profile.assert_called_once_with(
        uid_to_update,
        {"display_name": "Just Display Name"}
    )


def test_update_profile_forbidden(client, mock_profile_service, test_user_1_uid):
    """Test attempting to update another user's profile."""
    # Arrange
    uid_to_update = "another-users-profile-id"  # Different UID
    update_payload = {"display_name": "Hacking Attempt"}

    # Act
    response = client.patch(f"/profiles/{uid_to_update}", json=update_payload)

    # Assert
    assert response.status_code == 403
    assert "Cannot update another user's profile" in response.json().get("detail", "")
    mock_profile_service.update_profile.assert_not_called()


def test_update_profile_service_fails(client, mock_profile_service, test_user_1_uid):
    """Test profile update when the service layer returns False."""
    # Arrange
    uid_to_update = test_user_1_uid
    update_payload = {"display_name": "Update Me Fail"}
    mock_profile_service.update_profile.return_value = False  # Simulate service failure

    # Act
    response = client.patch(f"/profiles/{uid_to_update}", json=update_payload)

    # Assert
    assert response.status_code == 500
    # FIX: Assert detail format
    assert response.json() == {"detail": "Failed to update profile in database"}
    mock_profile_service.update_profile.assert_called_once()


# --- Test Cases for /profiles/search/{username_prefix} ---

def test_search_profiles_found(client, mock_profile_service, sample_user_profile):
    """Test searching for profiles when the service finds results."""
    # Arrange
    prefix = "integ"
    mock_results = [sample_user_profile]  # Service returns a list containing the sample
    mock_profile_service.search_profiles.return_value = mock_results
    limit = 5

    # Act
    response = client.get(f"/profiles/search/{prefix}?limit={limit}")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    assert isinstance(response_data, list)
    assert len(response_data) == 1
    assert response_data[0]["uid"] == sample_user_profile.uid  # Compare response to mock data

    # Assert service call
    mock_profile_service.search_profiles.assert_called_once_with(prefix, limit)


def test_search_profiles_not_found(client, mock_profile_service):
    """Test searching for profiles when the service finds no results."""
    # Arrange
    prefix = "nonexistentprefix"
    mock_profile_service.search_profiles.return_value = []  # Service returns empty list
    limit = 10

    # Act
    response = client.get(f"/profiles/search/{prefix}?limit={limit}")

    # Assert
    assert response.status_code == 200
    assert response.json() == []
    mock_profile_service.search_profiles.assert_called_once_with(prefix, limit)


# --- Test Cases for /profiles/leaderboard/top ---

def test_get_leaderboard_success(client, mock_profile_service, sample_user_profile):
    """Test fetching the leaderboard when the service returns data."""
    # Arrange
    mock_leaderboard_data = [sample_user_profile]  # Simulate service returning leaderboard
    mock_profile_service.get_leaderboard.return_value = mock_leaderboard_data
    limit = 10

    # Act
    response = client.get(f"/profiles/leaderboard/top?limit={limit}")

    # Assert
    assert response.status_code == 200
    response_data = response.json()
    assert isinstance(response_data, list)
    assert len(response_data) == 1
    assert response_data[0]["uid"] == sample_user_profile.uid  # Compare response to mock

    # Assert service call
    mock_profile_service.get_leaderboard.assert_called_once_with(limit)


# --- Test Cases for /profiles/{uid}/achievements/{achievement_id} ---

def test_add_achievement_success(client, mock_profile_service, test_user_1_uid):
    """Test adding an achievement to the authenticated user's profile."""
    # Arrange
    uid = test_user_1_uid  # Matches authenticated user
    achievement_id = "integration_complete"
    # Mock service success
    mock_profile_service.add_achievement.return_value = True

    # Act: Route uses path params based on definition
    response = client.post(f"/profiles/{uid}/achievements/{achievement_id}")

    # Assert
    assert response.status_code == 200
    assert response.json() == {"status": "success", "message": "Achievement added successfully"}
    mock_profile_service.add_achievement.assert_called_once_with(uid, achievement_id)


def test_add_achievement_forbidden(client, mock_profile_service, test_user_1_uid):
    """Test attempting to add an achievement to another user's profile."""
    # Arrange
    uid = "another-user-achieve"  # Different UID
    achievement_id = "forbidden_achieve"

    # Act
    response = client.post(f"/profiles/{uid}/achievements/{achievement_id}")

    # Assert
    assert response.status_code == 403
    assert "Cannot modify another user's achievements" in response.json().get("detail", "")
    mock_profile_service.add_achievement.assert_not_called()


def test_add_achievement_service_fails(client, mock_profile_service, test_user_1_uid):
    """Test adding achievement when the service layer returns False."""
    # Arrange
    uid = test_user_1_uid
    achievement_id = "fail_achieve"
    mock_profile_service.add_achievement.return_value = False  # Simulate service failure

    # Act
    response = client.post(f"/profiles/{uid}/achievements/{achievement_id}")

    # Assert
    assert response.status_code == 500  # Route succeeded
    assert response.json() == {"detail": "Failed to add achievement"}
    mock_profile_service.add_achievement.assert_called_once_with(uid, achievement_id)


================================================================================

Filename: tests/unit_whitebox/test_u_analytics_service.py
Content:
# Filename: tests/unit_whitebox/test_u_analytics_service.py

from datetime import datetime, timezone, timedelta
from unittest.mock import AsyncMock, patch

import pytest

from models.game_history import GameResult  # Import enum for results
# Import the class to test and its dependencies/models
from services.analytics_service import AnalyticsService


# Fixtures `mock_db_client`, `test_user_1_uid`, `test_user_2_uid` from conftest.py

@pytest.fixture
def analytics_service(mock_db_client):
    """Creates an instance of the AnalyticsService with the mocked DB client."""
    return AnalyticsService(mock_db_client)


# --- Test Cases ---

@pytest.mark.asyncio
async def test_record_game_analytics_success(analytics_service, mock_db_client):
    """Test successfully recording analytics for a completed game."""
    start = datetime.now(timezone.utc) - timedelta(minutes=15)
    end = datetime.now(timezone.utc)
    duration_secs = (end - start).total_seconds()
    game_data = {
        'game_id': 'ana_game_1',
        'white_player_id': 'p_white',
        'black_player_id': 'p_black',
        'start_time': start,
        'end_time': end,
        'result': GameResult.DRAW,
        'moves': ['e4', 'e5'] * 15,  # 30 moves
        'rating_change': {'white': 1, 'black': -1},
        'game_type': 'portal_gambit',
        'time_control': {'initial': 600, 'increment': 5}
    }

    # Mock the underlying set_document call
    mock_set = AsyncMock(return_value=True)
    # Patch BaseService.set_document used by the service instance
    with patch.object(AnalyticsService, 'set_document', mock_set):
        result = await analytics_service.record_game_analytics(game_data)

    assert result is True
    # Verify the call to set_document
    mock_set.assert_called_once()
    call_args = mock_set.call_args[0]
    assert call_args[0] == 'analytics'  # collection name
    assert call_args[1] == 'game_ana_game_1'  # doc id format
    saved_data = call_args[2]  # The data dict saved
    assert saved_data['game_id'] == game_data['game_id']
    assert saved_data['duration'] == duration_secs
    assert saved_data['total_moves'] == 30
    assert saved_data['result'] == GameResult.DRAW
    assert saved_data['white_player_id'] == game_data['white_player_id']
    assert saved_data['rating_change'] == game_data['rating_change']
    assert saved_data['game_type'] == game_data['game_type']
    assert saved_data['time_control'] == game_data['time_control']
    assert 'timestamp' in saved_data  # Should be added by the service


@pytest.mark.asyncio
async def test_record_game_analytics_failure(analytics_service):
    """Test analytics recording when the database operation fails."""
    now = datetime.now(timezone.utc)
    game_data = {  # Add required fields accessed before set_document
        'game_id': 'fail_game',
        'start_time': now,
        'end_time': now,
        'moves': [],
        'result': 'draw',  # Add dummy
        'white_player_id': 'pW',  # Add dummy
        'black_player_id': 'pB',  # Add dummy
        'rating_change': {},  # Add dummy
        'game_type': 'test',  # Add dummy
        'time_control': {},  # Add dummy
    }
    with patch.object(AnalyticsService, 'set_document', AsyncMock(return_value=False)) as mock_set:
        result = await analytics_service.record_game_analytics(game_data)
    assert result is False
    mock_set.assert_called_once()


# --- Daily Stats Tests ---

@pytest.mark.asyncio
async def test_get_daily_stats_cache_hit(analytics_service):
    """Test hitting the cache for daily stats."""
    test_date = datetime(2024, 3, 10)
    cache_key = f"daily_stats_{test_date.strftime('%Y-%m-%d')}"
    cached_data = {'total_games': 5, 'mock': 'data'}

    with patch.object(AnalyticsService, 'get_document', AsyncMock(return_value=cached_data)) as mock_get, \
            patch.object(AnalyticsService, 'query_collection', new_callable=AsyncMock) as mock_query:
        stats = await analytics_service.get_daily_stats(test_date)

    assert stats == cached_data
    mock_get.assert_called_once_with('analytics_cache', cache_key)
    mock_query.assert_not_called()  # Should not query DB if cache hits


@pytest.mark.asyncio
async def test_get_daily_stats_cache_miss_no_data(analytics_service):
    """Test cache miss and no games found in the database."""
    test_date = datetime(2024, 3, 11)
    cache_key = f"daily_stats_{test_date.strftime('%Y-%m-%d')}"

    with patch.object(AnalyticsService, 'get_document', AsyncMock(return_value=None)) as mock_get, \
            patch.object(AnalyticsService, 'query_collection', AsyncMock(return_value=[])) as mock_query, \
            patch.object(AnalyticsService, 'set_document', AsyncMock(return_value=True)) as mock_set:
        stats = await analytics_service.get_daily_stats(test_date)

    mock_get.assert_called_once_with('analytics_cache', cache_key)
    mock_query.assert_called_once()  # DB query should happen
    assert stats['total_games'] == 0
    assert stats['white_wins'] == 0
    assert stats['average_duration'] == 0
    mock_set.assert_called_once_with('analytics_cache', cache_key, stats)  # Should cache empty stats


@pytest.mark.asyncio
async def test_get_daily_stats_calculation(analytics_service):
    """Test correct calculation of daily stats from fetched game data."""
    test_date = datetime(2024, 3, 12)
    cache_key = f"daily_stats_{test_date.strftime('%Y-%m-%d')}"
    start_time = datetime.combine(test_date, datetime.min.time())
    end_time = start_time + timedelta(days=1)

    # Mock game data returned by query
    mock_games = [
        {'duration': 300, 'total_moves': 40, 'result': GameResult.WHITE_WIN, 'game_type': 'standard',
         'time_control': {'initial': 300, 'increment': 0}},
        {'duration': 600, 'total_moves': 60, 'result': GameResult.BLACK_WIN, 'game_type': 'portal_gambit',
         'time_control': {'initial': 600, 'increment': 5}},
        {'duration': 450, 'total_moves': 50, 'result': GameResult.DRAW, 'game_type': 'portal_gambit',
         'time_control': {'initial': 600, 'increment': 5}},
        {'duration': 150, 'total_moves': 10, 'result': GameResult.ABANDONED, 'game_type': 'standard',
         'time_control': {'initial': 180, 'increment': 0}},
    ]

    with patch.object(AnalyticsService, 'get_document', AsyncMock(return_value=None)) as mock_get, \
            patch.object(AnalyticsService, 'query_collection', AsyncMock(return_value=mock_games)) as mock_query, \
            patch.object(AnalyticsService, 'set_document', AsyncMock(return_value=True)) as mock_set:
        stats = await analytics_service.get_daily_stats(test_date)

    assert stats['total_games'] == 4
    assert stats['white_wins'] == 1
    assert stats['black_wins'] == 1
    assert stats['draws'] == 1
    assert stats['abandoned'] == 1
    assert stats['average_duration'] == pytest.approx((300 + 600 + 450 + 150) / 4)
    assert stats['average_moves'] == pytest.approx((40 + 60 + 50 + 10) / 4)
    assert stats['game_types'] == {'standard': 2, 'portal_gambit': 2}
    # Time control key format depends on the service implementation
    expected_tc_key1 = f"{mock_games[0]['time_control']['initial']}/{mock_games[0]['time_control']['increment']}"
    expected_tc_key2 = f"{mock_games[1]['time_control']['initial']}/{mock_games[1]['time_control']['increment']}"
    expected_tc_key3 = f"{mock_games[3]['time_control']['initial']}/{mock_games[3]['time_control']['increment']}"
    assert stats['time_controls'] == {expected_tc_key1: 1, expected_tc_key2: 2, expected_tc_key3: 1}
    mock_set.assert_called_once_with('analytics_cache', cache_key, stats)  # Verify caching


# --- Player Performance Tests ---

@pytest.mark.asyncio
async def test_get_player_performance_no_games(analytics_service, test_user_1_uid):
    """Test player performance when the player has no games in the period."""
    user_id = test_user_1_uid
    days = 30
    with patch.object(AnalyticsService, 'query_collection', AsyncMock(return_value=[])) as mock_query:
        perf = await analytics_service.get_player_performance(user_id, days)

    assert mock_query.call_count == 2  # Called for white and black games
    assert perf['rating_progression'] == []
    assert perf['win_rate'] == 0
    assert perf['average_game_duration'] == 0


@pytest.mark.asyncio
async def test_get_player_performance_calculation(analytics_service, test_user_1_uid):
    """Test correct calculation of player performance stats."""
    user_id = test_user_1_uid
    days = 30
    start_date = datetime.now(timezone.utc) - timedelta(days=days)

    # Mock games involving the user
    game1 = {'timestamp': start_date + timedelta(days=1), 'white_player_id': user_id, 'black_player_id': 'p2',
             'result': GameResult.WHITE_WIN, 'rating_change': {'white': 8, 'black': -8}, 'duration': 400,
             'total_moves': 50, 'game_type': 'portal_gambit', 'time_control': {'initial': 600, 'increment': 5}}
    game2 = {'timestamp': start_date + timedelta(days=2), 'white_player_id': 'p3', 'black_player_id': user_id,
             'result': GameResult.BLACK_WIN, 'rating_change': {'white': -7, 'black': 7}, 'duration': 500,
             'total_moves': 60, 'game_type': 'portal_gambit', 'time_control': {'initial': 600, 'increment': 5}}
    game3 = {'timestamp': start_date + timedelta(days=3), 'white_player_id': user_id, 'black_player_id': 'p4',
             'result': GameResult.DRAW, 'rating_change': {'white': 0, 'black': 0}, 'duration': 300, 'total_moves': 40,
             'game_type': 'standard', 'time_control': {'initial': 300, 'increment': 0}}

    with patch.object(AnalyticsService, 'query_collection', new_callable=AsyncMock) as mock_query:
        # Simulate query results: user as white -> g1, g3; user as black -> g2
        mock_query.side_effect = [
            [game1, game3],  # Games where user_id is white
            [game2]  # Games where user_id is black
        ]
        perf = await analytics_service.get_player_performance(user_id, days)

    assert mock_query.call_count == 2
    assert len(perf['rating_progression']) == 3
    # Index 0: Game 1 (Correct)
    assert perf['rating_progression'][0] == {'timestamp': game1['timestamp'], 'rating_change': 8}
    assert perf['rating_progression'][1] == {'timestamp': game2['timestamp'], 'rating_change': 7} # Game 2 comes second
    assert perf['rating_progression'][2] == {'timestamp': game3['timestamp'], 'rating_change': 0}
    assert perf['average_game_duration'] == pytest.approx((400 + 500 + 300) / 3)
    assert perf['average_moves_per_game'] == pytest.approx((50 + 60 + 40) / 3)
    # Preferred TC/GT based on counts
    assert perf['preferred_time_control'] == '600/5'  # Appeared twice
    assert perf['preferred_game_type'] == 'portal_gambit'  # Appeared twice
    # Wins: g1 (as white), g2 (as black) -> 2 wins out of 3 games
    assert perf['win_rate'] == pytest.approx(2 / 3)
    # Performance by color
    assert perf['performance_by_color']['white']['games'] == 2
    assert perf['performance_by_color']['white']['wins'] == 1  # Only g1
    assert perf['performance_by_color']['black']['games'] == 1
    assert perf['performance_by_color']['black']['wins'] == 1  # Only g2


# --- Global Stats Tests ---

@pytest.mark.asyncio
async def test_get_global_stats_cache_hit_recent(analytics_service):
    """Test global stats cache hit when data is recent."""
    cache_key = 'global_stats'
    # Simulate cached data less than 1 hour old
    cached_data = {'total_games': 100, 'last_updated': datetime.now(timezone.utc) - timedelta(minutes=30)}

    with patch.object(AnalyticsService, 'get_document', AsyncMock(return_value=cached_data)) as mock_get, \
            patch.object(AnalyticsService, 'query_collection', new_callable=AsyncMock) as mock_query:
        stats = await analytics_service.get_global_stats()

    assert stats == cached_data
    mock_get.assert_called_once_with('analytics_cache', cache_key)
    mock_query.assert_not_called()


@pytest.mark.asyncio
async def test_get_global_stats_cache_hit_stale(analytics_service):
    """Test global stats cache hit when data is stale (needs recalculation)."""
    cache_key = 'global_stats'
    stale_cached_data = {'total_games': 50,
                         'last_updated': datetime.now(timezone.utc) - timedelta(hours=2)}  # Over 1 hour old
    # Mock new data from DB query
    mock_games_for_recalc = [
        {'duration': 300, 'total_moves': 40, 'result': GameResult.WHITE_WIN, 'game_type': 'standard',
         'time_control': {'initial': 300, 'increment': 0}},
        {'duration': 600, 'total_moves': 60, 'result': GameResult.BLACK_WIN, 'game_type': 'portal_gambit',
         'time_control': {'initial': 600, 'increment': 5}},
    ]

    with patch.object(AnalyticsService, 'get_document', AsyncMock(return_value=stale_cached_data)) as mock_get, \
            patch.object(AnalyticsService, 'query_collection',
                         AsyncMock(return_value=mock_games_for_recalc)) as mock_query, \
            patch.object(AnalyticsService, 'set_document', AsyncMock(return_value=True)) as mock_set:
        stats = await analytics_service.get_global_stats()

    mock_get.assert_called_once_with('analytics_cache', cache_key)
    mock_query.assert_called_once()  # Query should run due to stale cache
    assert stats['total_games'] == 2  # Recalculated total
    assert stats['white_win_rate'] == 0.5  # 1 white win out of 2 games
    assert stats['average_game_duration'] == pytest.approx((300 + 600) / 2)
    assert 'last_updated' in stats
    assert stats['last_updated'] > stale_cached_data['last_updated']  # Should be newer
    mock_set.assert_called_once()  # Should save recalculated stats to cache
    assert mock_set.call_args[0][0] == 'analytics_cache'
    assert mock_set.call_args[0][1] == cache_key


@pytest.mark.asyncio
async def test_get_global_stats_cache_miss(analytics_service):
    """Test global stats cache miss (needs calculation)."""
    cache_key = 'global_stats'
    # Similar to stale test, but get_document returns None
    mock_games_for_calc = [
        {'duration': 400, 'total_moves': 50, 'result': GameResult.WHITE_WIN, 'game_type': 'portal_gambit',
         'time_control': {'initial': 600, 'increment': 5}},
    ]
    with patch.object(AnalyticsService, 'get_document', AsyncMock(return_value=None)) as mock_get, \
            patch.object(AnalyticsService, 'query_collection',
                         AsyncMock(return_value=mock_games_for_calc)) as mock_query, \
            patch.object(AnalyticsService, 'set_document', AsyncMock(return_value=True)) as mock_set:
        stats = await analytics_service.get_global_stats()

    mock_get.assert_called_once_with('analytics_cache', cache_key)
    mock_query.assert_called_once()
    assert stats['total_games'] == 1
    assert stats['white_win_rate'] == 1.0
    mock_set.assert_called_once_with('analytics_cache', cache_key, stats)


================================================================================

Filename: tests/unit_whitebox/test_u_friend_service.py
Content:
import uuid
from datetime import datetime
from unittest.mock import AsyncMock, MagicMock, patch  # Import ANY

import pytest
# Import necessary Firestore types
from google.cloud.firestore_v1.async_query import AsyncQuery  # Import AsyncQuery
from google.cloud.firestore_v1.async_transaction import AsyncTransaction  # Import AsyncTransaction

# Import models and service
from models.friend import FriendRequest, FriendRequestStatus
# Import BaseService to patch its methods
from services.base_service import BaseService
from services.friend_service import FriendService


@pytest.fixture
def friend_service(mock_db_client):  # Use mock_db_client fixture
    """Creates an instance of the FriendService with the mocked DB client."""
    # FriendService __init__ takes db: AsyncClient
    return FriendService(mock_db_client)


@pytest.mark.asyncio
async def test_send_friend_request_success(friend_service, mock_db_client, test_user_1_uid, test_user_2_uid):
    # ... (Arrange sender_id, etc.) ...
    sender_id, receiver_id, message = test_user_1_uid, test_user_2_uid, "Hi!"
    test_uuid_obj = uuid.uuid4()
    request_id = f"req_{test_uuid_obj.hex}"

    # Mock BaseService.get_document
    mock_get_friendship = AsyncMock(return_value=None)

    # FIX: Correctly mock the query chain for checking existing requests
    mock_query_get_method = AsyncMock(return_value=[])  # This is what `await query.get()` returns
    mock_query_chain = MagicMock(spec=AsyncQuery)
    # Mock methods called on the query object, ensure they return the mock itself for chaining
    mock_query_chain.where.return_value = mock_query_chain
    mock_query_chain.limit.return_value = mock_query_chain
    # Assign the awaitable get method to the final link in the chain
    mock_query_chain.get = mock_query_get_method

    # Ensure the db client returns the start of the mock chain
    # db.collection(...).where(...).where(...).where(...).limit(...) -> mock_query_chain
    mock_db_client.collection.return_value.where.return_value.where.return_value.where.return_value = mock_query_chain

    # Mock BaseService.set_document
    mock_set_request = AsyncMock(return_value=True)

    with patch.object(BaseService, 'get_document', mock_get_friendship), \
            patch.object(BaseService, 'set_document', mock_set_request), \
            patch('services.friend_service.uuid.uuid4', return_value=test_uuid_obj):

        result = await friend_service.send_friend_request(sender_id, receiver_id, message)

    assert result is True
    mock_get_friendship.assert_called_once_with(friend_service.friends_collection, f"{sender_id}_{receiver_id}")
    # Assert the final .get() was awaited twice
    assert mock_query_get_method.await_count == 2
    mock_set_request.assert_called_once()
    # Check args passed to set_document
    call_args_set = mock_set_request.call_args[0]
    assert call_args_set[0] == friend_service.requests_collection
    assert call_args_set[1] == request_id  # Check ID format
    saved_data = call_args_set[2]
    assert saved_data['sender_id'] == sender_id
    assert saved_data['receiver_id'] == receiver_id
    assert saved_data['message'] == message
    assert saved_data['status'] == FriendRequestStatus.PENDING.value  # Check serialized enum
    assert 'created_at' in saved_data
    assert 'updated_at' in saved_data


@pytest.mark.asyncio
async def test_send_friend_request_failure(friend_service, mock_db_client, test_user_1_uid, test_user_2_uid):
    sender_id, receiver_id = test_user_1_uid, test_user_2_uid

    # Mock BaseService.get_document
    mock_get_friendship = AsyncMock(return_value=None)

    # FIX: Correctly mock the query chain
    mock_query_get_method = AsyncMock(return_value=[])
    mock_query_chain = MagicMock(spec=AsyncQuery)
    mock_query_chain.where.return_value = mock_query_chain
    mock_query_chain.limit.return_value = mock_query_chain
    mock_query_chain.get = mock_query_get_method
    mock_db_client.collection.return_value.where.return_value.where.return_value.where.return_value = mock_query_chain

    # Mock BaseService.set_document to fail
    mock_set_request = AsyncMock(return_value=False)

    with patch.object(BaseService, 'get_document', mock_get_friendship), \
            patch.object(BaseService, 'set_document', mock_set_request), \
            patch('services.friend_service.uuid.uuid4'):

        result = await friend_service.send_friend_request(sender_id, receiver_id)

    assert result is False
    # Assert the final .get() was awaited twice (check happens before set attempt)
    assert mock_query_get_method.await_count == 2
    mock_set_request.assert_called_once()  # Ensure it was attempted


# --- Tests for get_friend_request ---
# ... (get_friend_request tests remain the same) ...
@pytest.mark.asyncio
async def test_get_friend_request_found(friend_service, sample_friend_request):
    request_id = sample_friend_request.request_id
    # Use mode='json' to simulate Firestore data serialization (enums to values)
    mock_data = sample_friend_request.model_dump(mode='json')
    with patch.object(BaseService, 'get_document', AsyncMock(return_value=mock_data)) as mock_get:
        request = await friend_service.get_friend_request(request_id)

    assert request is not None
    assert isinstance(request, FriendRequest)
    assert request.request_id == request_id
    assert request.sender_id == sample_friend_request.sender_id
    mock_get.assert_called_once_with(friend_service.requests_collection, request_id)


@pytest.mark.asyncio
async def test_get_friend_request_not_found(friend_service):
    request_id = "non_existent_req"
    with patch.object(BaseService, 'get_document', AsyncMock(return_value=None)) as mock_get:
        request = await friend_service.get_friend_request(request_id)

    assert request is None
    mock_get.assert_called_once_with(friend_service.requests_collection, request_id)


# --- Tests for get_pending_requests ---
# ... (get_pending_requests tests remain the same) ...
@pytest.mark.asyncio
async def test_get_pending_requests(friend_service, mock_db_client, sample_friend_request, test_user_1_uid):
    # ... (Arrange user_id, mock_return_data_dict) ...
    user_id = test_user_1_uid
    sample_friend_request.receiver_id = user_id
    sample_friend_request.status = FriendRequestStatus.PENDING
    mock_return_data_dict = sample_friend_request.model_dump(mode='json')

    # Mock the final query result snapshot
    mock_snapshot = MagicMock()
    mock_snapshot.exists = True
    mock_snapshot.to_dict.return_value = mock_return_data_dict
    # Mock the awaitable .get() method
    mock_query_get_method = AsyncMock(return_value=[mock_snapshot])

    # Mock the query chain, including the two where calls
    mock_query_chain = MagicMock(spec=AsyncQuery)
    # FIX: Make the first .where() return the chain so the second .where() can be called
    mock_query_chain.where.return_value = mock_query_chain
    # Assign the awaitable get method to the end of the chain
    mock_query_chain.get = mock_query_get_method

    # Mock the db client call chain to return the start of the mock chain
    # db.collection(...).where(...).where(...) -> mock_query_chain
    mock_db_client.collection.return_value.where.return_value = mock_query_chain

    # Act
    results = await friend_service.get_pending_requests(user_id)

    # Assert results
    assert len(results) == 1
    assert results[0].receiver_id == user_id

    # Verify query chain calls
    mock_db_client.collection.assert_called_with(friend_service.requests_collection)
    # Get the mock object representing the collection reference
    collection_mock = mock_db_client.collection.return_value
    # Assert the first where call on the collection mock
    first_where_call = collection_mock.where.call_args_list[0]
    filter1_args = first_where_call[1]['filter']
    assert filter1_args.field_path == 'receiver_id'  # Use public attribute
    assert filter1_args.op_string == '=='
    assert filter1_args.value == user_id

    # Assert the second where call on the result of the first where (which is mock_query_chain)
    second_where_call = mock_query_chain.where.call_args_list[0]  # Called once on mock_query_chain
    filter2_args = second_where_call[1]['filter']
    assert filter2_args.field_path == 'status'  # Use public attribute
    assert filter2_args.op_string == '=='
    assert filter2_args.value == FriendRequestStatus.PENDING.value

    # Check get was awaited
    mock_query_get_method.assert_awaited_once()


# --- Tests for respond_to_request ---
# ... (respond_to_request tests remain the same) ...
@pytest.mark.asyncio
async def test_respond_to_request_accept(friend_service, sample_friend_request):
    request_id = sample_friend_request.request_id
    sender_id = sample_friend_request.sender_id
    receiver_id = sample_friend_request.receiver_id
    status_key1 = f"{sender_id}_{receiver_id}"
    status_key2 = f"{receiver_id}_{sender_id}"
    # Use mode='json' to simulate Firestore data
    mock_request_data = sample_friend_request.model_dump(mode='json')

    # Mock BaseService methods used by respond_to_request
    with patch.object(BaseService, 'get_document', AsyncMock(return_value=mock_request_data)) as mock_get_req, \
            patch.object(BaseService, 'update_document', AsyncMock(return_value=True)) as mock_update_req, \
            patch.object(BaseService, 'set_document', AsyncMock(return_value=True)) as mock_set_status:
        result = await friend_service.respond_to_request(request_id, accept=True)

    assert result is True
    # Verify get_document was called for the request
    mock_get_req.assert_called_once_with(friend_service.requests_collection, request_id)
    # Verify update_document call for the request status
    mock_update_req.assert_called_once()
    update_call_args = mock_update_req.call_args[0]  # Positional args
    assert update_call_args[0] == friend_service.requests_collection
    assert update_call_args[1] == request_id
    assert update_call_args[2]['status'] == FriendRequestStatus.ACCEPTED.value  # Check enum value
    assert 'updated_at' in update_call_args[2]
    # Verify set_document calls for friend status
    assert mock_set_status.call_count == 2
    set_calls = mock_set_status.call_args_list
    # Check that both keys were used for setting friend status
    keys_called = {call[0][1] for call in set_calls}  # Get the doc_id from each call
    assert keys_called == {status_key1, status_key2}
    # Optionally check the data structure passed to set_document
    assert set_calls[0][0][2]['user_id'] in [sender_id, receiver_id]
    assert set_calls[0][0][2]['friend_id'] in [sender_id, receiver_id]


@pytest.mark.asyncio
async def test_respond_to_request_reject(friend_service, sample_friend_request):
    request_id = sample_friend_request.request_id
    mock_request_data = sample_friend_request.model_dump(mode='json')

    with patch.object(BaseService, 'get_document', AsyncMock(return_value=mock_request_data)) as mock_get_req, \
            patch.object(BaseService, 'update_document', AsyncMock(return_value=True)) as mock_update_req, \
            patch.object(BaseService, 'set_document', AsyncMock()) as mock_set_status:  # Mock set just in case

        result = await friend_service.respond_to_request(request_id, accept=False)

    assert result is True
    mock_get_req.assert_called_once_with(friend_service.requests_collection, request_id)
    # Verify request status update to REJECTED
    mock_update_req.assert_called_once()
    update_args = mock_update_req.call_args[0][2]  # Data dict
    assert update_args['status'] == FriendRequestStatus.REJECTED.value
    # Verify friend status was NOT created
    mock_set_status.assert_not_called()


@pytest.mark.asyncio
async def test_respond_to_request_not_found(friend_service):
    """Test responding to a request that doesn't exist."""
    request_id = "fake_req"
    with patch.object(BaseService, 'get_document', AsyncMock(return_value=None)):
        result = await friend_service.respond_to_request(request_id, accept=True)
    assert result is False


@pytest.mark.asyncio
async def test_respond_to_request_parsing_error(friend_service, sample_friend_request):
    """Test responding when the fetched data is invalid."""
    request_id = sample_friend_request.request_id
    invalid_data = {"wrong_field": "some_value"}  # Missing required fields
    with patch.object(BaseService, 'get_document', AsyncMock(return_value=invalid_data)):
        result = await friend_service.respond_to_request(request_id, accept=True)
    assert result is False  # Service should handle parsing error and return False


# --- Tests for get_friends ---
# ... (get_friends tests remain the same) ...
@pytest.mark.asyncio
async def test_get_friends(friend_service, mock_db_client, sample_friend_status, test_user_1_uid):
    # ... (Arrange user_id, mock_return_data_dict) ...
    user_id = test_user_1_uid
    sample_friend_status.user_id = user_id
    mock_return_data_dict = sample_friend_status.model_dump(mode='json')

    mock_snapshot = MagicMock()
    mock_snapshot.exists = True
    mock_snapshot.to_dict.return_value = mock_return_data_dict
    mock_query_get_method = AsyncMock(return_value=[mock_snapshot])

    # Mock the query chain
    mock_query_chain = MagicMock(spec=AsyncQuery)
    mock_query_chain.get = mock_query_get_method
    mock_db_client.collection.return_value.where.return_value = mock_query_chain

    # Act
    friends = await friend_service.get_friends(user_id)

    # Assert results
    assert len(friends) == 1
    assert friends[0].user_id == user_id

    # Verify query
    mock_db_client.collection.assert_called_with(friend_service.friends_collection)
    where_call = mock_db_client.collection.return_value.where.call_args
    filter_args = where_call[1]['filter']
    # FIX: Use public attribute field_path
    assert filter_args.field_path == 'user_id'
    assert filter_args.op_string == '=='
    assert filter_args.value == user_id
    mock_query_get_method.assert_awaited_once()


# --- Tests for remove_friend ---
@pytest.mark.asyncio
async def test_remove_friend_success(friend_service, mock_db_client, test_user_1_uid, test_user_2_uid):
    user_id, friend_id = test_user_1_uid, test_user_2_uid
    status_key1 = f"{user_id}_{friend_id}"
    status_key2 = f"{friend_id}_{user_id}"

    # Mock document references needed before transaction starts
    mock_doc_ref1 = MagicMock()
    mock_doc_ref2 = MagicMock()

    def doc_side_effect(key):
        if key == status_key1: return mock_doc_ref1
        if key == status_key2: return mock_doc_ref2
        return MagicMock()

    mock_db_client.collection.return_value.document.side_effect = doc_side_effect

    # --- FIX: Mock db.transaction() AND the delete method ---
    # 1. Mock the transaction object that will be passed to the inner function
    mock_transaction_obj = AsyncMock(spec=AsyncTransaction)

    # 2. Mock db.transaction() to return a simple context manager that yields the mock transaction object
    #    This avoids errors like '_read_only' attribute missing.
    @pytest.mark.asyncio
    async def mock_transaction_context_manager(*args, **kwargs):
        yield mock_transaction_obj  # Yield the mock transaction

    mock_db_client.transaction.return_value = AsyncMock()  # Mock the initial call
    mock_db_client.transaction.return_value.__aenter__.return_value = mock_transaction_obj  # Make context yield mock
    mock_db_client.transaction.return_value.__aexit__ = AsyncMock(return_value=None)  # Mock exit

    # Act: Call the service method. The @async_transactional decorator will use the mocked transaction.
    result = await friend_service.remove_friend(user_id, friend_id)

    # Assert
    assert result is True
    # Verify the transaction was initiated
    mock_db_client.transaction.assert_called_once()
    # Verify delete was called on the mock transaction object for both refs
    assert mock_transaction_obj.delete.call_count == 2
    mock_transaction_obj.delete.assert_any_call(mock_doc_ref1)
    mock_transaction_obj.delete.assert_any_call(mock_doc_ref2)


@pytest.mark.asyncio
async def test_remove_friend_failure(friend_service, mock_db_client, test_user_1_uid, test_user_2_uid):
    user_id, friend_id = test_user_1_uid, test_user_2_uid
    status_key1 = f"{user_id}_{friend_id}"
    status_key2 = f"{friend_id}_{user_id}"

    # Mock document references
    mock_doc_ref1 = MagicMock()
    mock_doc_ref2 = MagicMock()

    def doc_side_effect(key):
        if key == status_key1: return mock_doc_ref1
        if key == status_key2: return mock_doc_ref2
        return MagicMock()

    mock_db_client.collection.return_value.document.side_effect = doc_side_effect

    # --- FIX: Mock db.transaction() AND make delete raise error ---
    mock_transaction_obj = AsyncMock(spec=AsyncTransaction)
    # Make the delete method raise an exception when called
    mock_transaction_obj.delete.side_effect = Exception("Simulated DB error during delete")

    @pytest.mark.asyncio
    async def mock_transaction_context_manager(*args, **kwargs):
        yield mock_transaction_obj

    mock_db_client.transaction.return_value = AsyncMock()
    mock_db_client.transaction.return_value.__aenter__.return_value = mock_transaction_obj
    mock_db_client.transaction.return_value.__aexit__ = AsyncMock(return_value=None)

    # Act
    result = await friend_service.remove_friend(user_id, friend_id)

    # Assert
    assert result is False
    # Verify the transaction was initiated
    mock_db_client.transaction.assert_called_once()
    # Verify delete was attempted
    mock_transaction_obj.delete.assert_called()  # Should be called at least once before raising


# --- Tests for update_last_interaction ---
# ... (update_last_interaction tests remain the same) ...
@pytest.mark.asyncio
async def test_update_last_interaction(friend_service, test_user_1_uid, test_user_2_uid):
    user_id, friend_id, game_id = test_user_1_uid, test_user_2_uid, "game1"
    status_key = f"{user_id}_{friend_id}"

    # Patch the BaseService method
    with patch.object(BaseService, 'update_document', AsyncMock(return_value=True)) as mock_update, \
            patch('services.friend_service.Increment') as MockIncrement:  # Mock Increment used inside the method
        MockIncrement.return_value = "INCREMENT_OBJECT"  # Return a placeholder
        result = await friend_service.update_last_interaction(user_id, friend_id, game_id)

    assert result is True
    mock_update.assert_called_once()
    # Check arguments passed to update_document
    call_args = mock_update.call_args[0]
    assert call_args[0] == friend_service.friends_collection
    assert call_args[1] == status_key
    update_data = call_args[2]
    assert 'last_interaction' in update_data
    assert isinstance(update_data['last_interaction'], datetime)
    assert update_data['games_played'] == "INCREMENT_OBJECT"  # Check the placeholder
    assert update_data['last_game'] == game_id


@pytest.mark.asyncio
async def test_update_last_interaction_no_game_id(friend_service, test_user_1_uid, test_user_2_uid):
    user_id, friend_id = test_user_1_uid, test_user_2_uid
    status_key = f"{user_id}_{friend_id}"

    with patch.object(BaseService, 'update_document', AsyncMock(return_value=True)) as mock_update, \
            patch('services.friend_service.Increment') as MockIncrement:
        MockIncrement.return_value = "INCREMENT_OBJECT"
        result = await friend_service.update_last_interaction(user_id, friend_id, game_id=None)

    assert result is True
    mock_update.assert_called_once()
    update_data = mock_update.call_args[0][2]
    assert 'last_interaction' in update_data
    assert update_data['games_played'] == "INCREMENT_OBJECT"
    assert 'last_game' not in update_data


================================================================================

Filename: tests/unit_whitebox/test_u_history_service.py
Content:
from datetime import datetime, timezone, timedelta
from unittest.mock import AsyncMock, patch

import pytest

from models.game_history import GameHistory, GameResult  # Import model and enum
from services.base_service import BaseService  # Import BaseService
# Import the class to test and its dependencies/models
from services.history_service import HistoryService


@pytest.fixture
def history_service(mock_db_client):
    """Creates an instance of the HistoryService with the mocked DB client."""
    return HistoryService(mock_db_client)


# --- Test Cases ---

@pytest.mark.asyncio
async def test_archive_game_success(history_service, mock_db_client, sample_game_history):
    """Test successfully archiving a game."""
    game_data = sample_game_history
    # Mock the underlying set_document call used by archive_game
    with patch.object(BaseService, 'set_document', new_callable=AsyncMock) as mock_set:
        mock_set.return_value = True
        result = await history_service.archive_game(game_data)

    assert result is True
    # Assert BaseService.set_document was called correctly
    mock_set.assert_called_once_with(
        history_service.collection,  # 'game_history'
        game_data.game_id,
        game_data.model_dump()  # Changed from dict() to model_dump()
    )


@pytest.mark.asyncio
async def test_archive_game_failure(history_service, mock_db_client, sample_game_history):
    """Test game archiving when the database set operation fails."""
    game_data = sample_game_history
    with patch.object(BaseService, 'set_document', new_callable=AsyncMock) as mock_set:
        mock_set.return_value = False  # Simulate failure
        result = await history_service.archive_game(game_data)

    assert result is False
    mock_set.assert_called_once()  # Ensure it was attempted


@pytest.mark.asyncio
async def test_get_game_found(history_service, mock_db_client, sample_game_history):
    """Test retrieving an existing game."""
    game_id = sample_game_history.game_id
    mock_data_dict = sample_game_history.model_dump()
    with patch.object(BaseService, 'get_document', new_callable=AsyncMock) as mock_get:
        mock_get.return_value = mock_data_dict
        game = await history_service.get_game(game_id)

    assert game is not None
    assert isinstance(game, GameHistory)
    assert game.game_id == game_id
    assert game.white_player_id == sample_game_history.white_player_id
    mock_get.assert_called_once_with(history_service.collection, game_id)


@pytest.mark.asyncio
async def test_get_game_not_found(history_service, mock_db_client):
    """Test retrieving a non-existent game."""
    game_id = "non_existent_game"
    with patch.object(BaseService, 'get_document', new_callable=AsyncMock) as mock_get:
        mock_get.return_value = None
        game = await history_service.get_game(game_id)

    assert game is None
    mock_get.assert_called_once_with(history_service.collection, game_id)


@pytest.mark.asyncio
async def test_get_user_games(history_service, sample_game_history, test_user_1_uid):
    user_id = test_user_1_uid
    limit = 20
    sample_game_history.white_player_id = user_id
    mock_return_data = [sample_game_history.model_dump(mode='json')]  # Use mode='json'

    # Mock BaseService.query_collection
    with patch.object(BaseService, 'query_collection', new_callable=AsyncMock) as mock_query_coll:
        # FIX: Simulate results for *two* calls
        mock_query_coll.side_effect = [
            mock_return_data,  # Games where user is white
            []  # Games where user is black
        ]
        results = await history_service.get_user_games(user_id, limit)

    assert len(results) == 1
    assert isinstance(results[0], GameHistory)
    assert results[0].game_id == sample_game_history.game_id
    assert user_id == results[0].white_player_id  # In this specific mock setup

    # FIX: Verify the calls to the mocked BaseService.query_collection
    assert mock_query_coll.call_count == 2
    # Check first call (user as white)
    call1_args, call1_kwargs = mock_query_coll.call_args_list[0]
    assert call1_args[0] == history_service.collection  # Positional collection arg
    assert call1_kwargs['filters'] == [('white_player_id', '==', user_id)]
    assert call1_kwargs['order_by'] == ('end_time', 'DESCENDING')
    assert call1_kwargs['limit'] == limit
    # Check second call (user as black)
    call2_args, call2_kwargs = mock_query_coll.call_args_list[1]
    assert call2_args[0] == history_service.collection  # Positional collection arg
    assert call2_kwargs['filters'] == [('black_player_id', '==', user_id)]
    assert call2_kwargs['order_by'] == ('end_time', 'DESCENDING')
    assert call2_kwargs['limit'] == limit


@pytest.mark.asyncio
async def test_get_games_between_players(history_service, sample_game_history, test_user_1_uid, test_user_2_uid):
    player1_id = test_user_1_uid
    player2_id = test_user_2_uid
    limit = 5
    sample_game_history.white_player_id = player1_id
    sample_game_history.black_player_id = player2_id
    mock_return_data = [sample_game_history.model_dump(mode='json')]  # Use mode='json'

    with patch.object(BaseService, 'query_collection', new_callable=AsyncMock) as mock_query_coll:
        mock_query_coll.side_effect = [mock_return_data, []]
        results = await history_service.get_games_between_players(player1_id, player2_id, limit)

    assert len(results) == 1
    assert isinstance(results[0], GameHistory)
    assert results[0].game_id == sample_game_history.game_id
    assert (results[0].white_player_id == player1_id and results[0].black_player_id == player2_id)

    # Verify query_collection was called twice with appropriate filters
    assert mock_query_coll.call_count == 2
    # FIX: Check positional args and kwargs for filters, limit, order_by
    # Call 1
    call1_args, call1_kwargs = mock_query_coll.call_args_list[0]
    expected_filters1 = [('white_player_id', '==', player1_id), ('black_player_id', '==', player2_id)]
    assert call1_args[0] == history_service.collection
    assert call1_kwargs['filters'] == expected_filters1
    assert call1_kwargs['limit'] == limit
    assert call1_kwargs['order_by'] == ('end_time', 'DESCENDING')
    # Call 2
    call2_args, call2_kwargs = mock_query_coll.call_args_list[1]
    expected_filters2 = [('white_player_id', '==', player2_id), ('black_player_id', '==', player1_id)]
    assert call2_args[0] == history_service.collection
    assert call2_kwargs['filters'] == expected_filters2
    assert call2_kwargs['limit'] == limit
    assert call2_kwargs['order_by'] == ('end_time', 'DESCENDING')


@pytest.mark.asyncio
async def test_get_user_stats_calculation(history_service, test_user_1_uid):
    # ... (Arrange game data, using mode='json') ...
    user_id = test_user_1_uid
    days = 30
    start_date = datetime.now(timezone.utc) - timedelta(days=days)
    game1_data = GameHistory(
        game_id="g1", white_player_id=user_id, black_player_id="p2", result=GameResult.WHITE_WIN,
        start_time=start_date + timedelta(days=1, minutes=-10), end_time=start_date + timedelta(days=1),
        moves=["e4"] * 20, rating_change={'white': 8, 'black': -8}, white_rating=0, black_rating=0, time_control={}
    ).model_dump(mode='json')  # Use mode='json'
    game2_data = GameHistory(
        game_id="g2", white_player_id="p3", black_player_id=user_id, result=GameResult.BLACK_WIN,
        start_time=start_date + timedelta(days=2, minutes=-15), end_time=start_date + timedelta(days=2),
        moves=["d4"] * 30, rating_change={'white': -7, 'black': 7}, white_rating=0, black_rating=0, time_control={}
    ).model_dump(mode='json')  # Use mode='json'
    game3_data = GameHistory(
        game_id="g3", white_player_id=user_id, black_player_id="p4", result=GameResult.DRAW,
        start_time=start_date + timedelta(days=3, minutes=-5), end_time=start_date + timedelta(days=3),
        moves=["c4"] * 10, rating_change={'white': 0, 'black': 0}, white_rating=0, black_rating=0, time_control={}
    ).model_dump(mode='json')  # Use mode='json'

    with patch.object(BaseService, 'query_collection', new_callable=AsyncMock) as mock_query_coll:
        mock_query_coll.side_effect = [[game1_data, game3_data], [game2_data]]
        stats = await history_service.get_user_stats(user_id, days)

    # ... (Verify stats totals) ...
    assert stats['total_games'] == 3
    assert stats['wins'] == 2
    assert stats['losses'] == 0
    assert stats['draws'] == 1

    # FIX: Parse ISO strings before calculating duration
    dur1 = (datetime.fromisoformat(game1_data['end_time']) - datetime.fromisoformat(
        game1_data['start_time'])).total_seconds()
    dur2 = (datetime.fromisoformat(game2_data['end_time']) - datetime.fromisoformat(
        game2_data['start_time'])).total_seconds()
    dur3 = (datetime.fromisoformat(game3_data['end_time']) - datetime.fromisoformat(
        game3_data['start_time'])).total_seconds()
    expected_total_duration = dur1 + dur2 + dur3
    assert stats['average_game_length'] == pytest.approx(expected_total_duration / 3)


@pytest.mark.asyncio
async def test_get_popular_openings(history_service):
    # ... (Arrange game data, using mode='json') ...
    limit = 2
    now = datetime.now(timezone.utc)
    game1_data = GameHistory(game_id="op1", moves=["e4", "e5", "Nf3", "Nc6"], end_time=now, result=GameResult.WHITE_WIN,
                             winner_id="p1", white_player_id="p1", black_player_id="p2",
                             start_time=now - timedelta(minutes=1), white_rating=0, black_rating=0, rating_change={},
                             time_control={}).model_dump(mode='json')
    game2_data = GameHistory(game_id="op2", moves=["d4", "d5", "c4", "e6"], end_time=now, result=GameResult.DRAW,
                             white_player_id="p3", black_player_id="p4", start_time=now - timedelta(minutes=1),
                             white_rating=0, black_rating=0, rating_change={}, time_control={}).model_dump(mode='json')
    game3_data = GameHistory(game_id="op3", moves=["e4", "e5", "Nf3", "Nf6"], end_time=now, result=GameResult.BLACK_WIN,
                             winner_id="p6", white_player_id="p5", black_player_id="p6",
                             start_time=now - timedelta(minutes=1), white_rating=0, black_rating=0, rating_change={},
                             time_control={}).model_dump(mode='json')
    game4_data = GameHistory(game_id="op4", moves=["e4", "e5", "Nf3", "Nc6", "Bb5"], end_time=now,
                             result=GameResult.WHITE_WIN, winner_id="p7", white_player_id="p7", black_player_id="p8",
                             start_time=now - timedelta(minutes=1), white_rating=0, black_rating=0, rating_change={},
                             time_control={}).model_dump(mode='json')
    game5_data = GameHistory(game_id="op5", moves=["e4", "c5"], end_time=now, result=GameResult.ABANDONED,
                             white_player_id="p9", black_player_id="p10", start_time=now - timedelta(minutes=1),
                             white_rating=0, black_rating=0, rating_change={}, time_control={}).model_dump(mode='json')

    with patch.object(BaseService, 'query_collection', new_callable=AsyncMock) as mock_query_coll:
        mock_query_coll.return_value = [game1_data, game2_data, game3_data, game4_data, game5_data]
        openings = await history_service.get_popular_openings(limit)

    assert len(openings) == limit
    opening1 = next((op for op in openings if op['moves'] == "e4 e5 Nf3"), None)
    assert opening1 is not None
    assert opening1['count'] == 3
    # FIX: Check 'wins' based on updated logic (only decisive wins counted)
    assert opening1['wins'] == 3  # g1(W), g3(B), g4(W) - assuming updated logic counts these
    opening2 = next((op for op in openings if op['moves'] == "d4 d5 c4"), None)
    assert opening2 is not None
    assert opening2['count'] == 1
    assert opening2['wins'] == 0  # Draw is not counted as win in updated logic example
    assert openings[0]['count'] >= openings[1]['count']
    assert openings[0]['moves'] == "e4 e5 Nf3"


================================================================================

Filename: tests/unit_whitebox/test_u_jwt_utils.py
Content:
# Filename: tests/unit_whitebox/test_u_jwt_utils.py
import time
from datetime import datetime, timedelta, timezone
from unittest.mock import patch
from fastapi import HTTPException
import pytest
from jose import JWTError, ExpiredSignatureError

# Import the module to be tested
from utils import jwt_utils


# Import specific exceptions if defined in jwt_utils or rely on jose's
# For this example, we assume it might raise HTTPException directly or rely on JOSE errors

# --- Test Configuration / Mocks ---

# We need to ensure the constants used by jwt_utils are available.
# Patching os.getenv is one way if they aren't set in the test environment.
@pytest.fixture(autouse=True)
def mock_jwt_settings():
    """Mocks environment variables used by jwt_utils."""
    with patch.dict(jwt_utils.os.environ, {
        "JWT_SECRET_KEY": "test-secret-key-for-unit-tests",
        # Optionally override ALGORITHM or EXPIRE_MINUTES if needed for tests
        # "JWT_ALGORITHM": "HS256",
        # "ACCESS_TOKEN_EXPIRE_MINUTES": "1" # Example: 1 minute expiry for testing
    }):
        # Reload the module IF it reads env vars at import time.
        # If it reads them inside functions, this might not be strictly needed,
        # but it's safer.
        import importlib
        importlib.reload(jwt_utils)
        yield
        # Restore original settings if necessary (though usually not needed for tests)
        importlib.reload(jwt_utils)


# --- Test Cases ---

def test_create_access_token_default_expiry():
    """Test creating a token with the default expiration."""
    data_to_encode = {"uid": "user123", "role": "tester"}
    token = jwt_utils.create_access_token(data=data_to_encode)

    assert isinstance(token, str)
    # Decode without verification to check payload structure (using a different library if needed, or jose itself)
    # Note: Direct decoding without verification is generally discouraged outside tests
    payload = jwt_utils.jwt.decode(token, jwt_utils.SECRET_KEY, algorithms=[jwt_utils.ALGORITHM],
                                   options={"verify_signature": False, "verify_exp": False})
    assert payload["uid"] == "user123"
    assert payload["role"] == "tester"
    assert "exp" in payload
    # Check if expiry is roughly correct (within a few seconds of default)
    expected_exp = datetime.now(timezone.utc) + timedelta(minutes=jwt_utils.ACCESS_TOKEN_EXPIRE_MINUTES)
    actual_exp = datetime.fromtimestamp(payload["exp"], timezone.utc)
    assert abs((expected_exp - actual_exp).total_seconds()) < 5  # Allow 5 seconds difference


def test_create_access_token_custom_expiry():
    """Test creating a token with a specific expiration delta."""
    data_to_encode = {"uid": "user456"}
    custom_delta = timedelta(hours=2)
    token = jwt_utils.create_access_token(data=data_to_encode, expires_delta=custom_delta)

    assert isinstance(token, str)
    payload = jwt_utils.jwt.decode(token, jwt_utils.SECRET_KEY, algorithms=[jwt_utils.ALGORITHM],
                                   options={"verify_signature": False, "verify_exp": False})
    assert payload["uid"] == "user456"
    assert "exp" in payload
    expected_exp = datetime.now(timezone.utc) + custom_delta
    actual_exp = datetime.fromtimestamp(payload["exp"], timezone.utc)
    assert abs((expected_exp - actual_exp).total_seconds()) < 5  # Allow 5 seconds difference


def test_verify_token_valid():
    """Test verifying a valid, unexpired token."""
    data = {"uid": "verify_me", "data": "test"}
    token = jwt_utils.create_access_token(data)
    time.sleep(0.1)  # Ensure token timestamp is slightly in the past

    payload = jwt_utils.verify_token(token)

    assert payload["uid"] == "verify_me"
    assert payload["data"] == "test"
    assert "exp" in payload


def test_verify_token_invalid_signature():
    """Test verifying a token signed with a different secret."""
    data = {"uid": "bad_sig"}
    # Create token with the correct algorithm but wrong key
    wrong_secret = "a-completely-different-secret"
    invalid_token = jwt_utils.jwt.encode(data, wrong_secret, algorithm=jwt_utils.ALGORITHM)

    # verify_token should raise an exception caught by the try...except block
    # which then raises an HTTPException (check jwt_utils implementation)
    # If verify_token raises jose.JWTError directly without catching:
    with pytest.raises(HTTPException) as exc_info:
        jwt_utils.verify_token(invalid_token)
    assert exc_info.value.status_code == 401
    assert "Signature verification failed" in exc_info.value.detail # Check detail


def test_verify_token_expired():
    """Test verifying a token that has expired."""
    data = {"uid": "expired_user"}
    # Create a token that expired 1 second ago
    expiry_delta = timedelta(seconds=-1)
    expired_token = jwt_utils.create_access_token(data, expires_delta=expiry_delta)

    # If verify_token raises jose.ExpiredSignatureError directly:
    # with pytest.raises(ExpiredSignatureError):
    #     jwt_utils.verify_token(expired_token)

    # If verify_token catches JWTError and raises HTTPException(401):
    with pytest.raises(HTTPException) as exc_info:
        jwt_utils.verify_token(expired_token)
    assert exc_info.value.status_code == 401
    assert "Could not validate credentials" in exc_info.value.detail # Or specific expiry message


def test_verify_token_malformed():
    """Test verifying a token that is not a valid JWT format."""
    malformed_token = "this.is.not.a.jwt"
    # with pytest.raises(JWTError):  # Expecting jose decode error
    #     jwt_utils.verify_token(malformed_token)

    # Or check for HTTPException if caught internally
    with pytest.raises(HTTPException) as exc_info:
        jwt_utils.verify_token(malformed_token)
    assert exc_info.value.status_code == 401


def test_create_tokens_for_user():
    """Test the helper function to create tokens based on Firebase user data."""
    # Simulate the structure returned by firebase_admin.auth.verify_id_token
    firebase_user_data = {
        "uid": "fb_user_for_token",
        "email": "fb_user@example.com",
        "email_verified": True,
        "name": "Firebase User Name"  # Other claims might be present
    }

    token_response = jwt_utils.create_tokens_for_user(firebase_user_data)

    assert "access_token" in token_response
    assert isinstance(token_response["access_token"], str)
    assert token_response["token_type"] == "bearer"
    assert "expires_in" in token_response
    assert token_response["expires_in"] == jwt_utils.ACCESS_TOKEN_EXPIRE_MINUTES * 60

    # Verify the claims within the generated access token
    access_token = token_response["access_token"]
    payload = jwt_utils.verify_token(access_token)
    assert payload["uid"] == "fb_user_for_token"
    assert payload["email"] == "fb_user@example.com"
    assert payload["email_verified"] is True
    assert "exp" in payload
    # Ensure extra claims from input aren't included unless explicitly added
    assert "name" not in payload


def test_create_tokens_for_user_minimal_firebase_data():
    """Test token creation with minimal required data from Firebase."""
    firebase_user_data = {
        "uid": "minimal_fb_user"
        # Email might be missing or not verified
    }

    token_response = jwt_utils.create_tokens_for_user(firebase_user_data)

    assert "access_token" in token_response
    access_token = token_response["access_token"]
    payload = jwt_utils.verify_token(access_token)
    assert payload["uid"] == "minimal_fb_user"
    assert payload.get("email") is None  # Check default handling
    assert payload.get("email_verified") is False  # Check default handling


================================================================================

Filename: tests/unit_whitebox/test_u_profile_service.py
Content:
from datetime import datetime, timezone
from unittest.mock import AsyncMock, patch, MagicMock  # Import call

import pytest
from google.cloud import firestore

from models.user_profile import UserProfile
# Import BaseService to patch its methods
from services.base_service import BaseService
# Import the class to test and its dependencies/models
from services.profile_service import ProfileService


# Import the mock Firestore utility classes if needed for assertions


@pytest.fixture
def profile_service(mock_db_client):  # Keep mock_db_client fixture for now, might remove later
    """Creates an instance of the ProfileService."""
    # We will patch BaseService methods directly in the tests below
    return ProfileService(mock_db_client)  # Pass the mock client, though we override methods


# Mocks for firestore field types (needed for assertions)
@pytest.fixture
def mock_fs_increment():
    return firestore.Increment(1)


@pytest.fixture
def mock_fs_array_union():
    return firestore.ArrayUnion(["some_value"])


# --- Test Cases ---

@pytest.mark.asyncio
async def test_create_profile_success(profile_service, sample_user_profile):
    """Test successfully creating a new profile by mocking BaseService.set_document."""
    profile_data = sample_user_profile
    # Mock the specific BaseService method used by create_profile
    with patch.object(BaseService, 'set_document', new_callable=AsyncMock) as mock_set:
        mock_set.return_value = True  # Simulate successful set
        result = await profile_service.create_profile(profile_data)

    assert result is True
    # Verify the call to the mocked BaseService method
    # Use model_dump() instead of dict() for Pydantic v2
    mock_set.assert_called_once_with(
        profile_service.collection,  # 'user_profiles'
        profile_data.uid,
        profile_data.model_dump()  # Use model_dump()
    )


@pytest.mark.asyncio
async def test_create_profile_failure(profile_service, sample_user_profile):
    """Test profile creation failure by mocking BaseService.set_document."""
    profile_data = sample_user_profile
    with patch.object(BaseService, 'set_document', new_callable=AsyncMock) as mock_set:
        mock_set.return_value = False  # Simulate failure
        result = await profile_service.create_profile(profile_data)

    assert result is False
    mock_set.assert_called_once_with(
        profile_service.collection, profile_data.uid, profile_data.model_dump()  # Use model_dump()
    )


@pytest.mark.asyncio
async def test_get_profile_found(profile_service, sample_user_profile):
    """Test retrieving an existing profile by mocking BaseService.get_document."""
    uid = sample_user_profile.uid
    # Mock get_document to return the expected dict
    with patch.object(BaseService, 'get_document', new_callable=AsyncMock) as mock_get:
        # Use model_dump() for serialization simulation
        mock_get.return_value = sample_user_profile.model_dump()
        profile = await profile_service.get_profile(uid)

    assert profile is not None
    assert isinstance(profile, UserProfile)
    assert profile.uid == uid
    mock_get.assert_called_once_with(profile_service.collection, uid)


@pytest.mark.asyncio
async def test_get_profile_not_found(profile_service, test_user_1_uid):
    """Test retrieving non-existent profile by mocking BaseService.get_document."""
    uid = test_user_1_uid
    with patch.object(BaseService, 'get_document', new_callable=AsyncMock) as mock_get:
        mock_get.return_value = None  # Simulate not found
        profile = await profile_service.get_profile(uid)

    assert profile is None
    mock_get.assert_called_once_with(profile_service.collection, uid)


@pytest.mark.asyncio
async def test_update_profile_success(profile_service, test_user_1_uid):
    """Test updating profile by mocking BaseService.update_document."""
    uid = test_user_1_uid
    updates = {"display_name": "New Updated Name"}
    # Mock utcnow used inside update_profile
    mock_now = datetime.now(timezone.utc)
    with patch.object(BaseService, 'update_document', new_callable=AsyncMock) as mock_update, \
            patch('services.profile_service.datetime') as mock_datetime:
        mock_datetime.now.return_value = mock_now  # Use timezone.utc if needed
        mock_update.return_value = True
        result = await profile_service.update_profile(uid, updates.copy())  # Pass copy

    assert result is True
    # Verify update_document call *includes* 'last_active'
    mock_update.assert_called_once()
    call_args = mock_update.call_args[0]
    assert call_args[0] == profile_service.collection  # collection
    assert call_args[1] == uid  # doc_id
    update_data = call_args[2]  # data dict
    assert update_data["display_name"] == "New Updated Name"
    assert "last_active" in update_data
    # assert update_data["last_active"] == mock_now # Check the mocked time is used


@pytest.mark.asyncio
async def test_update_profile_failure(profile_service, test_user_1_uid):
    """Test profile update failure by mocking BaseService.update_document."""
    uid = test_user_1_uid
    updates = {"display_name": "Update Fail"}
    with patch.object(BaseService, 'update_document', new_callable=AsyncMock) as mock_update, \
            patch('services.profile_service.datetime'):  # Still need to patch datetime if used
        mock_update.return_value = False  # Simulate failure
        result = await profile_service.update_profile(uid, updates.copy())

    assert result is False
    mock_update.assert_called_once()  # Check it was called even on failure


# --- Tests requiring mocked Firestore field types ---

@pytest.mark.asyncio
async def test_update_rating_win(profile_service, test_user_1_uid, mock_fs_increment):
    """Test updating rating after win by mocking BaseService.update_document."""
    uid = test_user_1_uid
    new_rating = 1258
    game_result = {"result": "win"}
    with patch.object(BaseService, 'update_document', new_callable=AsyncMock) as mock_update, \
            patch('services.profile_service.firestore.Increment',  # Mock Increment where it's used
                  return_value=mock_fs_increment):
        mock_update.return_value = True
        result = await profile_service.update_rating(uid, new_rating, game_result)

    assert result is True
    expected_update = {
        'rating': new_rating,
        'games_played': mock_fs_increment,
        'wins': mock_fs_increment
    }
    mock_update.assert_called_once_with(profile_service.collection, uid, expected_update)


@pytest.mark.asyncio
async def test_update_rating_loss(profile_service, test_user_1_uid, mock_fs_increment):
    """Test updating rating after loss by mocking BaseService.update_document."""
    uid = test_user_1_uid
    new_rating = 1242
    game_result = {"result": "loss"}
    with patch.object(BaseService, 'update_document', new_callable=AsyncMock) as mock_update, \
            patch('services.profile_service.firestore.Increment', return_value=mock_fs_increment):
        mock_update.return_value = True
        result = await profile_service.update_rating(uid, new_rating, game_result)

    assert result is True
    expected_update = {
        'rating': new_rating,
        'games_played': mock_fs_increment,
        'losses': mock_fs_increment
    }
    mock_update.assert_called_once_with(profile_service.collection, uid, expected_update)


@pytest.mark.asyncio
async def test_update_rating_draw(profile_service, test_user_1_uid, mock_fs_increment):
    """Test updating rating after draw by mocking BaseService.update_document."""
    uid = test_user_1_uid
    new_rating = 1250
    game_result = {"result": "draw"}
    with patch.object(BaseService, 'update_document', new_callable=AsyncMock) as mock_update, \
            patch('services.profile_service.firestore.Increment', return_value=mock_fs_increment):
        mock_update.return_value = True
        result = await profile_service.update_rating(uid, new_rating, game_result)

    assert result is True
    expected_update = {
        'rating': new_rating,
        'games_played': mock_fs_increment,
        'draws': mock_fs_increment
    }
    mock_update.assert_called_once_with(profile_service.collection, uid, expected_update)


@pytest.mark.asyncio
async def test_add_achievement_success(profile_service, test_user_1_uid):
    uid = test_user_1_uid
    achievement_id = "unit_test_master"
    # Patch BaseService method and the correct ArrayUnion
    with patch.object(BaseService, 'update_document', new_callable=AsyncMock) as mock_update, \
            patch('google.cloud.firestore_v1.ArrayUnion') as mock_array_union_constructor:  # FIX: Correct patch target
        # Configure mocks
        mock_update.return_value = True
        # Create a dummy object to represent what ArrayUnion might return
        # This is needed because the code calls ArrayUnion(...)
        mock_array_union_instance = MagicMock(name="ArrayUnionInstance")
        mock_array_union_constructor.return_value = mock_array_union_instance

        # Act
        result = await profile_service.add_achievement(uid, achievement_id)

    # Assert
    assert result is True
    # Verify ArrayUnion constructor was called
    mock_array_union_constructor.assert_called_once_with([achievement_id])
    # FIX: Verify update_document call structure using ANY
    mock_update.assert_called_once_with(
        profile_service.collection,
        uid,
        {'achievements': mock_array_union_instance}  # Check the instance returned by the mock constructor was used
        # Or use ANY for more flexibility: {'achievements': ANY}
    )


# --- Query Tests (Mocking BaseService.query_collection) ---

@pytest.mark.asyncio
async def test_search_profiles_found(profile_service, sample_user_profile):
    """Test searching profiles by mocking BaseService.query_collection."""
    prefix = sample_user_profile.username[:5]
    limit = 10
    with patch.object(BaseService, 'query_collection', new_callable=AsyncMock) as mock_query:
        # Return data that matches what the real query would return (list of dicts)
        mock_query.return_value = [sample_user_profile.model_dump()]
        results = await profile_service.search_profiles(prefix, limit)

    assert len(results) == 1
    assert isinstance(results[0], UserProfile)
    assert results[0].uid == sample_user_profile.uid

    # Verify the arguments passed to the mocked query_collection
    mock_query.assert_called_once()
    call_args, call_kwargs = mock_query.call_args
    assert call_args[0] == profile_service.collection  # Check positional collection arg
    expected_filters = [
        ('username', '>=', prefix),
        ('username', '<=', prefix + '\uf8ff')
    ]
    assert call_kwargs.get('filters') == expected_filters
    assert call_kwargs.get('order_by') == ('username', 'ASCENDING')
    assert call_kwargs.get('limit') == limit


@pytest.mark.asyncio
async def test_search_profiles_not_found(profile_service):
    """Test searching profiles when no results are found."""
    prefix = "nonexistent"
    limit = 5
    with patch.object(BaseService, 'query_collection', new_callable=AsyncMock) as mock_query:
        mock_query.return_value = []  # Simulate empty result
        results = await profile_service.search_profiles(prefix, limit)

    assert isinstance(results, list)
    assert len(results) == 0
    mock_query.assert_called_once()  # Verify it was called


@pytest.mark.asyncio
async def test_get_leaderboard(profile_service, sample_user_profile):
    """Test retrieving the leaderboard by mocking BaseService.query_collection."""
    limit = 50
    with patch.object(BaseService, 'query_collection', new_callable=AsyncMock) as mock_query:
        mock_query.return_value = [sample_user_profile.model_dump()]
        results = await profile_service.get_leaderboard(limit)

    assert len(results) == 1
    assert isinstance(results[0], UserProfile)

    # Verify arguments passed to query_collection
    # FIX: Match the actual call which doesn't explicitly pass filters=None
    mock_query.assert_called_once_with(
        profile_service.collection,  # Positional collection
        # filters=None, # REMOVE this assertion
        order_by=('rating', 'DESCENDING'),
        limit=limit
    )

================================================================================

Filename: token_generator.py
Content:
import json
import os  # Import os to use getenv for backend URL

import requests
from dotenv import load_dotenv

# Load optional .env if needed for API key (or hardcode it temporarily)
load_dotenv()

# --- Configuration ---
# GET THIS FROM YOUR FIREBASE PROJECT SETTINGS! (Project Settings -> General -> Web API Key)
# !! IMPORTANT: Replace "YOUR_FIREBASE_WEB_API_KEY" with your actual key !!
FIREBASE_WEB_API_KEY = os.getenv("FIREBASE_WEB_API_KEY", "YOUR_FIREBASE_WEB_API_KEY")
if FIREBASE_WEB_API_KEY == "YOUR_FIREBASE_WEB_API_KEY":
    print("WARNING: FIREBASE_WEB_API_KEY is not set. Please set it in your .env file or directly in the script.")

# Backend URL (use environment variable like in tests)
BACKEND_BASE_URL = os.getenv("TEST_BASE_URL", "http://localhost:8080").rstrip('/')

# Credentials for your test users (replace with actuals you created in Firebase Auth)
USER1_EMAIL = os.getenv("TEST_USER1_EMAIL", "testuser1@example.com")
USER1_PASSWORD = os.getenv("TEST_USER1_PASSWORD", "testP4ssw0rd1")
USER2_EMAIL = os.getenv("TEST_USER2_EMAIL", "testuser2@example.com")
USER2_PASSWORD = os.getenv("TEST_USER2_PASSWORD", "testP4ssw0rd2")

# Firebase REST API endpoint for email/password sign-in
rest_api_url = f"https://identitytoolkit.googleapis.com/v1/accounts:signInWithPassword?key={FIREBASE_WEB_API_KEY}"


# --- Function to Get Firebase Token ---
def get_firebase_id_token(email, password):
    """Authenticates a user via Firebase REST API and returns their Firebase ID token."""
    print(f"Attempting Firebase authentication for {email}...")
    payload = json.dumps({
        "email": email,
        "password": password,
        "returnSecureToken": True
    })
    headers = {"Content-Type": "application/json"}

    try:
        response = requests.post(rest_api_url, headers=headers, data=payload)
        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)
        token_data = response.json()
        print(f"Successfully authenticated {email} with Firebase.")
        # print(f"Full Firebase Response: {token_data}") # Uncomment for debugging
        return token_data.get("idToken")
    except requests.exceptions.RequestException as e:
        print(f"Error authenticating {email} with Firebase: {e}")
        if e.response is not None:
            print(f"Firebase Error details: {e.response.text}")
        return None
    except json.JSONDecodeError:
        print(f"Error decoding Firebase response for {email}.")
        return None


# --- Function to Get Backend Token ---
def get_backend_token(base_url, firebase_id_token):
    """Exchanges a Firebase ID token for a backend access token."""
    if not firebase_id_token:
        return None

    backend_token_url = f"{base_url}/auth/token"
    print(f"Attempting backend token exchange at {backend_token_url}...")
    payload = json.dumps({"firebase_token": firebase_id_token})
    headers = {"Content-Type": "application/json"}

    try:
        response = requests.post(backend_token_url, headers=headers, data=payload)
        response.raise_for_status()
        token_data = response.json()
        print("Successfully exchanged Firebase token for backend token.")
        # print(f"Full Backend Response: {token_data}") # Uncomment for debugging
        return token_data.get("access_token")
    except requests.exceptions.RequestException as e:
        print(f"Error exchanging token with backend: {e}")
        if e.response is not None:
            print(f"Backend Error details: {e.response.text}")
        return None
    except json.JSONDecodeError:
        print("Error decoding backend response.")
        return None


# --- Main Execution ---

# --- Step 1: Get Firebase ID Tokens ---
print("\n--- Step 1: Obtaining Firebase ID Tokens ---")
user1_firebase_token = get_firebase_id_token(USER1_EMAIL, USER1_PASSWORD)
user2_firebase_token = get_firebase_id_token(USER2_EMAIL, USER2_PASSWORD)

# --- Step 2: Exchange for Backend Tokens ---
print("\n--- Step 2: Exchanging for Backend Access Tokens ---")
user1_backend_token = None
user2_backend_token = None

if user1_firebase_token:
    user1_backend_token = get_backend_token(BACKEND_BASE_URL, user1_firebase_token)
else:
    print("Skipping backend token exchange for User 1 (Firebase token missing).")

if user2_firebase_token:
    user2_backend_token = get_backend_token(BACKEND_BASE_URL, user2_firebase_token)
else:
    print("Skipping backend token exchange for User 2 (Firebase token missing).")

# --- Step 3: Print Results for Environment Variables ---
print("\n--- Step 3: Tokens for Environment Variables ---")

if user1_firebase_token:
    print("Set this Firebase token for TEST_FIREBASE_ID_TOKEN:")
    print(f"{user1_firebase_token}\n")
else:
    print("Failed to get Firebase ID Token for User 1.\n")

if user1_backend_token:
    print("Set this backend token for TEST_USER1_BACKEND_TOKEN:")
    print(f"{user1_backend_token}\n")
else:
    print("Failed to get Backend Access Token for User 1.\n")

if user2_backend_token:
    print("Set this backend token for TEST_USER2_BACKEND_TOKEN:")
    print(f"{user2_backend_token}\n")
else:
    print("Failed to get Backend Access Token for User 2.\n")

print("Remember to also set TEST_USER1_UID and TEST_USER2_UID (obtainable from Firebase console or decoded tokens).")


================================================================================

Filename: utils/dependencies.py
Content:
from fastapi import HTTPException, Security
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer

from config.firebase_config import initialize_firebase
from schemas.auth_schemas import TokenData
from services.analytics_service import AnalyticsService
from services.friend_service import FriendService
from services.history_service import HistoryService
from services.profile_service import ProfileService
from utils.jwt_utils import verify_token

# Initialize Firebase and get Firestore client
db_client = initialize_firebase()

# Initialize services
profile_service = ProfileService(db_client)
friend_service = FriendService(db_client)
history_service = HistoryService(db_client)
analytics_service = AnalyticsService(db_client)

# Security scheme
security = HTTPBearer()


async def get_current_user(credentials: HTTPAuthorizationCredentials = Security(security)) -> TokenData:
    """Verify JWT token and return user data."""
    try:
        payload = verify_token(credentials.credentials)
        return TokenData(
            uid=payload["uid"],
            email=payload.get("email"),
            email_verified=payload.get("email_verified", False)
        )
    except Exception as e:
        raise HTTPException(
            status_code=401,
            detail=f"Could not validate credentials: {str(e)}",
            headers={"WWW-Authenticate": "Bearer"}
        )


def get_profile_service() -> ProfileService:
    """Dependency for profile service."""
    return profile_service


def get_friend_service() -> FriendService:
    """Dependency for friend service."""
    return friend_service


def get_history_service() -> HistoryService:
    """Dependency for history service."""
    return history_service


def get_analytics_service() -> AnalyticsService:
    """Dependency for analytics service."""
    return analytics_service


================================================================================

Filename: utils/jwt_utils.py
Content:
import os
from datetime import datetime, timedelta, timezone  # Use timezone-aware objects
from typing import Optional

from dotenv import load_dotenv
from fastapi import HTTPException
from jose import JWTError, jwt

load_dotenv()

# Get JWT settings from environment variables
SECRET_KEY = os.getenv("JWT_SECRET_KEY")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 60  # 1 hour

if not SECRET_KEY:
    raise ValueError("JWT_SECRET_KEY must be set in environment variables")


def create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:
    """Create a new JWT access token."""
    to_encode = data.copy()

    # Set expiration time using timezone-aware datetime
    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        expire = datetime.now(timezone.utc) + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)

    to_encode.update({"exp": expire})
    # Ensure standard claims like 'iat' are included if needed, though jose might add them.
    # Add 'iat' (issued at) claim
    to_encode.setdefault("iat", datetime.now(timezone.utc))

    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt


def verify_token(token: str) -> dict:
    """Verify a JWT token and return its payload."""
    try:
        # Decode the token, ignoring audience verification for internal use
        # Explicitly pass options to disable audience verification
        payload = jwt.decode(
            token,
            SECRET_KEY,
            algorithms=[ALGORITHM],
            options={"verify_aud": False}  # <--- FIX: Ignore audience verification
        )
        if "uid" not in payload:
            raise JWTError("Missing 'uid' claim in token payload.")
        # Optional: Add expiration check here if not handled by decode
        # exp = payload.get("exp")
        # if exp is None or datetime.fromtimestamp(exp, timezone.utc) < datetime.now(timezone.utc):
        #     raise ExpiredSignatureError("Token has expired.")
        return payload
    except JWTError as e:  # Catch specific JOSE errors first
        raise HTTPException(
            status_code=401,
            detail=f"Could not validate credentials: {str(e)}",
            headers={"WWW-Authenticate": "Bearer"},
        )
    except Exception as e:  # Catch other potential errors during decoding
        raise HTTPException(
            status_code=401,
            detail=f"Could not validate credentials: Unexpected error ({type(e).__name__})",
            headers={"WWW-Authenticate": "Bearer"},
        )


def create_tokens_for_user(firebase_user: dict) -> dict:
    """Create access token from Firebase user data."""
    # Extract relevant user data
    user_data = {
        "uid": firebase_user["uid"],
        "email": firebase_user.get("email"),
        "email_verified": firebase_user.get("email_verified", False),
        # Add other claims from firebase_user if needed for the backend token
        # e.g., "name": firebase_user.get("name")
    }

    # Create access token
    access_token = create_access_token(user_data)

    return {
        "access_token": access_token,
        "token_type": "bearer",
        "expires_in": ACCESS_TOKEN_EXPIRE_MINUTES * 60  # in seconds
    }

================================================================================
